{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "-028b2NqE02R",
   "metadata": {
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1693232083105,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "-028b2NqE02R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 17:45:28.084686: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.Session(config=config).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a034672d",
   "metadata": {
    "executionInfo": {
     "elapsed": 1150,
     "status": "ok",
     "timestamp": 1693232086282,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "a034672d"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import BatchNormalization, LeakyReLU, MaxPooling1D, Dropout, Flatten, Dense, Conv1D,Reshape,multiply,GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from scipy.interpolate import splev, splrep\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591596f3",
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1693232087740,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "591596f3"
   },
   "outputs": [],
   "source": [
    "base_dir = \"./dataset\"\n",
    "\n",
    "ir = 3 \n",
    "before = 2\n",
    "after = 2\n",
    "scaler = lambda arr: (arr - np.min(arr)) / (np.max(arr) - np.min(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cef782d",
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1693232089719,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "0cef782d"
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "def interpolate_numpy_array(arr, desired_length):\n",
    "    cs = CubicSpline(np.linspace(0, 1, len(arr)), arr)\n",
    "    x_new = np.linspace(0, 1, desired_length)\n",
    "    interpolated_arr = cs(x_new)\n",
    "    return interpolated_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "KXj-pyPoXKm3",
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1693232167282,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "KXj-pyPoXKm3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def load_data():\n",
    "    tm = np.arange(0, (before + 1 + after) * 60, step=1 / float(ir))\n",
    "    with open(os.path.join(base_dir, \"apnea.pkl\"), 'rb') as f:\n",
    "        apnea_ecg = pickle.load(f)\n",
    "    x_train1,x_train2,x_train3 = [],[],[]\n",
    "    o_train, y_train = apnea_ecg[\"o_train\"], apnea_ecg[\"y_train\"]\n",
    "    groups_train = apnea_ecg[\"groups_train\"]\n",
    "    for i in range(len(o_train)):\n",
    "        min_distance_list, max_distance_list= o_train[i]\n",
    "        min_distance_list_inter = interpolate_numpy_array(min_distance_list,900)\n",
    "        max_distance_list_inter = interpolate_numpy_array(max_distance_list,900)\n",
    "        x_train1.append([min_distance_list_inter, max_distance_list_inter])\n",
    "        x_train2.append([min_distance_list_inter[180:720], max_distance_list_inter[180:720]])\n",
    "        x_train3.append([min_distance_list_inter[360:540], max_distance_list_inter[360:540]])\n",
    "    x_training1,x_training2,x_training3,y_training,groups_training = [],[],[],[],[]\n",
    "    x_val1,x_val2,x_val3,y_val,groups_val = [],[],[],[],[]\n",
    "\n",
    "    trainlist = random.sample(range(len(o_train)),int(len(o_train)*0.7))\n",
    "    num=[i for i in range(16713)]\n",
    "    vallist = set(num) - set(trainlist)\n",
    "    vallist = list(vallist)\n",
    "    for i in trainlist:\n",
    "        x_training1.append(x_train1[i])\n",
    "        x_training2.append(x_train2[i])\n",
    "        x_training3.append(x_train3[i])\n",
    "        y_training.append(y_train[i])\n",
    "        groups_training.append(groups_train[i])\n",
    "    for i in vallist:\n",
    "        x_val1.append(x_train1[i])\n",
    "        x_val2.append(x_train2[i])\n",
    "        x_val3.append(x_train3[i])\n",
    "        y_val.append(y_train[i])\n",
    "        groups_val.append(groups_train[i])\n",
    "\n",
    "    x_training1 = np.array(x_training1, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_training2 = np.array(x_training2, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_training3 = np.array(x_training3, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    y_training = np.array(y_training, dtype=\"float32\")\n",
    "    x_val1 = np.array(x_val1, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_val2 = np.array(x_val2, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_val3 = np.array(x_val3, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    y_val = np.array(y_val, dtype=\"float32\")\n",
    "\n",
    "    x_test1,x_test2,x_test3 = [],[],[]\n",
    "    o_test, y_test = apnea_ecg[\"o_test\"], apnea_ecg[\"y_test\"]\n",
    "    groups_test = apnea_ecg[\"groups_test\"]\n",
    "    for i in range(len(o_test)):\n",
    "        min_distance_list, max_distance_list = o_test[i]\n",
    "        min_distance_list_inter = interpolate_numpy_array(min_distance_list,900)\n",
    "        max_distance_list_inter = interpolate_numpy_array(max_distance_list,900)\n",
    "        x_test1.append([min_distance_list_inter, max_distance_list_inter])\n",
    "        x_test2.append([min_distance_list_inter[180:720], max_distance_list_inter[180:720]])\n",
    "        x_test3.append([min_distance_list_inter[360:540], max_distance_list_inter[360:540]])\n",
    "    x_test1 = np.array(x_test1, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_test2 = np.array(x_test2, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_test3 = np.array(x_test3, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    y_test = np.array(y_test, dtype=\"float32\")\n",
    "\n",
    "    return x_training1, x_training2, x_training3, y_training, groups_training, x_val1, x_val2, x_val3, y_val, groups_val, x_test1, x_test2, x_test3, y_test, groups_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ef5b79-3b27-4888-9bb6-ad2415d780d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, ratio=4,**kwargs):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.channels = input_shape[-1]\n",
    "        self.fc1 = tf.keras.layers.Dense(self.channels // self.ratio, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(self.channels, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        max_pool = tf.reduce_max(inputs, axis=[1, 2], keepdims=True)\n",
    "        avg_pool = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n",
    "        max_pool = self.fc1(max_pool)\n",
    "        avg_pool = self.fc1(avg_pool)\n",
    "        attention = self.fc2(tf.keras.layers.add([max_pool, avg_pool]))\n",
    "        return inputs * attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9c50e53-c397-4432-bb00-4ec3a202a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = keras.layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71576d5f-5bfa-4321-bd05-f1a9b3c2d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualAttentionBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(ResidualAttentionBlock, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv1D(num_output_features, kernel_size=1, strides=1, padding='valid', use_bias=False)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv1D(num_output_features, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv3 = tf.keras.layers.Conv1D(num_output_features, kernel_size=1, strides=1, padding='valid', use_bias=False)\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        residual = x       \n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = self.sigmoid(out)      \n",
    "\n",
    "        out = out * residual + residual\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd7222a-ca10-4ac3-b7ca-6272cbbd2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers=2, d_model=64, nhead=1, dim_feedforward=128, dropout=0.30):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.precnnlayer = layers.Dense(d_model)\n",
    "        self.multi_head_attention = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model)\n",
    "\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(dim_feedforward, activation='relu'),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "\n",
    "        self.layer_norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "        self.pred_layer = tf.keras.Sequential([\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.precnnlayer(x)\n",
    "        x += self.multi_head_attention(x, x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm1(x)\n",
    "        ffn_output = self.ffn(x)\n",
    "        x += ffn_output\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.pred_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "GnDFx0fGCy1m",
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1693232096445,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "GnDFx0fGCy1m"
   },
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling1D\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, GRU, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def create_model(input_b_shape,input_c_shape, weight=1e-3,rate=1):\n",
    "    leaky_relu = LeakyReLU()\n",
    "    \n",
    "    # CNN-2\n",
    "    input2 = Input(shape=input_b_shape)\n",
    "    x2 = BatchNormalization()(input2)\n",
    "    x2 = Conv1D(16, kernel_size=9, strides=4, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x2)\n",
    "    \n",
    "    x2 = leaky_relu(x2)\n",
    "    x2 = MaxPooling1D(pool_size=3)(x2)\n",
    "    x2 = Dropout(0.5)(x2)\n",
    "\n",
    "    x2 = Conv1D(32, kernel_size=5, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = leaky_relu(x2)\n",
    "    x2 = MaxPooling1D(pool_size=3)(x2)\n",
    "    x2 = Dropout(0.5)(x2)\n",
    "\n",
    "    x2 = Conv1D(64, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = leaky_relu(x2)\n",
    "    x2 = Dropout(0.5)(x2)\n",
    "\n",
    "    x2 = Conv1D(128, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = leaky_relu(x2)\n",
    "    x2 = Dropout(0.5)(x2)\n",
    "\n",
    "    x2 = Conv1D(256, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = leaky_relu(x2)   \n",
    "    x2 = MaxPooling1D(pool_size=3)(x2)    \n",
    "    x2 = Dropout(0.5)(x2)\n",
    "    \n",
    "  \n",
    "    # CNN-3\n",
    "    input3 = Input(shape=input_c_shape)\n",
    "    x3 = Conv1D(16, kernel_size=7, strides=4, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(input3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = leaky_relu(x3)\n",
    "    x3 = MaxPooling1D(pool_size=3)(x3)\n",
    "    x3 = Dropout(0.5)(x3)\n",
    "\n",
    "    x3 = Conv1D(32, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = leaky_relu(x3)\n",
    "    x3 = MaxPooling1D(pool_size=3)(x3)\n",
    "    x3 = Dropout(0.5)(x3)\n",
    "\n",
    "    x3 = Conv1D(64, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = leaky_relu(x3)\n",
    "    x3 = Dropout(0.5)(x3)\n",
    "\n",
    "    attention1 = ResidualAttentionBlock(256, 256)\n",
    "    attention2 = ResidualAttentionBlock(64, 64)\n",
    "    # 将注意力应用于输入数据\n",
    "    x2 = attention1(x2)\n",
    "    x3 = attention2(x3)\n",
    "\n",
    "    concat = keras.layers.concatenate([x2, x3], name=\"Concat_Layer\", axis=-1)  \n",
    "    concat=ChannelAttention()(concat)\n",
    "    x = GlobalAveragePooling1D()(concat)\n",
    "    dp = Dropout(0.5)(x)\n",
    "    outputs = Dense(2, activation='softmax', name=\"Output_Layer\")(dp)\n",
    "    model = Model(inputs=[input2,input3], outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c830eb3",
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1693232100397,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "6c830eb3"
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch > 70 and \\\n",
    "            (epoch - 1) % 10 == 0:\n",
    "        lr *= 0.1\n",
    "    print(\"Learning rate: \", lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded3f606",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1693232101699,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "ded3f606"
   },
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    \"\"\"Plot performance curve\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    axes[0].plot(history[\"loss\"], \"r-\", history[\"val_loss\"], \"b-\", linewidth=0.5)\n",
    "    axes[0].set_title(\"Loss\")\n",
    "    axes[1].plot(history[\"accuracy\"], \"r-\", history[\"val_accuracy\"], \"b-\", linewidth=0.5)\n",
    "    axes[1].set_title(\"Accuracy\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "v6XhEYeu7cgM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45661,
     "status": "ok",
     "timestamp": 1693233004292,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "v6XhEYeu7cgM",
    "outputId": "4f452c32-a1f2-4c9e-b7bc-05ca348f3613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape (11699, 900, 2) (11699, 540, 2) (11699, 180, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    x_train1, x_train2, x_train3, y_train, groups_train, x_val1, x_val2, x_val3, y_val, groups_val, x_test1, x_test2, x_test3, y_test, groups_test= load_data()\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes=2)  # Convert to two categories\n",
    "    y_val = keras.utils.to_categorical(y_val, num_classes=2)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes=2)\n",
    "\n",
    "    print('input_shape', x_train1.shape, x_train2.shape, x_train3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ae98c6d-d470-4371-b7bb-6707c20168f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 19s 41ms/step - loss: 1.9931 - accuracy: 0.5723 - val_loss: 1.7549 - val_accuracy: 0.4639 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.6317 - accuracy: 0.6060 - val_loss: 1.5781 - val_accuracy: 0.4882 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.4262 - accuracy: 0.6370 - val_loss: 1.4340 - val_accuracy: 0.4896 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.2692 - accuracy: 0.6542 - val_loss: 1.3016 - val_accuracy: 0.5158 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.1381 - accuracy: 0.6752 - val_loss: 1.1858 - val_accuracy: 0.5525 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 1.0341 - accuracy: 0.6879 - val_loss: 1.0896 - val_accuracy: 0.5929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.9410 - accuracy: 0.7026 - val_loss: 0.9637 - val_accuracy: 0.6572 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.8580 - accuracy: 0.7184 - val_loss: 0.8335 - val_accuracy: 0.7256 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.7804 - accuracy: 0.7420 - val_loss: 0.7483 - val_accuracy: 0.7603 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.7215 - accuracy: 0.7577 - val_loss: 0.6818 - val_accuracy: 0.7734 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.6724 - accuracy: 0.7725 - val_loss: 0.6769 - val_accuracy: 0.7611 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.6373 - accuracy: 0.7812 - val_loss: 0.6115 - val_accuracy: 0.7924 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.5980 - accuracy: 0.7950 - val_loss: 0.5920 - val_accuracy: 0.7980 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.5634 - accuracy: 0.8075 - val_loss: 0.5566 - val_accuracy: 0.8073 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.5361 - accuracy: 0.8170 - val_loss: 0.5441 - val_accuracy: 0.8215 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.5194 - accuracy: 0.8196 - val_loss: 0.4878 - val_accuracy: 0.8412 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4945 - accuracy: 0.8320 - val_loss: 0.4856 - val_accuracy: 0.8383 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.4699 - accuracy: 0.8406 - val_loss: 0.4890 - val_accuracy: 0.8412 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4526 - accuracy: 0.8470 - val_loss: 0.4282 - val_accuracy: 0.8642 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4511 - accuracy: 0.8447 - val_loss: 0.4122 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4288 - accuracy: 0.8585 - val_loss: 0.4488 - val_accuracy: 0.8638 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4331 - accuracy: 0.8520 - val_loss: 0.4233 - val_accuracy: 0.8668 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4243 - accuracy: 0.8567 - val_loss: 0.3830 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4202 - accuracy: 0.8575 - val_loss: 0.3916 - val_accuracy: 0.8797 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4086 - accuracy: 0.8648 - val_loss: 0.3738 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4057 - accuracy: 0.8629 - val_loss: 0.4109 - val_accuracy: 0.8791 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4087 - accuracy: 0.8620 - val_loss: 0.3791 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4120 - accuracy: 0.8573 - val_loss: 0.3848 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3996 - accuracy: 0.8650 - val_loss: 0.3629 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3995 - accuracy: 0.8614 - val_loss: 0.3729 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3932 - accuracy: 0.8679 - val_loss: 0.3588 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3922 - accuracy: 0.8643 - val_loss: 0.3678 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3936 - accuracy: 0.8628 - val_loss: 0.3562 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3797 - accuracy: 0.8740 - val_loss: 0.3424 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3816 - accuracy: 0.8692 - val_loss: 0.3462 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3816 - accuracy: 0.8723 - val_loss: 0.3718 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3855 - accuracy: 0.8690 - val_loss: 0.3608 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3735 - accuracy: 0.8748 - val_loss: 0.3501 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3781 - accuracy: 0.8716 - val_loss: 0.3500 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3745 - accuracy: 0.8728 - val_loss: 0.3564 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3799 - accuracy: 0.8708 - val_loss: 0.3542 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3830 - accuracy: 0.8667 - val_loss: 0.3456 - val_accuracy: 0.8935 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3736 - accuracy: 0.8702 - val_loss: 0.3381 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3741 - accuracy: 0.8709 - val_loss: 0.3477 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3676 - accuracy: 0.8758 - val_loss: 0.3405 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3721 - accuracy: 0.8763 - val_loss: 0.3543 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3743 - accuracy: 0.8741 - val_loss: 0.3416 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3709 - accuracy: 0.8733 - val_loss: 0.3468 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3745 - accuracy: 0.8732 - val_loss: 0.3435 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3716 - accuracy: 0.8711 - val_loss: 0.3557 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3703 - accuracy: 0.8735 - val_loss: 0.3539 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3686 - accuracy: 0.8719 - val_loss: 0.3345 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3632 - accuracy: 0.8752 - val_loss: 0.3832 - val_accuracy: 0.8769 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3677 - accuracy: 0.8752 - val_loss: 0.3315 - val_accuracy: 0.8945 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3666 - accuracy: 0.8724 - val_loss: 0.3479 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3703 - accuracy: 0.8740 - val_loss: 0.3622 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3624 - accuracy: 0.8755 - val_loss: 0.3274 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3677 - accuracy: 0.8723 - val_loss: 0.3513 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3709 - accuracy: 0.8759 - val_loss: 0.3413 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3674 - accuracy: 0.8729 - val_loss: 0.3286 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3671 - accuracy: 0.8739 - val_loss: 0.3355 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3655 - accuracy: 0.8774 - val_loss: 0.3371 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3643 - accuracy: 0.8740 - val_loss: 0.3247 - val_accuracy: 0.8957 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3620 - accuracy: 0.8743 - val_loss: 0.3251 - val_accuracy: 0.8987 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3618 - accuracy: 0.8767 - val_loss: 0.3311 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3624 - accuracy: 0.8743 - val_loss: 0.3434 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3661 - accuracy: 0.8734 - val_loss: 0.3268 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3563 - accuracy: 0.8752 - val_loss: 0.3312 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.3600 - accuracy: 0.8754 - val_loss: 0.3281 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3592 - accuracy: 0.8755 - val_loss: 0.3227 - val_accuracy: 0.8983 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3635 - accuracy: 0.8745 - val_loss: 0.3293 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3480 - accuracy: 0.8796 - val_loss: 0.3226 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3457 - accuracy: 0.8842 - val_loss: 0.3194 - val_accuracy: 0.9019 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3422 - accuracy: 0.8809 - val_loss: 0.3157 - val_accuracy: 0.9021 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3377 - accuracy: 0.8845 - val_loss: 0.3187 - val_accuracy: 0.9013 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3347 - accuracy: 0.8859 - val_loss: 0.3151 - val_accuracy: 0.9017 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3406 - accuracy: 0.8843 - val_loss: 0.3100 - val_accuracy: 0.9013 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3357 - accuracy: 0.8839 - val_loss: 0.3099 - val_accuracy: 0.9021 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3364 - accuracy: 0.8818 - val_loss: 0.3117 - val_accuracy: 0.9017 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3363 - accuracy: 0.8818 - val_loss: 0.3118 - val_accuracy: 0.9019 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 0.3294 - accuracy: 0.8871 - val_loss: 0.3102 - val_accuracy: 0.9027 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.3297 - accuracy: 0.8871 - val_loss: 0.3111 - val_accuracy: 0.9033 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.3317 - accuracy: 0.8857 - val_loss: 0.3114 - val_accuracy: 0.9023 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3290 - accuracy: 0.8865 - val_loss: 0.3112 - val_accuracy: 0.9025 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3308 - accuracy: 0.8830 - val_loss: 0.3102 - val_accuracy: 0.9025 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.3343 - accuracy: 0.8821 - val_loss: 0.3108 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3336 - accuracy: 0.8819 - val_loss: 0.3100 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.3322 - accuracy: 0.8819 - val_loss: 0.3093 - val_accuracy: 0.9027 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.3303 - accuracy: 0.8846 - val_loss: 0.3100 - val_accuracy: 0.9033 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3309 - accuracy: 0.8874 - val_loss: 0.3095 - val_accuracy: 0.9029 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3254 - accuracy: 0.8872 - val_loss: 0.3099 - val_accuracy: 0.9033 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3282 - accuracy: 0.8860 - val_loss: 0.3098 - val_accuracy: 0.9027 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3276 - accuracy: 0.8874 - val_loss: 0.3101 - val_accuracy: 0.9035 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3299 - accuracy: 0.8873 - val_loss: 0.3096 - val_accuracy: 0.9027 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3272 - accuracy: 0.8883 - val_loss: 0.3100 - val_accuracy: 0.9031 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.3264 - accuracy: 0.8874 - val_loss: 0.3096 - val_accuracy: 0.9031 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3225 - accuracy: 0.8872 - val_loss: 0.3097 - val_accuracy: 0.9027 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.3280 - accuracy: 0.8815 - val_loss: 0.3101 - val_accuracy: 0.9029 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.3275 - accuracy: 0.8842 - val_loss: 0.3097 - val_accuracy: 0.9025 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.3284 - accuracy: 0.8832 - val_loss: 0.3096 - val_accuracy: 0.9033 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 7s 13ms/step - loss: 0.2814 - accuracy: 0.9062\n",
      "17/17 [==============================] - 2s 26ms/step\n",
      "TP:5667, TN:9690, FP:765, FN:824, loss0.281370609998703, acc0.906231559069987, sn0.8730549992297026, sp0.926829268292683, f10.8770409347674689, auc0.9627924726146587\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 25s 55ms/step - loss: 1.9133 - accuracy: 0.5691 - val_loss: 1.7048 - val_accuracy: 0.5822 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 1.5874 - accuracy: 0.6072 - val_loss: 1.6829 - val_accuracy: 0.3957 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 1.3840 - accuracy: 0.6312 - val_loss: 1.5227 - val_accuracy: 0.4035 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 1.2116 - accuracy: 0.6471 - val_loss: 1.3078 - val_accuracy: 0.4729 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 1.0765 - accuracy: 0.6691 - val_loss: 1.1596 - val_accuracy: 0.5383 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.9760 - accuracy: 0.6767 - val_loss: 1.0301 - val_accuracy: 0.5903 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.8858 - accuracy: 0.6949 - val_loss: 0.9590 - val_accuracy: 0.6131 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.8176 - accuracy: 0.7099 - val_loss: 0.8228 - val_accuracy: 0.6821 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.7517 - accuracy: 0.7291 - val_loss: 0.7154 - val_accuracy: 0.7463 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.6922 - accuracy: 0.7504 - val_loss: 0.6545 - val_accuracy: 0.7902 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.6535 - accuracy: 0.7591 - val_loss: 0.6237 - val_accuracy: 0.7882 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.6213 - accuracy: 0.7706 - val_loss: 0.5629 - val_accuracy: 0.8151 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.5809 - accuracy: 0.7872 - val_loss: 0.5422 - val_accuracy: 0.8127 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.5496 - accuracy: 0.8024 - val_loss: 0.5083 - val_accuracy: 0.8251 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.5168 - accuracy: 0.8160 - val_loss: 0.4728 - val_accuracy: 0.8448 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.5027 - accuracy: 0.8232 - val_loss: 0.4927 - val_accuracy: 0.8420 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.4829 - accuracy: 0.8330 - val_loss: 0.4274 - val_accuracy: 0.8682 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.4595 - accuracy: 0.8432 - val_loss: 0.4313 - val_accuracy: 0.8658 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.4407 - accuracy: 0.8486 - val_loss: 0.4398 - val_accuracy: 0.8684 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.4394 - accuracy: 0.8500 - val_loss: 0.3966 - val_accuracy: 0.8769 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.4289 - accuracy: 0.8545 - val_loss: 0.3795 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.4129 - accuracy: 0.8602 - val_loss: 0.3820 - val_accuracy: 0.8813 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.4161 - accuracy: 0.8583 - val_loss: 0.3839 - val_accuracy: 0.8801 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.4111 - accuracy: 0.8561 - val_loss: 0.3758 - val_accuracy: 0.8813 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.4092 - accuracy: 0.8584 - val_loss: 0.3647 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.4016 - accuracy: 0.8623 - val_loss: 0.3702 - val_accuracy: 0.8837 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3933 - accuracy: 0.8625 - val_loss: 0.3564 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3922 - accuracy: 0.8673 - val_loss: 0.3564 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3867 - accuracy: 0.8685 - val_loss: 0.3807 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3820 - accuracy: 0.8716 - val_loss: 0.3409 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3844 - accuracy: 0.8696 - val_loss: 0.3503 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.3802 - accuracy: 0.8726 - val_loss: 0.3439 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3818 - accuracy: 0.8711 - val_loss: 0.3538 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.3719 - accuracy: 0.8762 - val_loss: 0.3490 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3768 - accuracy: 0.8715 - val_loss: 0.3486 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3723 - accuracy: 0.8729 - val_loss: 0.3509 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3784 - accuracy: 0.8673 - val_loss: 0.3565 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3749 - accuracy: 0.8725 - val_loss: 0.3752 - val_accuracy: 0.8803 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.3683 - accuracy: 0.8746 - val_loss: 0.3332 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.3751 - accuracy: 0.8725 - val_loss: 0.3514 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3687 - accuracy: 0.8746 - val_loss: 0.3434 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3655 - accuracy: 0.8756 - val_loss: 0.3323 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3640 - accuracy: 0.8754 - val_loss: 0.3377 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3696 - accuracy: 0.8743 - val_loss: 0.3386 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3708 - accuracy: 0.8786 - val_loss: 0.3296 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3661 - accuracy: 0.8752 - val_loss: 0.3608 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3627 - accuracy: 0.8729 - val_loss: 0.3427 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3587 - accuracy: 0.8761 - val_loss: 0.3521 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3644 - accuracy: 0.8737 - val_loss: 0.3340 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3560 - accuracy: 0.8779 - val_loss: 0.3258 - val_accuracy: 0.8945 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3591 - accuracy: 0.8758 - val_loss: 0.3478 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3626 - accuracy: 0.8741 - val_loss: 0.3497 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3601 - accuracy: 0.8738 - val_loss: 0.3311 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3559 - accuracy: 0.8808 - val_loss: 0.3638 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3652 - accuracy: 0.8723 - val_loss: 0.3559 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3567 - accuracy: 0.8772 - val_loss: 0.3213 - val_accuracy: 0.8993 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3600 - accuracy: 0.8746 - val_loss: 0.3401 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3587 - accuracy: 0.8773 - val_loss: 0.3299 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3575 - accuracy: 0.8746 - val_loss: 0.3254 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3645 - accuracy: 0.8712 - val_loss: 0.3311 - val_accuracy: 0.8965 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3541 - accuracy: 0.8759 - val_loss: 0.3470 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3577 - accuracy: 0.8752 - val_loss: 0.3173 - val_accuracy: 0.9015 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3572 - accuracy: 0.8747 - val_loss: 0.3328 - val_accuracy: 0.8971 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3560 - accuracy: 0.8769 - val_loss: 0.3380 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3598 - accuracy: 0.8732 - val_loss: 0.3577 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3568 - accuracy: 0.8775 - val_loss: 0.3309 - val_accuracy: 0.8965 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3562 - accuracy: 0.8789 - val_loss: 0.3257 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3535 - accuracy: 0.8765 - val_loss: 0.3327 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.3557 - accuracy: 0.8783 - val_loss: 0.3438 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3518 - accuracy: 0.8783 - val_loss: 0.3294 - val_accuracy: 0.8985 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3571 - accuracy: 0.8757 - val_loss: 0.3329 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3483 - accuracy: 0.8806 - val_loss: 0.3241 - val_accuracy: 0.8989 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3379 - accuracy: 0.8861 - val_loss: 0.3221 - val_accuracy: 0.8997 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3393 - accuracy: 0.8822 - val_loss: 0.3194 - val_accuracy: 0.9011 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 5s 52ms/step - loss: 0.3345 - accuracy: 0.8838 - val_loss: 0.3188 - val_accuracy: 0.9003 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3389 - accuracy: 0.8820 - val_loss: 0.3164 - val_accuracy: 0.8997 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3359 - accuracy: 0.8847 - val_loss: 0.3154 - val_accuracy: 0.8997 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3339 - accuracy: 0.8855 - val_loss: 0.3130 - val_accuracy: 0.9023 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.3328 - accuracy: 0.8832 - val_loss: 0.3125 - val_accuracy: 0.9009 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.3262 - accuracy: 0.8876 - val_loss: 0.3110 - val_accuracy: 0.9013 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.3323 - accuracy: 0.8826 - val_loss: 0.3090 - val_accuracy: 0.9009 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3301 - accuracy: 0.8832 - val_loss: 0.3102 - val_accuracy: 0.9017 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3296 - accuracy: 0.8835 - val_loss: 0.3101 - val_accuracy: 0.9017 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3269 - accuracy: 0.8873 - val_loss: 0.3102 - val_accuracy: 0.9013 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3307 - accuracy: 0.8824 - val_loss: 0.3101 - val_accuracy: 0.9017 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3231 - accuracy: 0.8876 - val_loss: 0.3102 - val_accuracy: 0.9011 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3250 - accuracy: 0.8863 - val_loss: 0.3102 - val_accuracy: 0.9011 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3259 - accuracy: 0.8861 - val_loss: 0.3104 - val_accuracy: 0.9017 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.3233 - accuracy: 0.8874 - val_loss: 0.3100 - val_accuracy: 0.9025 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3229 - accuracy: 0.8862 - val_loss: 0.3095 - val_accuracy: 0.9021 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3265 - accuracy: 0.8884 - val_loss: 0.3101 - val_accuracy: 0.9017 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.3234 - accuracy: 0.8869 - val_loss: 0.3100 - val_accuracy: 0.9019 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3241 - accuracy: 0.8879 - val_loss: 0.3101 - val_accuracy: 0.9025 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3251 - accuracy: 0.8856 - val_loss: 0.3104 - val_accuracy: 0.9021 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3274 - accuracy: 0.8861 - val_loss: 0.3103 - val_accuracy: 0.9019 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3257 - accuracy: 0.8868 - val_loss: 0.3101 - val_accuracy: 0.9019 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3218 - accuracy: 0.8877 - val_loss: 0.3099 - val_accuracy: 0.9019 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3211 - accuracy: 0.8871 - val_loss: 0.3098 - val_accuracy: 0.9019 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3281 - accuracy: 0.8844 - val_loss: 0.3101 - val_accuracy: 0.9021 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3216 - accuracy: 0.8875 - val_loss: 0.3097 - val_accuracy: 0.9021 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 9ms/step - loss: 0.2847 - accuracy: 0.9053\n",
      "17/17 [==============================] - 1s 9ms/step\n",
      "TP:5523, TN:9818, FP:637, FN:968, loss0.28467845916748047, acc0.9052873834533223, sn0.8508704359882915, sp0.9390722142515543, f10.8731325586910125, auc0.961049508199596\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 26s 50ms/step - loss: 1.8488 - accuracy: 0.5720 - val_loss: 1.6525 - val_accuracy: 0.5927 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 1.5199 - accuracy: 0.6089 - val_loss: 1.4452 - val_accuracy: 0.5868 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 1.3022 - accuracy: 0.6316 - val_loss: 1.2697 - val_accuracy: 0.6099 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 1.1316 - accuracy: 0.6522 - val_loss: 1.1671 - val_accuracy: 0.5858 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 1.0077 - accuracy: 0.6701 - val_loss: 1.0516 - val_accuracy: 0.5676 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 0.9137 - accuracy: 0.6784 - val_loss: 0.9726 - val_accuracy: 0.5578 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 0.8418 - accuracy: 0.6909 - val_loss: 0.9157 - val_accuracy: 0.5927 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.7787 - accuracy: 0.7119 - val_loss: 0.8447 - val_accuracy: 0.6239 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.7388 - accuracy: 0.7141 - val_loss: 0.8424 - val_accuracy: 0.6027 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.7008 - accuracy: 0.7305 - val_loss: 0.7879 - val_accuracy: 0.6328 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.6633 - accuracy: 0.7440 - val_loss: 0.6378 - val_accuracy: 0.7519 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.6275 - accuracy: 0.7572 - val_loss: 0.6268 - val_accuracy: 0.7553 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.6080 - accuracy: 0.7639 - val_loss: 0.6774 - val_accuracy: 0.7150 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.5843 - accuracy: 0.7784 - val_loss: 0.5959 - val_accuracy: 0.7629 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.5595 - accuracy: 0.7858 - val_loss: 0.5516 - val_accuracy: 0.7906 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.5363 - accuracy: 0.7954 - val_loss: 0.4938 - val_accuracy: 0.8215 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.5110 - accuracy: 0.8075 - val_loss: 0.5494 - val_accuracy: 0.8099 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.4885 - accuracy: 0.8207 - val_loss: 0.5509 - val_accuracy: 0.8095 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.4749 - accuracy: 0.8293 - val_loss: 0.4537 - val_accuracy: 0.8566 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.4529 - accuracy: 0.8402 - val_loss: 0.4284 - val_accuracy: 0.8664 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.4455 - accuracy: 0.8467 - val_loss: 0.4082 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.4365 - accuracy: 0.8482 - val_loss: 0.4073 - val_accuracy: 0.8740 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.4207 - accuracy: 0.8535 - val_loss: 0.3881 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.4113 - accuracy: 0.8600 - val_loss: 0.3833 - val_accuracy: 0.8791 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.4132 - accuracy: 0.8581 - val_loss: 0.3850 - val_accuracy: 0.8793 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.4007 - accuracy: 0.8652 - val_loss: 0.3847 - val_accuracy: 0.8815 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.4016 - accuracy: 0.8598 - val_loss: 0.3693 - val_accuracy: 0.8831 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3978 - accuracy: 0.8605 - val_loss: 0.3584 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3971 - accuracy: 0.8590 - val_loss: 0.3444 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3874 - accuracy: 0.8673 - val_loss: 0.3816 - val_accuracy: 0.8767 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3820 - accuracy: 0.8674 - val_loss: 0.3359 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3820 - accuracy: 0.8689 - val_loss: 0.3607 - val_accuracy: 0.8803 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3854 - accuracy: 0.8655 - val_loss: 0.4414 - val_accuracy: 0.8546 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3760 - accuracy: 0.8708 - val_loss: 0.3420 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3798 - accuracy: 0.8694 - val_loss: 0.3546 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3716 - accuracy: 0.8696 - val_loss: 0.3718 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3764 - accuracy: 0.8679 - val_loss: 0.3518 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3721 - accuracy: 0.8704 - val_loss: 0.3484 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3696 - accuracy: 0.8722 - val_loss: 0.3395 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3740 - accuracy: 0.8700 - val_loss: 0.3543 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3709 - accuracy: 0.8732 - val_loss: 0.3782 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3663 - accuracy: 0.8745 - val_loss: 0.3237 - val_accuracy: 0.8983 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3597 - accuracy: 0.8798 - val_loss: 0.3339 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3612 - accuracy: 0.8793 - val_loss: 0.3355 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3660 - accuracy: 0.8764 - val_loss: 0.3342 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3630 - accuracy: 0.8720 - val_loss: 0.3238 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3657 - accuracy: 0.8709 - val_loss: 0.3332 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3674 - accuracy: 0.8754 - val_loss: 0.3365 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3678 - accuracy: 0.8749 - val_loss: 0.3302 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3610 - accuracy: 0.8729 - val_loss: 0.3278 - val_accuracy: 0.8987 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3564 - accuracy: 0.8762 - val_loss: 0.3258 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3577 - accuracy: 0.8756 - val_loss: 0.3433 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3616 - accuracy: 0.8761 - val_loss: 0.3268 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3538 - accuracy: 0.8796 - val_loss: 0.3522 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 4s 47ms/step - loss: 0.3548 - accuracy: 0.8778 - val_loss: 0.3352 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3596 - accuracy: 0.8750 - val_loss: 0.3336 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3619 - accuracy: 0.8730 - val_loss: 0.3301 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3571 - accuracy: 0.8776 - val_loss: 0.3278 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3550 - accuracy: 0.8749 - val_loss: 0.3217 - val_accuracy: 0.8999 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3543 - accuracy: 0.8784 - val_loss: 0.3128 - val_accuracy: 0.9003 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3536 - accuracy: 0.8780 - val_loss: 0.3420 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3589 - accuracy: 0.8785 - val_loss: 0.3271 - val_accuracy: 0.8999 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3550 - accuracy: 0.8796 - val_loss: 0.3291 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3619 - accuracy: 0.8729 - val_loss: 0.3125 - val_accuracy: 0.9009 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3524 - accuracy: 0.8779 - val_loss: 0.3179 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3532 - accuracy: 0.8765 - val_loss: 0.3303 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3538 - accuracy: 0.8776 - val_loss: 0.3295 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3569 - accuracy: 0.8777 - val_loss: 0.3274 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3616 - accuracy: 0.8773 - val_loss: 0.3483 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3496 - accuracy: 0.8782 - val_loss: 0.3242 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3523 - accuracy: 0.8767 - val_loss: 0.3107 - val_accuracy: 0.9035 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3496 - accuracy: 0.8781 - val_loss: 0.3128 - val_accuracy: 0.9007 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3394 - accuracy: 0.8853 - val_loss: 0.3134 - val_accuracy: 0.9009 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3336 - accuracy: 0.8861 - val_loss: 0.3111 - val_accuracy: 0.9029 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3366 - accuracy: 0.8812 - val_loss: 0.3102 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3352 - accuracy: 0.8829 - val_loss: 0.3103 - val_accuracy: 0.9007 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3305 - accuracy: 0.8836 - val_loss: 0.3091 - val_accuracy: 0.9009 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3370 - accuracy: 0.8824 - val_loss: 0.3065 - val_accuracy: 0.9017 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3366 - accuracy: 0.8790 - val_loss: 0.3045 - val_accuracy: 0.9035 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3315 - accuracy: 0.8834 - val_loss: 0.3030 - val_accuracy: 0.9029 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3292 - accuracy: 0.8854 - val_loss: 0.3034 - val_accuracy: 0.9035 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3224 - accuracy: 0.8879 - val_loss: 0.3043 - val_accuracy: 0.9023 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3283 - accuracy: 0.8834 - val_loss: 0.3046 - val_accuracy: 0.9021 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3258 - accuracy: 0.8829 - val_loss: 0.3046 - val_accuracy: 0.9025 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3241 - accuracy: 0.8872 - val_loss: 0.3053 - val_accuracy: 0.9027 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3234 - accuracy: 0.8880 - val_loss: 0.3049 - val_accuracy: 0.9025 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3257 - accuracy: 0.8854 - val_loss: 0.3043 - val_accuracy: 0.9019 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3203 - accuracy: 0.8866 - val_loss: 0.3046 - val_accuracy: 0.9021 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3254 - accuracy: 0.8873 - val_loss: 0.3046 - val_accuracy: 0.9027 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3249 - accuracy: 0.8860 - val_loss: 0.3044 - val_accuracy: 0.9023 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 5s 49ms/step - loss: 0.3227 - accuracy: 0.8861 - val_loss: 0.3045 - val_accuracy: 0.9021 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 4s 49ms/step - loss: 0.3284 - accuracy: 0.8824 - val_loss: 0.3048 - val_accuracy: 0.9023 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3231 - accuracy: 0.8875 - val_loss: 0.3048 - val_accuracy: 0.9023 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.3269 - accuracy: 0.8854 - val_loss: 0.3046 - val_accuracy: 0.9023 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3255 - accuracy: 0.8855 - val_loss: 0.3044 - val_accuracy: 0.9023 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3229 - accuracy: 0.8845 - val_loss: 0.3046 - val_accuracy: 0.9023 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3208 - accuracy: 0.8873 - val_loss: 0.3047 - val_accuracy: 0.9021 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 0.3211 - accuracy: 0.8891 - val_loss: 0.3045 - val_accuracy: 0.9023 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 0.3254 - accuracy: 0.8866 - val_loss: 0.3045 - val_accuracy: 0.9023 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 5s 51ms/step - loss: 0.3241 - accuracy: 0.8843 - val_loss: 0.3045 - val_accuracy: 0.9023 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 7s 14ms/step - loss: 0.2741 - accuracy: 0.9072\n",
      "17/17 [==============================] - 1s 14ms/step\n",
      "TP:5646, TN:9727, FP:728, FN:845, loss0.2740961015224457, acc0.9071757346866517, sn0.8698197504236636, sp0.9303682448589192, f10.8777302759424797, auc0.9636642900544113\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 28s 66ms/step - loss: 1.9077 - accuracy: 0.5768 - val_loss: 1.7676 - val_accuracy: 0.4085 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 5s 50ms/step - loss: 1.5729 - accuracy: 0.6201 - val_loss: 1.5929 - val_accuracy: 0.4310 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 4s 48ms/step - loss: 1.3666 - accuracy: 0.6518 - val_loss: 1.4404 - val_accuracy: 0.4210 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 1.2035 - accuracy: 0.6672 - val_loss: 1.3126 - val_accuracy: 0.4079 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 1.0748 - accuracy: 0.6790 - val_loss: 1.2036 - val_accuracy: 0.4388 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.9727 - accuracy: 0.6875 - val_loss: 1.1264 - val_accuracy: 0.4874 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.8872 - accuracy: 0.7044 - val_loss: 1.0579 - val_accuracy: 0.5371 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.8250 - accuracy: 0.7074 - val_loss: 0.9663 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.7658 - accuracy: 0.7217 - val_loss: 0.9021 - val_accuracy: 0.6009 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.7208 - accuracy: 0.7331 - val_loss: 0.8556 - val_accuracy: 0.6342 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.6723 - accuracy: 0.7494 - val_loss: 0.7803 - val_accuracy: 0.6823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.6358 - accuracy: 0.7607 - val_loss: 0.7237 - val_accuracy: 0.7012 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.6055 - accuracy: 0.7710 - val_loss: 0.6260 - val_accuracy: 0.7487 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.5858 - accuracy: 0.7795 - val_loss: 0.5831 - val_accuracy: 0.7669 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.5619 - accuracy: 0.7866 - val_loss: 0.5975 - val_accuracy: 0.7529 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.5403 - accuracy: 0.7987 - val_loss: 0.5233 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.5187 - accuracy: 0.8108 - val_loss: 0.5128 - val_accuracy: 0.8109 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.5016 - accuracy: 0.8190 - val_loss: 0.5240 - val_accuracy: 0.8167 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.4792 - accuracy: 0.8288 - val_loss: 0.4701 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.4733 - accuracy: 0.8327 - val_loss: 0.4342 - val_accuracy: 0.8560 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.4578 - accuracy: 0.8399 - val_loss: 0.4929 - val_accuracy: 0.8291 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.4445 - accuracy: 0.8448 - val_loss: 0.4291 - val_accuracy: 0.8558 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.4401 - accuracy: 0.8438 - val_loss: 0.3951 - val_accuracy: 0.8759 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.4305 - accuracy: 0.8511 - val_loss: 0.3980 - val_accuracy: 0.8751 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.3873 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.4211 - accuracy: 0.8543 - val_loss: 0.4071 - val_accuracy: 0.8738 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4168 - accuracy: 0.8551 - val_loss: 0.4232 - val_accuracy: 0.8680 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 0.4108 - accuracy: 0.8586 - val_loss: 0.3867 - val_accuracy: 0.8821 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4060 - accuracy: 0.8548 - val_loss: 0.3863 - val_accuracy: 0.8676 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.4021 - accuracy: 0.8613 - val_loss: 0.3644 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.4034 - accuracy: 0.8610 - val_loss: 0.3722 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3960 - accuracy: 0.8667 - val_loss: 0.3738 - val_accuracy: 0.8837 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3977 - accuracy: 0.8633 - val_loss: 0.3881 - val_accuracy: 0.8801 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3941 - accuracy: 0.8627 - val_loss: 0.3605 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3918 - accuracy: 0.8679 - val_loss: 0.3602 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3833 - accuracy: 0.8699 - val_loss: 0.3433 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3832 - accuracy: 0.8680 - val_loss: 0.3530 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3837 - accuracy: 0.8691 - val_loss: 0.3504 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3832 - accuracy: 0.8678 - val_loss: 0.3576 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3857 - accuracy: 0.8663 - val_loss: 0.3470 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3800 - accuracy: 0.8675 - val_loss: 0.3555 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3786 - accuracy: 0.8707 - val_loss: 0.3517 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3734 - accuracy: 0.8750 - val_loss: 0.3615 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3760 - accuracy: 0.8708 - val_loss: 0.3612 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3806 - accuracy: 0.8695 - val_loss: 0.3607 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3758 - accuracy: 0.8702 - val_loss: 0.3374 - val_accuracy: 0.8955 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3747 - accuracy: 0.8696 - val_loss: 0.3858 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3696 - accuracy: 0.8767 - val_loss: 0.3683 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3695 - accuracy: 0.8757 - val_loss: 0.3347 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3744 - accuracy: 0.8731 - val_loss: 0.3485 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3660 - accuracy: 0.8726 - val_loss: 0.3455 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3704 - accuracy: 0.8713 - val_loss: 0.3421 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3683 - accuracy: 0.8727 - val_loss: 0.3273 - val_accuracy: 0.8977 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3662 - accuracy: 0.8766 - val_loss: 0.3392 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3671 - accuracy: 0.8749 - val_loss: 0.3456 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3639 - accuracy: 0.8732 - val_loss: 0.3594 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3690 - accuracy: 0.8766 - val_loss: 0.3307 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3653 - accuracy: 0.8717 - val_loss: 0.3395 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3662 - accuracy: 0.8739 - val_loss: 0.3325 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3620 - accuracy: 0.8744 - val_loss: 0.3457 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3699 - accuracy: 0.8748 - val_loss: 0.3265 - val_accuracy: 0.8969 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3682 - accuracy: 0.8708 - val_loss: 0.3535 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3620 - accuracy: 0.8772 - val_loss: 0.3605 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3623 - accuracy: 0.8720 - val_loss: 0.3380 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3567 - accuracy: 0.8765 - val_loss: 0.3335 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3610 - accuracy: 0.8784 - val_loss: 0.3384 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3578 - accuracy: 0.8781 - val_loss: 0.3220 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3605 - accuracy: 0.8746 - val_loss: 0.3306 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3637 - accuracy: 0.8742 - val_loss: 0.3303 - val_accuracy: 0.8965 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3527 - accuracy: 0.8810 - val_loss: 0.3352 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3641 - accuracy: 0.8743 - val_loss: 0.3338 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3541 - accuracy: 0.8790 - val_loss: 0.3249 - val_accuracy: 0.8967 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3479 - accuracy: 0.8803 - val_loss: 0.3256 - val_accuracy: 0.8949 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3400 - accuracy: 0.8819 - val_loss: 0.3260 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3437 - accuracy: 0.8816 - val_loss: 0.3231 - val_accuracy: 0.8991 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3449 - accuracy: 0.8807 - val_loss: 0.3222 - val_accuracy: 0.8985 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3393 - accuracy: 0.8772 - val_loss: 0.3194 - val_accuracy: 0.8987 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3327 - accuracy: 0.8855 - val_loss: 0.3188 - val_accuracy: 0.8979 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3386 - accuracy: 0.8811 - val_loss: 0.3154 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3346 - accuracy: 0.8814 - val_loss: 0.3177 - val_accuracy: 0.8993 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3318 - accuracy: 0.8829 - val_loss: 0.3168 - val_accuracy: 0.8987 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3334 - accuracy: 0.8847 - val_loss: 0.3153 - val_accuracy: 0.8989 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3311 - accuracy: 0.8853 - val_loss: 0.3163 - val_accuracy: 0.8989 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3286 - accuracy: 0.8859 - val_loss: 0.3155 - val_accuracy: 0.8983 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3294 - accuracy: 0.8811 - val_loss: 0.3157 - val_accuracy: 0.8985 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3281 - accuracy: 0.8849 - val_loss: 0.3156 - val_accuracy: 0.8995 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3260 - accuracy: 0.8903 - val_loss: 0.3157 - val_accuracy: 0.8993 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3333 - accuracy: 0.8855 - val_loss: 0.3147 - val_accuracy: 0.8987 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3329 - accuracy: 0.8838 - val_loss: 0.3149 - val_accuracy: 0.8989 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3312 - accuracy: 0.8861 - val_loss: 0.3145 - val_accuracy: 0.8989 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3319 - accuracy: 0.8852 - val_loss: 0.3135 - val_accuracy: 0.8995 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3270 - accuracy: 0.8865 - val_loss: 0.3138 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3310 - accuracy: 0.8877 - val_loss: 0.3140 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3320 - accuracy: 0.8829 - val_loss: 0.3138 - val_accuracy: 0.8991 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3290 - accuracy: 0.8863 - val_loss: 0.3138 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3290 - accuracy: 0.8841 - val_loss: 0.3139 - val_accuracy: 0.8995 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3318 - accuracy: 0.8853 - val_loss: 0.3140 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3295 - accuracy: 0.8877 - val_loss: 0.3140 - val_accuracy: 0.8991 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3263 - accuracy: 0.8857 - val_loss: 0.3142 - val_accuracy: 0.8991 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3239 - accuracy: 0.8866 - val_loss: 0.3144 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 4s 7ms/step - loss: 0.2814 - accuracy: 0.9052\n",
      "17/17 [==============================] - 1s 7ms/step\n",
      "TP:5655, TN:9684, FP:771, FN:836, loss0.2814459800720215, acc0.9051693615012393, sn0.8712062856262517, sp0.9262553802008608, f10.8755903073469071, auc0.9628093815805441\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 19s 33ms/step - loss: 1.8880 - accuracy: 0.5708 - val_loss: 1.7506 - val_accuracy: 0.3887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 1.5558 - accuracy: 0.6126 - val_loss: 1.5286 - val_accuracy: 0.4192 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 1.3425 - accuracy: 0.6257 - val_loss: 1.3315 - val_accuracy: 0.5030 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 1.1757 - accuracy: 0.6495 - val_loss: 1.1798 - val_accuracy: 0.5536 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.0462 - accuracy: 0.6642 - val_loss: 1.0675 - val_accuracy: 0.6035 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.9428 - accuracy: 0.6765 - val_loss: 0.9712 - val_accuracy: 0.6099 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.8621 - accuracy: 0.6929 - val_loss: 0.8107 - val_accuracy: 0.7325 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.7834 - accuracy: 0.7142 - val_loss: 0.7435 - val_accuracy: 0.7435 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.7117 - accuracy: 0.7493 - val_loss: 0.6513 - val_accuracy: 0.7828 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.6519 - accuracy: 0.7685 - val_loss: 0.6067 - val_accuracy: 0.7880 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.6110 - accuracy: 0.7849 - val_loss: 0.5737 - val_accuracy: 0.7994 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.5749 - accuracy: 0.7979 - val_loss: 0.5505 - val_accuracy: 0.8020 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.5389 - accuracy: 0.8132 - val_loss: 0.5076 - val_accuracy: 0.8339 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.5194 - accuracy: 0.8183 - val_loss: 0.4848 - val_accuracy: 0.8420 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.4857 - accuracy: 0.8334 - val_loss: 0.4709 - val_accuracy: 0.8488 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.4728 - accuracy: 0.8401 - val_loss: 0.4392 - val_accuracy: 0.8606 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.4569 - accuracy: 0.8417 - val_loss: 0.4080 - val_accuracy: 0.8740 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.4453 - accuracy: 0.8481 - val_loss: 0.4247 - val_accuracy: 0.8656 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.4329 - accuracy: 0.8546 - val_loss: 0.4307 - val_accuracy: 0.8620 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.4281 - accuracy: 0.8565 - val_loss: 0.4282 - val_accuracy: 0.8660 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.4210 - accuracy: 0.8584 - val_loss: 0.4196 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.4118 - accuracy: 0.8596 - val_loss: 0.3715 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.4126 - accuracy: 0.8620 - val_loss: 0.3781 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.4144 - accuracy: 0.8571 - val_loss: 0.4090 - val_accuracy: 0.8672 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.4019 - accuracy: 0.8620 - val_loss: 0.3729 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3998 - accuracy: 0.8630 - val_loss: 0.4276 - val_accuracy: 0.8628 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3991 - accuracy: 0.8614 - val_loss: 0.3544 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3946 - accuracy: 0.8625 - val_loss: 0.3575 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3878 - accuracy: 0.8682 - val_loss: 0.3796 - val_accuracy: 0.8795 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3968 - accuracy: 0.8648 - val_loss: 0.3737 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3898 - accuracy: 0.8677 - val_loss: 0.3604 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3865 - accuracy: 0.8677 - val_loss: 0.3539 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3822 - accuracy: 0.8685 - val_loss: 0.3523 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3870 - accuracy: 0.8651 - val_loss: 0.3416 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3862 - accuracy: 0.8686 - val_loss: 0.3735 - val_accuracy: 0.8805 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3807 - accuracy: 0.8688 - val_loss: 0.3708 - val_accuracy: 0.8813 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3797 - accuracy: 0.8715 - val_loss: 0.3619 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3771 - accuracy: 0.8698 - val_loss: 0.3515 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3823 - accuracy: 0.8679 - val_loss: 0.3704 - val_accuracy: 0.8787 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3809 - accuracy: 0.8711 - val_loss: 0.3515 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3717 - accuracy: 0.8733 - val_loss: 0.3458 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3740 - accuracy: 0.8696 - val_loss: 0.3394 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3773 - accuracy: 0.8737 - val_loss: 0.3363 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3676 - accuracy: 0.8760 - val_loss: 0.3318 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3747 - accuracy: 0.8695 - val_loss: 0.3741 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3805 - accuracy: 0.8673 - val_loss: 0.3285 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3670 - accuracy: 0.8765 - val_loss: 0.3332 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3716 - accuracy: 0.8702 - val_loss: 0.3335 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3646 - accuracy: 0.8762 - val_loss: 0.3430 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3680 - accuracy: 0.8725 - val_loss: 0.3292 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3644 - accuracy: 0.8738 - val_loss: 0.3355 - val_accuracy: 0.8965 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3715 - accuracy: 0.8691 - val_loss: 0.3275 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3677 - accuracy: 0.8729 - val_loss: 0.3401 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3669 - accuracy: 0.8735 - val_loss: 0.3611 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3688 - accuracy: 0.8717 - val_loss: 0.3349 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3655 - accuracy: 0.8740 - val_loss: 0.3440 - val_accuracy: 0.8995 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3611 - accuracy: 0.8740 - val_loss: 0.3386 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3594 - accuracy: 0.8767 - val_loss: 0.3266 - val_accuracy: 0.8971 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3634 - accuracy: 0.8741 - val_loss: 0.3319 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3653 - accuracy: 0.8756 - val_loss: 0.3254 - val_accuracy: 0.8989 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3634 - accuracy: 0.8778 - val_loss: 0.3385 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3579 - accuracy: 0.8761 - val_loss: 0.3533 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3568 - accuracy: 0.8775 - val_loss: 0.3385 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3650 - accuracy: 0.8737 - val_loss: 0.3253 - val_accuracy: 0.8955 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3647 - accuracy: 0.8749 - val_loss: 0.3417 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3623 - accuracy: 0.8749 - val_loss: 0.3327 - val_accuracy: 0.8955 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3550 - accuracy: 0.8756 - val_loss: 0.3478 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3672 - accuracy: 0.8709 - val_loss: 0.3202 - val_accuracy: 0.8979 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3607 - accuracy: 0.8769 - val_loss: 0.3356 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3576 - accuracy: 0.8739 - val_loss: 0.3397 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3629 - accuracy: 0.8743 - val_loss: 0.3381 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3462 - accuracy: 0.8830 - val_loss: 0.3274 - val_accuracy: 0.8961 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3428 - accuracy: 0.8810 - val_loss: 0.3219 - val_accuracy: 0.8979 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3404 - accuracy: 0.8859 - val_loss: 0.3183 - val_accuracy: 0.8979 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3453 - accuracy: 0.8806 - val_loss: 0.3164 - val_accuracy: 0.8967 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3379 - accuracy: 0.8854 - val_loss: 0.3144 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3399 - accuracy: 0.8822 - val_loss: 0.3131 - val_accuracy: 0.8987 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3370 - accuracy: 0.8857 - val_loss: 0.3119 - val_accuracy: 0.8989 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3376 - accuracy: 0.8815 - val_loss: 0.3121 - val_accuracy: 0.8985 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3315 - accuracy: 0.8854 - val_loss: 0.3147 - val_accuracy: 0.8987 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3348 - accuracy: 0.8845 - val_loss: 0.3118 - val_accuracy: 0.8989 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3287 - accuracy: 0.8866 - val_loss: 0.3121 - val_accuracy: 0.8999 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3317 - accuracy: 0.8834 - val_loss: 0.3122 - val_accuracy: 0.8991 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3281 - accuracy: 0.8847 - val_loss: 0.3133 - val_accuracy: 0.8995 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3281 - accuracy: 0.8855 - val_loss: 0.3129 - val_accuracy: 0.8995 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3297 - accuracy: 0.8840 - val_loss: 0.3128 - val_accuracy: 0.8993 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3323 - accuracy: 0.8836 - val_loss: 0.3126 - val_accuracy: 0.8991 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3302 - accuracy: 0.8850 - val_loss: 0.3123 - val_accuracy: 0.8995 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3348 - accuracy: 0.8803 - val_loss: 0.3120 - val_accuracy: 0.8995 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3284 - accuracy: 0.8830 - val_loss: 0.3119 - val_accuracy: 0.8995 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3293 - accuracy: 0.8843 - val_loss: 0.3115 - val_accuracy: 0.9001 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3282 - accuracy: 0.8861 - val_loss: 0.3122 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3226 - accuracy: 0.8868 - val_loss: 0.3123 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3281 - accuracy: 0.8849 - val_loss: 0.3122 - val_accuracy: 0.8991 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3239 - accuracy: 0.8868 - val_loss: 0.3119 - val_accuracy: 0.8999 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3322 - accuracy: 0.8857 - val_loss: 0.3122 - val_accuracy: 0.8989 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3295 - accuracy: 0.8839 - val_loss: 0.3120 - val_accuracy: 0.8999 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3269 - accuracy: 0.8873 - val_loss: 0.3124 - val_accuracy: 0.8997 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3253 - accuracy: 0.8853 - val_loss: 0.3122 - val_accuracy: 0.8991 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3293 - accuracy: 0.8836 - val_loss: 0.3123 - val_accuracy: 0.8995 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 10ms/step - loss: 0.2807 - accuracy: 0.9058\n",
      "17/17 [==============================] - 1s 9ms/step\n",
      "TP:5675, TN:9675, FP:780, FN:816, loss0.28070124983787537, acc0.9058184822376962, sn0.8742874749653367, sp0.9253945480631277, f10.8767186775838097, auc0.9630304064465967\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 23s 53ms/step - loss: 1.8730 - accuracy: 0.5775 - val_loss: 1.8282 - val_accuracy: 0.3885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 1.5479 - accuracy: 0.6198 - val_loss: 1.6781 - val_accuracy: 0.3885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 1.3259 - accuracy: 0.6418 - val_loss: 1.3814 - val_accuracy: 0.4507 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 1.1434 - accuracy: 0.6876 - val_loss: 1.1189 - val_accuracy: 0.6239 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.9864 - accuracy: 0.7279 - val_loss: 0.9148 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.8591 - accuracy: 0.7602 - val_loss: 0.8014 - val_accuracy: 0.7690 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.7770 - accuracy: 0.7697 - val_loss: 0.7006 - val_accuracy: 0.7934 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.7082 - accuracy: 0.7852 - val_loss: 0.6352 - val_accuracy: 0.8079 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.6421 - accuracy: 0.8031 - val_loss: 0.6028 - val_accuracy: 0.8203 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.5920 - accuracy: 0.8141 - val_loss: 0.5562 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.5560 - accuracy: 0.8240 - val_loss: 0.5364 - val_accuracy: 0.8375 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.5201 - accuracy: 0.8354 - val_loss: 0.5206 - val_accuracy: 0.8389 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4984 - accuracy: 0.8408 - val_loss: 0.4911 - val_accuracy: 0.8442 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.4745 - accuracy: 0.8470 - val_loss: 0.4511 - val_accuracy: 0.8592 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.4639 - accuracy: 0.8510 - val_loss: 0.4256 - val_accuracy: 0.8706 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.4475 - accuracy: 0.8546 - val_loss: 0.4197 - val_accuracy: 0.8740 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.4562 - accuracy: 0.8491 - val_loss: 0.4060 - val_accuracy: 0.8795 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.4302 - accuracy: 0.8612 - val_loss: 0.4467 - val_accuracy: 0.8614 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4291 - accuracy: 0.8579 - val_loss: 0.4034 - val_accuracy: 0.8765 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4213 - accuracy: 0.8600 - val_loss: 0.3879 - val_accuracy: 0.8775 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.4135 - accuracy: 0.8615 - val_loss: 0.3827 - val_accuracy: 0.8787 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.4233 - accuracy: 0.8596 - val_loss: 0.4208 - val_accuracy: 0.8660 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.4074 - accuracy: 0.8636 - val_loss: 0.3685 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.4135 - accuracy: 0.8608 - val_loss: 0.3928 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.4058 - accuracy: 0.8620 - val_loss: 0.3783 - val_accuracy: 0.8815 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4014 - accuracy: 0.8632 - val_loss: 0.3882 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3969 - accuracy: 0.8655 - val_loss: 0.4175 - val_accuracy: 0.8666 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3959 - accuracy: 0.8643 - val_loss: 0.3594 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3952 - accuracy: 0.8633 - val_loss: 0.3711 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3883 - accuracy: 0.8701 - val_loss: 0.3712 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3885 - accuracy: 0.8685 - val_loss: 0.3445 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3827 - accuracy: 0.8678 - val_loss: 0.3609 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3882 - accuracy: 0.8654 - val_loss: 0.3699 - val_accuracy: 0.8837 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3823 - accuracy: 0.8663 - val_loss: 0.3801 - val_accuracy: 0.8785 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3859 - accuracy: 0.8670 - val_loss: 0.3481 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3831 - accuracy: 0.8668 - val_loss: 0.3410 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3758 - accuracy: 0.8720 - val_loss: 0.3522 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3824 - accuracy: 0.8714 - val_loss: 0.3515 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3822 - accuracy: 0.8691 - val_loss: 0.3569 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3736 - accuracy: 0.8730 - val_loss: 0.3685 - val_accuracy: 0.8827 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3786 - accuracy: 0.8687 - val_loss: 0.3440 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3783 - accuracy: 0.8685 - val_loss: 0.3542 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3695 - accuracy: 0.8730 - val_loss: 0.3619 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3697 - accuracy: 0.8721 - val_loss: 0.3295 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3740 - accuracy: 0.8727 - val_loss: 0.3494 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3709 - accuracy: 0.8735 - val_loss: 0.3371 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3715 - accuracy: 0.8702 - val_loss: 0.3495 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3710 - accuracy: 0.8724 - val_loss: 0.3359 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3635 - accuracy: 0.8774 - val_loss: 0.3513 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3659 - accuracy: 0.8732 - val_loss: 0.3583 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3673 - accuracy: 0.8732 - val_loss: 0.3295 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3669 - accuracy: 0.8751 - val_loss: 0.3260 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3660 - accuracy: 0.8769 - val_loss: 0.3354 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3621 - accuracy: 0.8747 - val_loss: 0.3323 - val_accuracy: 0.8957 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3689 - accuracy: 0.8726 - val_loss: 0.3287 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3656 - accuracy: 0.8721 - val_loss: 0.3419 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3646 - accuracy: 0.8745 - val_loss: 0.3516 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3682 - accuracy: 0.8708 - val_loss: 0.3353 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3650 - accuracy: 0.8749 - val_loss: 0.3307 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3622 - accuracy: 0.8749 - val_loss: 0.3295 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3615 - accuracy: 0.8736 - val_loss: 0.3432 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3632 - accuracy: 0.8720 - val_loss: 0.3519 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3626 - accuracy: 0.8742 - val_loss: 0.3177 - val_accuracy: 0.8977 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3636 - accuracy: 0.8727 - val_loss: 0.3326 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3613 - accuracy: 0.8745 - val_loss: 0.3635 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3606 - accuracy: 0.8759 - val_loss: 0.3242 - val_accuracy: 0.8983 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3613 - accuracy: 0.8773 - val_loss: 0.3204 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3644 - accuracy: 0.8759 - val_loss: 0.3450 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3601 - accuracy: 0.8770 - val_loss: 0.3237 - val_accuracy: 0.8971 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3571 - accuracy: 0.8752 - val_loss: 0.3242 - val_accuracy: 0.8979 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3574 - accuracy: 0.8792 - val_loss: 0.3216 - val_accuracy: 0.8989 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3529 - accuracy: 0.8802 - val_loss: 0.3278 - val_accuracy: 0.8975 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3483 - accuracy: 0.8789 - val_loss: 0.3272 - val_accuracy: 0.8971 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3446 - accuracy: 0.8814 - val_loss: 0.3209 - val_accuracy: 0.8989 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3369 - accuracy: 0.8865 - val_loss: 0.3328 - val_accuracy: 0.8943 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3410 - accuracy: 0.8830 - val_loss: 0.3287 - val_accuracy: 0.8951 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3411 - accuracy: 0.8820 - val_loss: 0.3188 - val_accuracy: 0.8969 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3365 - accuracy: 0.8861 - val_loss: 0.3203 - val_accuracy: 0.8965 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3287 - accuracy: 0.8885 - val_loss: 0.3222 - val_accuracy: 0.8957 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3395 - accuracy: 0.8818 - val_loss: 0.3138 - val_accuracy: 0.9001 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3380 - accuracy: 0.8810 - val_loss: 0.3137 - val_accuracy: 0.8983 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3403 - accuracy: 0.8808 - val_loss: 0.3140 - val_accuracy: 0.8993 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3331 - accuracy: 0.8820 - val_loss: 0.3142 - val_accuracy: 0.8995 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3301 - accuracy: 0.8863 - val_loss: 0.3163 - val_accuracy: 0.8987 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3325 - accuracy: 0.8842 - val_loss: 0.3164 - val_accuracy: 0.8983 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3356 - accuracy: 0.8845 - val_loss: 0.3149 - val_accuracy: 0.8993 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3327 - accuracy: 0.8850 - val_loss: 0.3155 - val_accuracy: 0.8991 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3291 - accuracy: 0.8870 - val_loss: 0.3152 - val_accuracy: 0.8991 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3380 - accuracy: 0.8809 - val_loss: 0.3160 - val_accuracy: 0.8995 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3316 - accuracy: 0.8816 - val_loss: 0.3158 - val_accuracy: 0.8999 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3264 - accuracy: 0.8857 - val_loss: 0.3163 - val_accuracy: 0.8989 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3303 - accuracy: 0.8835 - val_loss: 0.3168 - val_accuracy: 0.8981 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3326 - accuracy: 0.8826 - val_loss: 0.3165 - val_accuracy: 0.8983 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3272 - accuracy: 0.8852 - val_loss: 0.3163 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3305 - accuracy: 0.8857 - val_loss: 0.3158 - val_accuracy: 0.8995 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3251 - accuracy: 0.8872 - val_loss: 0.3162 - val_accuracy: 0.8991 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3340 - accuracy: 0.8817 - val_loss: 0.3172 - val_accuracy: 0.8983 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3320 - accuracy: 0.8842 - val_loss: 0.3168 - val_accuracy: 0.8985 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3338 - accuracy: 0.8825 - val_loss: 0.3166 - val_accuracy: 0.8987 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3319 - accuracy: 0.8849 - val_loss: 0.3165 - val_accuracy: 0.8985 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 9ms/step - loss: 0.2863 - accuracy: 0.9041\n",
      "17/17 [==============================] - 1s 8ms/step\n",
      "TP:5766, TN:9555, FP:900, FN:725, loss0.2863132059574127, acc0.9041071639324915, sn0.8883068864581729, sp0.9139167862266858, f10.8764916014288971, auc0.9635502963637029\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 21s 48ms/step - loss: 1.9120 - accuracy: 0.5636 - val_loss: 1.6783 - val_accuracy: 0.6276 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 1.5780 - accuracy: 0.6053 - val_loss: 1.4984 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 1.3683 - accuracy: 0.6219 - val_loss: 1.3195 - val_accuracy: 0.5987 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 1.1849 - accuracy: 0.6666 - val_loss: 1.1559 - val_accuracy: 0.5991 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 1.0054 - accuracy: 0.7253 - val_loss: 1.0224 - val_accuracy: 0.6865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.8683 - accuracy: 0.7678 - val_loss: 0.8403 - val_accuracy: 0.7661 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.7772 - accuracy: 0.7840 - val_loss: 0.6965 - val_accuracy: 0.8083 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.7026 - accuracy: 0.8002 - val_loss: 0.6448 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.6511 - accuracy: 0.8031 - val_loss: 0.5941 - val_accuracy: 0.8323 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.5940 - accuracy: 0.8184 - val_loss: 0.5561 - val_accuracy: 0.8371 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.5688 - accuracy: 0.8214 - val_loss: 0.5414 - val_accuracy: 0.8335 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.5281 - accuracy: 0.8332 - val_loss: 0.5187 - val_accuracy: 0.8404 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.5180 - accuracy: 0.8311 - val_loss: 0.4968 - val_accuracy: 0.8428 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.4822 - accuracy: 0.8464 - val_loss: 0.4798 - val_accuracy: 0.8480 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4698 - accuracy: 0.8499 - val_loss: 0.4562 - val_accuracy: 0.8570 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.4633 - accuracy: 0.8466 - val_loss: 0.4554 - val_accuracy: 0.8596 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.4426 - accuracy: 0.8535 - val_loss: 0.4241 - val_accuracy: 0.8692 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.4404 - accuracy: 0.8569 - val_loss: 0.4146 - val_accuracy: 0.8698 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.4276 - accuracy: 0.8588 - val_loss: 0.3986 - val_accuracy: 0.8821 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4143 - accuracy: 0.8636 - val_loss: 0.3818 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4159 - accuracy: 0.8605 - val_loss: 0.3706 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4098 - accuracy: 0.8615 - val_loss: 0.4118 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4095 - accuracy: 0.8641 - val_loss: 0.3875 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4002 - accuracy: 0.8652 - val_loss: 0.3960 - val_accuracy: 0.8781 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3997 - accuracy: 0.8660 - val_loss: 0.3767 - val_accuracy: 0.8815 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3954 - accuracy: 0.8696 - val_loss: 0.3938 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3875 - accuracy: 0.8690 - val_loss: 0.3644 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3900 - accuracy: 0.8665 - val_loss: 0.3597 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3914 - accuracy: 0.8662 - val_loss: 0.3551 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3860 - accuracy: 0.8679 - val_loss: 0.3835 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3932 - accuracy: 0.8656 - val_loss: 0.3570 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3833 - accuracy: 0.8696 - val_loss: 0.3523 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3835 - accuracy: 0.8690 - val_loss: 0.3517 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3873 - accuracy: 0.8673 - val_loss: 0.3775 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3823 - accuracy: 0.8714 - val_loss: 0.3497 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3779 - accuracy: 0.8754 - val_loss: 0.3471 - val_accuracy: 0.8935 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3848 - accuracy: 0.8687 - val_loss: 0.3508 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3788 - accuracy: 0.8701 - val_loss: 0.3375 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3729 - accuracy: 0.8729 - val_loss: 0.3512 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3753 - accuracy: 0.8742 - val_loss: 0.3342 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3782 - accuracy: 0.8720 - val_loss: 0.3443 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3702 - accuracy: 0.8725 - val_loss: 0.3412 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3821 - accuracy: 0.8679 - val_loss: 0.3544 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3645 - accuracy: 0.8747 - val_loss: 0.3283 - val_accuracy: 0.8965 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3697 - accuracy: 0.8742 - val_loss: 0.3417 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3670 - accuracy: 0.8737 - val_loss: 0.3464 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3656 - accuracy: 0.8772 - val_loss: 0.3418 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3729 - accuracy: 0.8700 - val_loss: 0.3397 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3680 - accuracy: 0.8746 - val_loss: 0.3217 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3711 - accuracy: 0.8715 - val_loss: 0.3356 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3608 - accuracy: 0.8780 - val_loss: 0.3372 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3668 - accuracy: 0.8743 - val_loss: 0.3473 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3653 - accuracy: 0.8758 - val_loss: 0.3327 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3615 - accuracy: 0.8758 - val_loss: 0.3723 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3624 - accuracy: 0.8763 - val_loss: 0.3287 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3692 - accuracy: 0.8713 - val_loss: 0.3420 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3613 - accuracy: 0.8756 - val_loss: 0.3338 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3600 - accuracy: 0.8779 - val_loss: 0.3316 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3651 - accuracy: 0.8743 - val_loss: 0.3496 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3605 - accuracy: 0.8742 - val_loss: 0.3347 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3584 - accuracy: 0.8766 - val_loss: 0.3308 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3585 - accuracy: 0.8791 - val_loss: 0.3273 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3601 - accuracy: 0.8777 - val_loss: 0.3489 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3593 - accuracy: 0.8755 - val_loss: 0.3323 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3544 - accuracy: 0.8783 - val_loss: 0.3386 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3622 - accuracy: 0.8763 - val_loss: 0.3322 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3704 - accuracy: 0.8720 - val_loss: 0.3286 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3559 - accuracy: 0.8786 - val_loss: 0.3324 - val_accuracy: 0.8969 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3534 - accuracy: 0.8779 - val_loss: 0.3357 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3544 - accuracy: 0.8811 - val_loss: 0.3377 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3601 - accuracy: 0.8760 - val_loss: 0.3315 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3494 - accuracy: 0.8780 - val_loss: 0.3240 - val_accuracy: 0.8935 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3457 - accuracy: 0.8820 - val_loss: 0.3230 - val_accuracy: 0.8971 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3457 - accuracy: 0.8820 - val_loss: 0.3190 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3404 - accuracy: 0.8845 - val_loss: 0.3191 - val_accuracy: 0.8989 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3411 - accuracy: 0.8824 - val_loss: 0.3155 - val_accuracy: 0.8965 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3308 - accuracy: 0.8852 - val_loss: 0.3159 - val_accuracy: 0.8991 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3407 - accuracy: 0.8800 - val_loss: 0.3112 - val_accuracy: 0.8995 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3339 - accuracy: 0.8851 - val_loss: 0.3160 - val_accuracy: 0.8991 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3300 - accuracy: 0.8842 - val_loss: 0.3124 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3340 - accuracy: 0.8816 - val_loss: 0.3117 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3308 - accuracy: 0.8840 - val_loss: 0.3131 - val_accuracy: 0.8995 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3323 - accuracy: 0.8813 - val_loss: 0.3131 - val_accuracy: 0.9007 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3299 - accuracy: 0.8845 - val_loss: 0.3137 - val_accuracy: 0.8997 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3270 - accuracy: 0.8868 - val_loss: 0.3131 - val_accuracy: 0.9007 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3287 - accuracy: 0.8819 - val_loss: 0.3119 - val_accuracy: 0.9003 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3290 - accuracy: 0.8830 - val_loss: 0.3123 - val_accuracy: 0.9007 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3298 - accuracy: 0.8837 - val_loss: 0.3128 - val_accuracy: 0.8999 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3290 - accuracy: 0.8861 - val_loss: 0.3120 - val_accuracy: 0.9007 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3278 - accuracy: 0.8888 - val_loss: 0.3121 - val_accuracy: 0.8999 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3301 - accuracy: 0.8853 - val_loss: 0.3120 - val_accuracy: 0.9003 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3308 - accuracy: 0.8857 - val_loss: 0.3117 - val_accuracy: 0.8997 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3304 - accuracy: 0.8871 - val_loss: 0.3121 - val_accuracy: 0.8999 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3312 - accuracy: 0.8827 - val_loss: 0.3117 - val_accuracy: 0.9003 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3299 - accuracy: 0.8856 - val_loss: 0.3122 - val_accuracy: 0.8997 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.3285 - accuracy: 0.8834 - val_loss: 0.3117 - val_accuracy: 0.8999 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3275 - accuracy: 0.8866 - val_loss: 0.3117 - val_accuracy: 0.9003 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3309 - accuracy: 0.8836 - val_loss: 0.3120 - val_accuracy: 0.8999 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3287 - accuracy: 0.8833 - val_loss: 0.3117 - val_accuracy: 0.9001 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3330 - accuracy: 0.8849 - val_loss: 0.3120 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 10ms/step - loss: 0.2797 - accuracy: 0.9055\n",
      "17/17 [==============================] - 1s 9ms/step\n",
      "TP:5589, TN:9756, FP:699, FN:902, loss0.27965813875198364, acc0.9055234273574885, sn0.8610383608072716, sp0.9331420373027259, f10.8747163314813365, auc0.9625117395745174\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 22s 50ms/step - loss: 1.9142 - accuracy: 0.5640 - val_loss: 1.7100 - val_accuracy: 0.5479 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 1.5738 - accuracy: 0.6036 - val_loss: 1.5343 - val_accuracy: 0.4384 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 1.3767 - accuracy: 0.6200 - val_loss: 1.3511 - val_accuracy: 0.5058 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 1.2004 - accuracy: 0.6454 - val_loss: 1.1825 - val_accuracy: 0.5931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 1.0390 - accuracy: 0.6958 - val_loss: 1.0028 - val_accuracy: 0.7004 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.8881 - accuracy: 0.7490 - val_loss: 0.8662 - val_accuracy: 0.7553 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.7883 - accuracy: 0.7765 - val_loss: 0.7101 - val_accuracy: 0.8045 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.7152 - accuracy: 0.7928 - val_loss: 0.6486 - val_accuracy: 0.8157 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.6604 - accuracy: 0.8026 - val_loss: 0.6027 - val_accuracy: 0.8325 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.6170 - accuracy: 0.8106 - val_loss: 0.5650 - val_accuracy: 0.8357 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.5725 - accuracy: 0.8279 - val_loss: 0.5414 - val_accuracy: 0.8404 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.5421 - accuracy: 0.8333 - val_loss: 0.5029 - val_accuracy: 0.8500 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.5170 - accuracy: 0.8333 - val_loss: 0.4775 - val_accuracy: 0.8600 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4926 - accuracy: 0.8423 - val_loss: 0.4977 - val_accuracy: 0.8498 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.4745 - accuracy: 0.8471 - val_loss: 0.4581 - val_accuracy: 0.8598 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.4640 - accuracy: 0.8490 - val_loss: 0.4226 - val_accuracy: 0.8744 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.4481 - accuracy: 0.8535 - val_loss: 0.4294 - val_accuracy: 0.8716 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.4376 - accuracy: 0.8561 - val_loss: 0.4170 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4334 - accuracy: 0.8560 - val_loss: 0.4078 - val_accuracy: 0.8742 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.4272 - accuracy: 0.8548 - val_loss: 0.3947 - val_accuracy: 0.8801 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.4181 - accuracy: 0.8595 - val_loss: 0.4019 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.4139 - accuracy: 0.8626 - val_loss: 0.4091 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.4113 - accuracy: 0.8614 - val_loss: 0.3639 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4062 - accuracy: 0.8611 - val_loss: 0.3602 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.4023 - accuracy: 0.8654 - val_loss: 0.3592 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3962 - accuracy: 0.8623 - val_loss: 0.3694 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3914 - accuracy: 0.8663 - val_loss: 0.3579 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3928 - accuracy: 0.8658 - val_loss: 0.3546 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3935 - accuracy: 0.8662 - val_loss: 0.3574 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3909 - accuracy: 0.8661 - val_loss: 0.3933 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3879 - accuracy: 0.8649 - val_loss: 0.3436 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3843 - accuracy: 0.8686 - val_loss: 0.3526 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3818 - accuracy: 0.8702 - val_loss: 0.3433 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3831 - accuracy: 0.8673 - val_loss: 0.3791 - val_accuracy: 0.8801 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3819 - accuracy: 0.8670 - val_loss: 0.3513 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3784 - accuracy: 0.8702 - val_loss: 0.4030 - val_accuracy: 0.8710 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3879 - accuracy: 0.8655 - val_loss: 0.3346 - val_accuracy: 0.8935 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3707 - accuracy: 0.8744 - val_loss: 0.3553 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3817 - accuracy: 0.8687 - val_loss: 0.3869 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3712 - accuracy: 0.8718 - val_loss: 0.3380 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3732 - accuracy: 0.8696 - val_loss: 0.3263 - val_accuracy: 0.8965 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3731 - accuracy: 0.8689 - val_loss: 0.3489 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3779 - accuracy: 0.8720 - val_loss: 0.3410 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3824 - accuracy: 0.8688 - val_loss: 0.3544 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3652 - accuracy: 0.8779 - val_loss: 0.3358 - val_accuracy: 0.8965 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3645 - accuracy: 0.8750 - val_loss: 0.3392 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3746 - accuracy: 0.8688 - val_loss: 0.3291 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3641 - accuracy: 0.8717 - val_loss: 0.3420 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3655 - accuracy: 0.8727 - val_loss: 0.3268 - val_accuracy: 0.8957 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3616 - accuracy: 0.8782 - val_loss: 0.3319 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3620 - accuracy: 0.8713 - val_loss: 0.3653 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3630 - accuracy: 0.8764 - val_loss: 0.3561 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3614 - accuracy: 0.8790 - val_loss: 0.3498 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3676 - accuracy: 0.8727 - val_loss: 0.3545 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3678 - accuracy: 0.8726 - val_loss: 0.3334 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3742 - accuracy: 0.8682 - val_loss: 0.3363 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3662 - accuracy: 0.8730 - val_loss: 0.3267 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3683 - accuracy: 0.8687 - val_loss: 0.3417 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3630 - accuracy: 0.8739 - val_loss: 0.3288 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3619 - accuracy: 0.8736 - val_loss: 0.3594 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3636 - accuracy: 0.8715 - val_loss: 0.3450 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3569 - accuracy: 0.8754 - val_loss: 0.3329 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3557 - accuracy: 0.8758 - val_loss: 0.3509 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3670 - accuracy: 0.8739 - val_loss: 0.3271 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3598 - accuracy: 0.8756 - val_loss: 0.3325 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3556 - accuracy: 0.8756 - val_loss: 0.3479 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3598 - accuracy: 0.8744 - val_loss: 0.3307 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3581 - accuracy: 0.8765 - val_loss: 0.3232 - val_accuracy: 0.8987 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3573 - accuracy: 0.8767 - val_loss: 0.3560 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3584 - accuracy: 0.8763 - val_loss: 0.3304 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3580 - accuracy: 0.8759 - val_loss: 0.3217 - val_accuracy: 0.8993 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3518 - accuracy: 0.8777 - val_loss: 0.3190 - val_accuracy: 0.8991 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3426 - accuracy: 0.8822 - val_loss: 0.3202 - val_accuracy: 0.8991 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3434 - accuracy: 0.8815 - val_loss: 0.3205 - val_accuracy: 0.8971 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3413 - accuracy: 0.8791 - val_loss: 0.3177 - val_accuracy: 0.8967 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3421 - accuracy: 0.8837 - val_loss: 0.3139 - val_accuracy: 0.8989 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3415 - accuracy: 0.8819 - val_loss: 0.3111 - val_accuracy: 0.8991 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3341 - accuracy: 0.8849 - val_loss: 0.3146 - val_accuracy: 0.8963 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3399 - accuracy: 0.8824 - val_loss: 0.3100 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3341 - accuracy: 0.8832 - val_loss: 0.3165 - val_accuracy: 0.8979 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3273 - accuracy: 0.8867 - val_loss: 0.3109 - val_accuracy: 0.9011 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3324 - accuracy: 0.8855 - val_loss: 0.3122 - val_accuracy: 0.9001 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3336 - accuracy: 0.8817 - val_loss: 0.3122 - val_accuracy: 0.8999 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3295 - accuracy: 0.8856 - val_loss: 0.3133 - val_accuracy: 0.8991 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3325 - accuracy: 0.8826 - val_loss: 0.3132 - val_accuracy: 0.8987 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3315 - accuracy: 0.8836 - val_loss: 0.3124 - val_accuracy: 0.8993 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3313 - accuracy: 0.8858 - val_loss: 0.3115 - val_accuracy: 0.8995 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3310 - accuracy: 0.8862 - val_loss: 0.3117 - val_accuracy: 0.8991 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3330 - accuracy: 0.8834 - val_loss: 0.3117 - val_accuracy: 0.8993 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3311 - accuracy: 0.8847 - val_loss: 0.3106 - val_accuracy: 0.8989 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3274 - accuracy: 0.8854 - val_loss: 0.3114 - val_accuracy: 0.8991 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3270 - accuracy: 0.8838 - val_loss: 0.3118 - val_accuracy: 0.8989 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3288 - accuracy: 0.8855 - val_loss: 0.3118 - val_accuracy: 0.8991 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3281 - accuracy: 0.8866 - val_loss: 0.3122 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3293 - accuracy: 0.8875 - val_loss: 0.3122 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3238 - accuracy: 0.8876 - val_loss: 0.3122 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3318 - accuracy: 0.8825 - val_loss: 0.3120 - val_accuracy: 0.8995 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3338 - accuracy: 0.8857 - val_loss: 0.3118 - val_accuracy: 0.8999 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3258 - accuracy: 0.8847 - val_loss: 0.3121 - val_accuracy: 0.8997 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3253 - accuracy: 0.8879 - val_loss: 0.3117 - val_accuracy: 0.8991 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 10ms/step - loss: 0.2816 - accuracy: 0.9059\n",
      "17/17 [==============================] - 1s 9ms/step\n",
      "TP:5707, TN:9645, FP:810, FN:784, loss0.28158387541770935, acc0.9059365041897793, sn0.8792173779078725, sp0.9225251076040172, f10.8774600246002461, auc0.9633466225280032\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 23s 46ms/step - loss: 1.8836 - accuracy: 0.5798 - val_loss: 1.8058 - val_accuracy: 0.4312 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 1.5527 - accuracy: 0.6200 - val_loss: 1.6129 - val_accuracy: 0.3883 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 1.3385 - accuracy: 0.6329 - val_loss: 1.3402 - val_accuracy: 0.4809 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 1.1679 - accuracy: 0.6571 - val_loss: 1.1679 - val_accuracy: 0.5822 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 1.0387 - accuracy: 0.6645 - val_loss: 1.0366 - val_accuracy: 0.6131 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.9380 - accuracy: 0.6779 - val_loss: 0.9389 - val_accuracy: 0.6193 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.8614 - accuracy: 0.6954 - val_loss: 0.9489 - val_accuracy: 0.6067 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.8043 - accuracy: 0.7053 - val_loss: 0.8536 - val_accuracy: 0.6272 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.7586 - accuracy: 0.7137 - val_loss: 0.7794 - val_accuracy: 0.6542 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.7053 - accuracy: 0.7353 - val_loss: 0.7152 - val_accuracy: 0.7042 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.6620 - accuracy: 0.7492 - val_loss: 0.6313 - val_accuracy: 0.7669 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.6302 - accuracy: 0.7619 - val_loss: 0.6093 - val_accuracy: 0.7702 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.6018 - accuracy: 0.7725 - val_loss: 0.5583 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.5700 - accuracy: 0.7862 - val_loss: 0.6008 - val_accuracy: 0.7714 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.5477 - accuracy: 0.8008 - val_loss: 0.5282 - val_accuracy: 0.8075 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.5248 - accuracy: 0.8103 - val_loss: 0.5452 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.4892 - accuracy: 0.8296 - val_loss: 0.5049 - val_accuracy: 0.8341 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4792 - accuracy: 0.8351 - val_loss: 0.4674 - val_accuracy: 0.8496 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.4548 - accuracy: 0.8458 - val_loss: 0.4296 - val_accuracy: 0.8724 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4499 - accuracy: 0.8446 - val_loss: 0.4069 - val_accuracy: 0.8751 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.4273 - accuracy: 0.8543 - val_loss: 0.4042 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.4295 - accuracy: 0.8503 - val_loss: 0.3942 - val_accuracy: 0.8753 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.4173 - accuracy: 0.8606 - val_loss: 0.3902 - val_accuracy: 0.8742 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.4101 - accuracy: 0.8611 - val_loss: 0.3695 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4041 - accuracy: 0.8617 - val_loss: 0.3689 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.4035 - accuracy: 0.8602 - val_loss: 0.3777 - val_accuracy: 0.8765 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4005 - accuracy: 0.8648 - val_loss: 0.3556 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3952 - accuracy: 0.8653 - val_loss: 0.3830 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3909 - accuracy: 0.8653 - val_loss: 0.3726 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3895 - accuracy: 0.8651 - val_loss: 0.3435 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3843 - accuracy: 0.8684 - val_loss: 0.3616 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3758 - accuracy: 0.8738 - val_loss: 0.3588 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3776 - accuracy: 0.8738 - val_loss: 0.3426 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3735 - accuracy: 0.8741 - val_loss: 0.3563 - val_accuracy: 0.8827 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3757 - accuracy: 0.8706 - val_loss: 0.3425 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3776 - accuracy: 0.8733 - val_loss: 0.3457 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3745 - accuracy: 0.8708 - val_loss: 0.3436 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3736 - accuracy: 0.8688 - val_loss: 0.3399 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3754 - accuracy: 0.8726 - val_loss: 0.3303 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3738 - accuracy: 0.8709 - val_loss: 0.3368 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3721 - accuracy: 0.8722 - val_loss: 0.3376 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3680 - accuracy: 0.8779 - val_loss: 0.3293 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3640 - accuracy: 0.8729 - val_loss: 0.3376 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3650 - accuracy: 0.8791 - val_loss: 0.3306 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3672 - accuracy: 0.8773 - val_loss: 0.3310 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3683 - accuracy: 0.8740 - val_loss: 0.3550 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3683 - accuracy: 0.8739 - val_loss: 0.3348 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3659 - accuracy: 0.8732 - val_loss: 0.3492 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3660 - accuracy: 0.8773 - val_loss: 0.3344 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3633 - accuracy: 0.8757 - val_loss: 0.3550 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3656 - accuracy: 0.8786 - val_loss: 0.3268 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3682 - accuracy: 0.8724 - val_loss: 0.3377 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3647 - accuracy: 0.8736 - val_loss: 0.3310 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3614 - accuracy: 0.8770 - val_loss: 0.3275 - val_accuracy: 0.8935 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3603 - accuracy: 0.8760 - val_loss: 0.3342 - val_accuracy: 0.8945 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3537 - accuracy: 0.8792 - val_loss: 0.3378 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3577 - accuracy: 0.8766 - val_loss: 0.3433 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3589 - accuracy: 0.8779 - val_loss: 0.3385 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3601 - accuracy: 0.8727 - val_loss: 0.3291 - val_accuracy: 0.8935 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3638 - accuracy: 0.8748 - val_loss: 0.3535 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3647 - accuracy: 0.8748 - val_loss: 0.3321 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3535 - accuracy: 0.8755 - val_loss: 0.3293 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3606 - accuracy: 0.8763 - val_loss: 0.3180 - val_accuracy: 0.8993 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3615 - accuracy: 0.8747 - val_loss: 0.3257 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3602 - accuracy: 0.8779 - val_loss: 0.3334 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3515 - accuracy: 0.8791 - val_loss: 0.3367 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3574 - accuracy: 0.8780 - val_loss: 0.3504 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3532 - accuracy: 0.8779 - val_loss: 0.3476 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3596 - accuracy: 0.8757 - val_loss: 0.3550 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3534 - accuracy: 0.8776 - val_loss: 0.3383 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3557 - accuracy: 0.8773 - val_loss: 0.3408 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3469 - accuracy: 0.8838 - val_loss: 0.3231 - val_accuracy: 0.8969 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3433 - accuracy: 0.8823 - val_loss: 0.3227 - val_accuracy: 0.8961 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3443 - accuracy: 0.8838 - val_loss: 0.3198 - val_accuracy: 0.8971 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3354 - accuracy: 0.8829 - val_loss: 0.3183 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3344 - accuracy: 0.8862 - val_loss: 0.3186 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3380 - accuracy: 0.8828 - val_loss: 0.3148 - val_accuracy: 0.8993 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3339 - accuracy: 0.8885 - val_loss: 0.3140 - val_accuracy: 0.9001 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3323 - accuracy: 0.8854 - val_loss: 0.3136 - val_accuracy: 0.9009 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3324 - accuracy: 0.8832 - val_loss: 0.3117 - val_accuracy: 0.8991 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3305 - accuracy: 0.8849 - val_loss: 0.3115 - val_accuracy: 0.8983 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.3305 - accuracy: 0.8871 - val_loss: 0.3117 - val_accuracy: 0.8989 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3241 - accuracy: 0.8849 - val_loss: 0.3125 - val_accuracy: 0.8991 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3302 - accuracy: 0.8838 - val_loss: 0.3125 - val_accuracy: 0.8997 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3297 - accuracy: 0.8853 - val_loss: 0.3120 - val_accuracy: 0.8991 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3268 - accuracy: 0.8874 - val_loss: 0.3119 - val_accuracy: 0.8999 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3261 - accuracy: 0.8843 - val_loss: 0.3121 - val_accuracy: 0.8991 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3289 - accuracy: 0.8847 - val_loss: 0.3118 - val_accuracy: 0.8999 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3252 - accuracy: 0.8882 - val_loss: 0.3126 - val_accuracy: 0.8989 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3308 - accuracy: 0.8820 - val_loss: 0.3123 - val_accuracy: 0.8995 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3261 - accuracy: 0.8844 - val_loss: 0.3126 - val_accuracy: 0.9001 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3243 - accuracy: 0.8865 - val_loss: 0.3126 - val_accuracy: 0.9005 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3278 - accuracy: 0.8867 - val_loss: 0.3125 - val_accuracy: 0.8997 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3238 - accuracy: 0.8866 - val_loss: 0.3125 - val_accuracy: 0.8999 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3295 - accuracy: 0.8854 - val_loss: 0.3123 - val_accuracy: 0.9003 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3293 - accuracy: 0.8839 - val_loss: 0.3127 - val_accuracy: 0.8999 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3244 - accuracy: 0.8839 - val_loss: 0.3128 - val_accuracy: 0.8999 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3322 - accuracy: 0.8837 - val_loss: 0.3124 - val_accuracy: 0.8999 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3317 - accuracy: 0.8846 - val_loss: 0.3124 - val_accuracy: 0.8995 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3273 - accuracy: 0.8836 - val_loss: 0.3124 - val_accuracy: 0.8991 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 10ms/step - loss: 0.2811 - accuracy: 0.9045\n",
      "17/17 [==============================] - 1s 10ms/step\n",
      "TP:5618, TN:9709, FP:746, FN:873, loss0.28111693263053894, acc0.9044612297887407, sn0.8655060853489447, sp0.9286465805834528, f10.8740567872423182, auc0.9625231374700399\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 22s 49ms/step - loss: 1.9012 - accuracy: 0.5805 - val_loss: 1.7618 - val_accuracy: 0.4103 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 1.5780 - accuracy: 0.6165 - val_loss: 1.5683 - val_accuracy: 0.3923 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 1.3750 - accuracy: 0.6316 - val_loss: 1.3558 - val_accuracy: 0.5654 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 1.2080 - accuracy: 0.6467 - val_loss: 1.1955 - val_accuracy: 0.5790 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 1.0718 - accuracy: 0.6658 - val_loss: 1.0826 - val_accuracy: 0.5718 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.9702 - accuracy: 0.6793 - val_loss: 0.9844 - val_accuracy: 0.5854 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.8847 - accuracy: 0.6904 - val_loss: 0.9127 - val_accuracy: 0.5989 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.8188 - accuracy: 0.7030 - val_loss: 0.8899 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.7731 - accuracy: 0.7071 - val_loss: 0.8744 - val_accuracy: 0.6009 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.7231 - accuracy: 0.7225 - val_loss: 0.8581 - val_accuracy: 0.5913 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.6841 - accuracy: 0.7362 - val_loss: 0.8496 - val_accuracy: 0.6125 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.6517 - accuracy: 0.7455 - val_loss: 0.6731 - val_accuracy: 0.7220 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.6243 - accuracy: 0.7542 - val_loss: 0.6762 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.5943 - accuracy: 0.7709 - val_loss: 0.6088 - val_accuracy: 0.7673 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.5708 - accuracy: 0.7817 - val_loss: 0.5359 - val_accuracy: 0.8111 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.5460 - accuracy: 0.7927 - val_loss: 0.5456 - val_accuracy: 0.7978 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.5315 - accuracy: 0.7958 - val_loss: 0.4848 - val_accuracy: 0.8329 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.5048 - accuracy: 0.8120 - val_loss: 0.4774 - val_accuracy: 0.8371 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.4825 - accuracy: 0.8229 - val_loss: 0.4411 - val_accuracy: 0.8558 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.4665 - accuracy: 0.8320 - val_loss: 0.4699 - val_accuracy: 0.8371 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4559 - accuracy: 0.8379 - val_loss: 0.5052 - val_accuracy: 0.8347 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.4412 - accuracy: 0.8466 - val_loss: 0.4212 - val_accuracy: 0.8584 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4257 - accuracy: 0.8496 - val_loss: 0.4196 - val_accuracy: 0.8614 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.4164 - accuracy: 0.8556 - val_loss: 0.3999 - val_accuracy: 0.8696 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.4150 - accuracy: 0.8583 - val_loss: 0.3617 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.4106 - accuracy: 0.8599 - val_loss: 0.3963 - val_accuracy: 0.8795 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.4045 - accuracy: 0.8620 - val_loss: 0.3763 - val_accuracy: 0.8805 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3954 - accuracy: 0.8629 - val_loss: 0.3758 - val_accuracy: 0.8797 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3889 - accuracy: 0.8682 - val_loss: 0.3813 - val_accuracy: 0.8751 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3918 - accuracy: 0.8610 - val_loss: 0.3869 - val_accuracy: 0.8714 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3871 - accuracy: 0.8686 - val_loss: 0.3469 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3866 - accuracy: 0.8692 - val_loss: 0.3398 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3749 - accuracy: 0.8673 - val_loss: 0.3415 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3754 - accuracy: 0.8698 - val_loss: 0.3475 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3795 - accuracy: 0.8691 - val_loss: 0.3425 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3785 - accuracy: 0.8714 - val_loss: 0.3862 - val_accuracy: 0.8748 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3766 - accuracy: 0.8701 - val_loss: 0.3539 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3727 - accuracy: 0.8736 - val_loss: 0.3395 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3674 - accuracy: 0.8769 - val_loss: 0.3478 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3706 - accuracy: 0.8744 - val_loss: 0.3352 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3649 - accuracy: 0.8718 - val_loss: 0.3271 - val_accuracy: 0.8945 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3669 - accuracy: 0.8754 - val_loss: 0.3270 - val_accuracy: 0.8945 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3699 - accuracy: 0.8725 - val_loss: 0.3398 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3607 - accuracy: 0.8780 - val_loss: 0.3374 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3580 - accuracy: 0.8767 - val_loss: 0.3247 - val_accuracy: 0.8969 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3652 - accuracy: 0.8749 - val_loss: 0.3377 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3639 - accuracy: 0.8770 - val_loss: 0.3294 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3637 - accuracy: 0.8758 - val_loss: 0.3444 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3680 - accuracy: 0.8743 - val_loss: 0.3247 - val_accuracy: 0.8979 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3557 - accuracy: 0.8792 - val_loss: 0.3381 - val_accuracy: 0.8935 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3590 - accuracy: 0.8761 - val_loss: 0.3278 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3589 - accuracy: 0.8732 - val_loss: 0.3251 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3577 - accuracy: 0.8799 - val_loss: 0.3353 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3622 - accuracy: 0.8763 - val_loss: 0.3295 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3556 - accuracy: 0.8771 - val_loss: 0.3232 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3587 - accuracy: 0.8784 - val_loss: 0.3444 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3609 - accuracy: 0.8765 - val_loss: 0.3348 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3603 - accuracy: 0.8755 - val_loss: 0.3355 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3568 - accuracy: 0.8754 - val_loss: 0.3274 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3545 - accuracy: 0.8787 - val_loss: 0.3287 - val_accuracy: 0.8971 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3533 - accuracy: 0.8798 - val_loss: 0.3318 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3611 - accuracy: 0.8778 - val_loss: 0.3277 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3490 - accuracy: 0.8814 - val_loss: 0.3282 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3558 - accuracy: 0.8752 - val_loss: 0.3525 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3498 - accuracy: 0.8808 - val_loss: 0.3347 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3572 - accuracy: 0.8761 - val_loss: 0.3159 - val_accuracy: 0.9003 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3569 - accuracy: 0.8781 - val_loss: 0.3187 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3496 - accuracy: 0.8791 - val_loss: 0.3181 - val_accuracy: 0.8957 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3558 - accuracy: 0.8730 - val_loss: 0.3168 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3475 - accuracy: 0.8790 - val_loss: 0.3239 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 0.3503 - accuracy: 0.8749 - val_loss: 0.3391 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3409 - accuracy: 0.8813 - val_loss: 0.3265 - val_accuracy: 0.8957 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3407 - accuracy: 0.8813 - val_loss: 0.3170 - val_accuracy: 0.9007 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3348 - accuracy: 0.8873 - val_loss: 0.3186 - val_accuracy: 0.8985 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3333 - accuracy: 0.8823 - val_loss: 0.3166 - val_accuracy: 0.8989 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3296 - accuracy: 0.8865 - val_loss: 0.3125 - val_accuracy: 0.9009 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 4s 43ms/step - loss: 0.3331 - accuracy: 0.8841 - val_loss: 0.3118 - val_accuracy: 0.9007 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 4s 44ms/step - loss: 0.3275 - accuracy: 0.8869 - val_loss: 0.3140 - val_accuracy: 0.8985 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3246 - accuracy: 0.8861 - val_loss: 0.3114 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3297 - accuracy: 0.8862 - val_loss: 0.3063 - val_accuracy: 0.9011 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3276 - accuracy: 0.8867 - val_loss: 0.3090 - val_accuracy: 0.8987 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3225 - accuracy: 0.8898 - val_loss: 0.3080 - val_accuracy: 0.9009 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3293 - accuracy: 0.8873 - val_loss: 0.3077 - val_accuracy: 0.9017 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3249 - accuracy: 0.8860 - val_loss: 0.3076 - val_accuracy: 0.9013 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3233 - accuracy: 0.8861 - val_loss: 0.3081 - val_accuracy: 0.9017 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3292 - accuracy: 0.8842 - val_loss: 0.3074 - val_accuracy: 0.9015 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3214 - accuracy: 0.8902 - val_loss: 0.3072 - val_accuracy: 0.9015 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3255 - accuracy: 0.8867 - val_loss: 0.3079 - val_accuracy: 0.9015 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3231 - accuracy: 0.8855 - val_loss: 0.3075 - val_accuracy: 0.9017 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 4s 45ms/step - loss: 0.3209 - accuracy: 0.8905 - val_loss: 0.3078 - val_accuracy: 0.9017 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3210 - accuracy: 0.8893 - val_loss: 0.3080 - val_accuracy: 0.9021 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3224 - accuracy: 0.8865 - val_loss: 0.3084 - val_accuracy: 0.9021 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.3228 - accuracy: 0.8835 - val_loss: 0.3087 - val_accuracy: 0.9019 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3242 - accuracy: 0.8834 - val_loss: 0.3086 - val_accuracy: 0.9021 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3209 - accuracy: 0.8902 - val_loss: 0.3081 - val_accuracy: 0.9025 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3214 - accuracy: 0.8820 - val_loss: 0.3084 - val_accuracy: 0.9025 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3250 - accuracy: 0.8861 - val_loss: 0.3081 - val_accuracy: 0.9025 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3204 - accuracy: 0.8902 - val_loss: 0.3083 - val_accuracy: 0.9021 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.3250 - accuracy: 0.8855 - val_loss: 0.3084 - val_accuracy: 0.9021 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.3216 - accuracy: 0.8862 - val_loss: 0.3082 - val_accuracy: 0.9023 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 6s 11ms/step - loss: 0.2803 - accuracy: 0.9048\n",
      "17/17 [==============================] - 1s 10ms/step\n",
      "TP:5632, TN:9701, FP:754, FN:859, loss0.2802874743938446, acc0.90481529564499, sn0.8676629178863041, sp0.9278813964610234, f10.8747379047914886, auc0.9625866326630679\n",
      "Average Test loss:  0.2811252027750015\n",
      "Average Accuracy:  0.9054526141862388\n",
      "Average Sensitivity:  0.8700970574641811\n",
      "Average Specificity:  0.927403156384505\n",
      "Average F1 Score:  0.8757675403875964\n",
      "Average AUC Score:  0.9627864487495138\n",
      "AUC for ROC curve 1: 0.9628\n",
      "AUC for ROC curve 2: 0.9628\n",
      "AUC for ROC curve 3: 0.9610\n",
      "AUC for ROC curve 4: 0.9610\n",
      "AUC for ROC curve 5: 0.9637\n",
      "AUC for ROC curve 6: 0.9637\n",
      "AUC for ROC curve 7: 0.9628\n",
      "AUC for ROC curve 8: 0.9628\n",
      "AUC for ROC curve 9: 0.9630\n",
      "AUC for ROC curve 10: 0.9630\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, f1_score,roc_auc_score\n",
    "losses = []\n",
    "accuracies = []\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "f1_scores = []\n",
    "auc_scores = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "\n",
    "num_trainings = 10\n",
    "for i in range(num_trainings):\n",
    "    model = create_model(x_train1.shape[1:], x_train2.shape[1:], x_train3.shape[1:])\n",
    "    model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "    history = model.fit([x_train1, x_train2, x_train3], y_train, batch_size=128, epochs=100,\n",
    "                        validation_data=([x_val1, x_val2, x_val3], y_val), callbacks=[lr_scheduler])\n",
    "    loss, accuracy = model.evaluate([x_test1, x_test2, x_test3], y_test)\n",
    "    y_prob = model.predict([x_test1, x_test2, x_test3], batch_size=1024, verbose=1)\n",
    "\n",
    "    y_true = y_test.argmax(axis=-1)\n",
    "    y_pred = np.argmax(y_prob, axis=-1)\n",
    "\n",
    "    C = confusion_matrix(y_true, y_pred, labels=(1, 0))\n",
    "    TP, TN, FP, FN = C[0, 0], C[1, 1], C[1, 0], C[0, 1]\n",
    "    acc, sn, sp = 1. * (TP + TN) / (TP + TN + FP + FN), 1. * TP / (TP + FN), 1. * TN / (TN + FP)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    sn = TP / (TP + FN)  \n",
    "    sp = TN / (TN + FP) \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = sn\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    auc_scores.append(roc_auc)\n",
    "    \n",
    "    print(\"TP:{}, TN:{}, FP:{}, FN:{}, loss{}, acc{}, sn{}, sp{}, f1{}, auc{}\".format(TP, TN, FP, FN, loss, acc, sn, sp, f1, roc_auc))\n",
    "    losses.append(loss)\n",
    "    accuracies.append(acc)\n",
    "    sensitivities.append(sn)\n",
    "    specificities.append(sp)\n",
    "    f1_scores.append(f1)\n",
    "    auc_scores.append(roc_auc)\n",
    "\n",
    "avg_loss = np.mean(losses)\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_sensitivity = np.mean(sensitivities)\n",
    "avg_specificity = np.mean(specificities)\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "avg_auc_score = np.mean(auc_scores)\n",
    "\n",
    "print(\"Average Test loss: \", avg_loss)\n",
    "print(\"Average Accuracy: \", avg_accuracy)\n",
    "print(\"Average Sensitivity: \", avg_sensitivity)\n",
    "print(\"Average Specificity: \", avg_specificity)\n",
    "print(\"Average F1 Score: \", avg_f1_score)\n",
    "print(\"Average AUC Score: \", avg_auc_score)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = np.zeros_like(mean_fpr)\n",
    "for i in range(num_trainings):\n",
    "    mean_tpr += np.interp(mean_fpr, fprs[i], tprs[i])\n",
    "    plt.plot(fprs[i], tprs[i], alpha=0.3, label='ROC curve {} (AUC = {:.4f})'.format(i+1, auc_scores[i]))\n",
    "    print('AUC for ROC curve {}: {:.4f}'.format(i+1, auc_scores[i]))\n",
    "mean_tpr /= num_trainings\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--', label='Mean ROC (AUC = {:.4f})'.format(mean_auc), lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f9963-cfa7-47f5-8701-2a24e58e20bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gcn",
   "language": "python",
   "name": "gcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
