{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "-028b2NqE02R",
   "metadata": {
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1693232083105,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "-028b2NqE02R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 22:00:55.214985: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.Session(config=config).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a034672d",
   "metadata": {
    "executionInfo": {
     "elapsed": 1150,
     "status": "ok",
     "timestamp": 1693232086282,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "a034672d"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import BatchNormalization, LeakyReLU, MaxPooling1D, Dropout, Flatten, Dense, Conv1D,Reshape,multiply,GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from scipy.interpolate import splev, splrep\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591596f3",
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1693232087740,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "591596f3"
   },
   "outputs": [],
   "source": [
    "base_dir = \"./dataset\"\n",
    "ir = 3 \n",
    "before = 2\n",
    "after = 2\n",
    "\n",
    "scaler = lambda arr: (arr - np.min(arr)) / (np.max(arr) - np.min(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cef782d",
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1693232089719,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "0cef782d"
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "def interpolate_numpy_array(arr, desired_length):\n",
    "    cs = CubicSpline(np.linspace(0, 1, len(arr)), arr)\n",
    "    x_new = np.linspace(0, 1, desired_length)\n",
    "    interpolated_arr = cs(x_new)\n",
    "    return interpolated_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "KXj-pyPoXKm3",
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1693232167282,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "KXj-pyPoXKm3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def load_data():\n",
    "    tm = np.arange(0, (before + 1 + after) * 60, step=1 / float(ir))\n",
    "    with open(os.path.join(base_dir, \"apnea.pkl\"), 'rb') as f:\n",
    "        apnea_ecg = pickle.load(f)\n",
    "    x_train1,x_train2,x_train3 = [],[],[]\n",
    "    o_train, y_train = apnea_ecg[\"o_train\"], apnea_ecg[\"y_train\"]\n",
    "    groups_train = apnea_ecg[\"groups_train\"]\n",
    "    for i in range(len(o_train)):\n",
    "        min_distance_list, max_distance_list= o_train[i]\n",
    "        min_distance_list_inter = interpolate_numpy_array(min_distance_list,900)\n",
    "        max_distance_list_inter = interpolate_numpy_array(max_distance_list,900)\n",
    "        x_train1.append([min_distance_list_inter, max_distance_list_inter])\n",
    "        x_train2.append([min_distance_list_inter[180:720], max_distance_list_inter[180:720]])\n",
    "        x_train3.append([min_distance_list_inter[360:540], max_distance_list_inter[360:540]])\n",
    "    x_training1,x_training2,x_training3,y_training,groups_training = [],[],[],[],[]\n",
    "    x_val1,x_val2,x_val3,y_val,groups_val = [],[],[],[],[]\n",
    "\n",
    "    trainlist = random.sample(range(len(o_train)),int(len(o_train)*0.7))\n",
    "    num=[i for i in range(16713)]\n",
    "    vallist = set(num) - set(trainlist)\n",
    "    vallist = list(vallist)\n",
    "    for i in trainlist:\n",
    "        x_training1.append(x_train1[i])\n",
    "        x_training2.append(x_train2[i])\n",
    "        x_training3.append(x_train3[i])\n",
    "        y_training.append(y_train[i])\n",
    "        groups_training.append(groups_train[i])\n",
    "    for i in vallist:\n",
    "        x_val1.append(x_train1[i])\n",
    "        x_val2.append(x_train2[i])\n",
    "        x_val3.append(x_train3[i])\n",
    "        y_val.append(y_train[i])\n",
    "        groups_val.append(groups_train[i])\n",
    "\n",
    "    x_training1 = np.array(x_training1, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_training2 = np.array(x_training2, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_training3 = np.array(x_training3, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    y_training = np.array(y_training, dtype=\"float32\")\n",
    "    x_val1 = np.array(x_val1, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_val2 = np.array(x_val2, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_val3 = np.array(x_val3, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    y_val = np.array(y_val, dtype=\"float32\")\n",
    "\n",
    "    x_test1,x_test2,x_test3 = [],[],[]\n",
    "    o_test, y_test = apnea_ecg[\"o_test\"], apnea_ecg[\"y_test\"]\n",
    "    groups_test = apnea_ecg[\"groups_test\"]\n",
    "    for i in range(len(o_test)):\n",
    "        min_distance_list, max_distance_list = o_test[i]\n",
    "        min_distance_list_inter = interpolate_numpy_array(min_distance_list,900)\n",
    "        max_distance_list_inter = interpolate_numpy_array(max_distance_list,900)\n",
    "        x_test1.append([min_distance_list_inter, max_distance_list_inter])\n",
    "        x_test2.append([min_distance_list_inter[180:720], max_distance_list_inter[180:720]])\n",
    "        x_test3.append([min_distance_list_inter[360:540], max_distance_list_inter[360:540]])\n",
    "    x_test1 = np.array(x_test1, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_test2 = np.array(x_test2, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_test3 = np.array(x_test3, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    y_test = np.array(y_test, dtype=\"float32\")\n",
    "\n",
    "    return x_training1, x_training2, x_training3, y_training, groups_training, x_val1, x_val2, x_val3, y_val, groups_val, x_test1, x_test2, x_test3, y_test, groups_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ef5b79-3b27-4888-9bb6-ad2415d780d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, ratio=4,**kwargs):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.channels = input_shape[-1]\n",
    "        self.fc1 = tf.keras.layers.Dense(self.channels // self.ratio, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(self.channels, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        max_pool = tf.reduce_max(inputs, axis=[1, 2], keepdims=True)\n",
    "        avg_pool = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n",
    "        max_pool = self.fc1(max_pool)\n",
    "        avg_pool = self.fc1(avg_pool)\n",
    "        attention = self.fc2(tf.keras.layers.add([max_pool, avg_pool]))\n",
    "        return inputs * attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9c50e53-c397-4432-bb00-4ec3a202a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = keras.layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71576d5f-5bfa-4321-bd05-f1a9b3c2d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualAttentionBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(ResidualAttentionBlock, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv1D(num_output_features, kernel_size=1, strides=1, padding='valid', use_bias=False)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv1D(num_output_features, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv3 = tf.keras.layers.Conv1D(num_output_features, kernel_size=1, strides=1, padding='valid', use_bias=False)\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        residual = x       \n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = self.sigmoid(out)      \n",
    "\n",
    "        out = out * residual + residual\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd7222a-ca10-4ac3-b7ca-6272cbbd2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers=2, d_model=64, nhead=1, dim_feedforward=128, dropout=0.30):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.precnnlayer = layers.Dense(d_model)\n",
    "        self.multi_head_attention = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model)\n",
    "\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(dim_feedforward, activation='relu'),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "\n",
    "        self.layer_norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "        self.pred_layer = tf.keras.Sequential([\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.precnnlayer(x)\n",
    "        x += self.multi_head_attention(x, x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm1(x)\n",
    "        ffn_output = self.ffn(x)\n",
    "        x += ffn_output\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.pred_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "GnDFx0fGCy1m",
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1693232096445,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "GnDFx0fGCy1m"
   },
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling1D\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, GRU, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "def create_model(input_a_shape, weight=1e-3,rate=1):\n",
    "    leaky_relu = LeakyReLU()\n",
    "    \n",
    "    # CNN-1\n",
    "    input1 = Input(shape=input_a_shape)\n",
    "\n",
    "    x1 = BatchNormalization()(input1)    \n",
    "    x1 = Conv1D(96, kernel_size=11, strides=4, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x1)\n",
    "    \n",
    "    x1 = leaky_relu(x1)\n",
    "    x1 = MaxPooling1D(pool_size=3, padding=\"same\")(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "\n",
    "    x1 = Conv1D(256, kernel_size=7, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = leaky_relu(x1)\n",
    "    x1 = MaxPooling1D(pool_size=3,strides=2, padding=\"same\")(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "\n",
    "    x1 = Conv1D(384, kernel_size=5, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = leaky_relu(x1)\n",
    "    x1 = MaxPooling1D(pool_size=2, padding=\"same\")(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "\n",
    "    x1 = Conv1D(384, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = leaky_relu(x1)\n",
    "    x1 = MaxPooling1D(pool_size=2, padding=\"same\")(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "\n",
    "    x1 = Conv1D(256, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = leaky_relu(x1)   \n",
    "    x1 = MaxPooling1D(pool_size=2, padding=\"same\")(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    " \n",
    "    attention = ResidualAttentionBlock(256, 256) \n",
    "    x1 = attention(x1)\n",
    "    \n",
    "    concat=ChannelAttention()(x1)\n",
    "    x = GlobalAveragePooling1D()(concat)\n",
    "    dp = Dropout(0.5)(x)\n",
    "    outputs = Dense(2, activation='softmax', name=\"Output_Layer\")(dp)\n",
    "    model = Model(inputs=input1, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c830eb3",
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1693232100397,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "6c830eb3"
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch > 70 and \\\n",
    "            (epoch - 1) % 10 == 0:\n",
    "        lr *= 0.1\n",
    "    print(\"Learning rate: \", lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded3f606",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1693232101699,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "ded3f606"
   },
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    \"\"\"Plot performance curve\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    axes[0].plot(history[\"loss\"], \"r-\", history[\"val_loss\"], \"b-\", linewidth=0.5)\n",
    "    axes[0].set_title(\"Loss\")\n",
    "    axes[1].plot(history[\"accuracy\"], \"r-\", history[\"val_accuracy\"], \"b-\", linewidth=0.5)\n",
    "    axes[1].set_title(\"Accuracy\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "v6XhEYeu7cgM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45661,
     "status": "ok",
     "timestamp": 1693233004292,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "v6XhEYeu7cgM",
    "outputId": "4f452c32-a1f2-4c9e-b7bc-05ca348f3613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape (11699, 900, 2) (11699, 540, 2) (11699, 180, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    x_train1, x_train2, x_train3, y_train, groups_train, x_val1, x_val2, x_val3, y_val, groups_val, x_test1, x_test2, x_test3, y_test, groups_test= load_data()\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes=2)  # Convert to two categories\n",
    "    y_val = keras.utils.to_categorical(y_val, num_classes=2)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes=2)\n",
    "\n",
    "    print('input_shape', x_train1.shape, x_train2.shape, x_train3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae98c6d-d470-4371-b7bb-6707c20168f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 13s 29ms/step - loss: 3.2061 - accuracy: 0.6630 - val_loss: 3.1859 - val_accuracy: 0.4464 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 1s 15ms/step - loss: 2.4511 - accuracy: 0.8020 - val_loss: 2.4044 - val_accuracy: 0.6235 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 1.8648 - accuracy: 0.8450 - val_loss: 1.6416 - val_accuracy: 0.8389 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 1.4141 - accuracy: 0.8581 - val_loss: 1.2396 - val_accuracy: 0.8606 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 1.0925 - accuracy: 0.8701 - val_loss: 0.9510 - val_accuracy: 0.8765 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.8623 - accuracy: 0.8801 - val_loss: 0.7927 - val_accuracy: 0.8736 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.7166 - accuracy: 0.8821 - val_loss: 0.6736 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.6145 - accuracy: 0.8872 - val_loss: 0.6707 - val_accuracy: 0.8580 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.5419 - accuracy: 0.8933 - val_loss: 0.5160 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4985 - accuracy: 0.8958 - val_loss: 0.4656 - val_accuracy: 0.9063 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.4685 - accuracy: 0.9007 - val_loss: 0.4931 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4511 - accuracy: 0.9021 - val_loss: 0.5184 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.4325 - accuracy: 0.9013 - val_loss: 0.5447 - val_accuracy: 0.8712 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.4249 - accuracy: 0.9044 - val_loss: 0.4103 - val_accuracy: 0.9114 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4304 - accuracy: 0.9010 - val_loss: 0.4660 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.4041 - accuracy: 0.9083 - val_loss: 0.4340 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.4082 - accuracy: 0.9063 - val_loss: 0.4504 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.4003 - accuracy: 0.9061 - val_loss: 0.3942 - val_accuracy: 0.9099 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.4021 - accuracy: 0.9056 - val_loss: 0.5572 - val_accuracy: 0.8546 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3970 - accuracy: 0.9069 - val_loss: 0.6481 - val_accuracy: 0.7994 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3875 - accuracy: 0.9096 - val_loss: 0.3918 - val_accuracy: 0.9047 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3818 - accuracy: 0.9096 - val_loss: 0.3703 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3972 - accuracy: 0.9065 - val_loss: 0.4030 - val_accuracy: 0.9065 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3779 - accuracy: 0.9091 - val_loss: 0.4140 - val_accuracy: 0.9005 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3833 - accuracy: 0.9114 - val_loss: 0.3724 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3863 - accuracy: 0.9059 - val_loss: 0.4562 - val_accuracy: 0.8965 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3804 - accuracy: 0.9107 - val_loss: 0.3986 - val_accuracy: 0.9067 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3813 - accuracy: 0.9109 - val_loss: 0.3973 - val_accuracy: 0.9039 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3788 - accuracy: 0.9091 - val_loss: 0.3673 - val_accuracy: 0.9168 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3826 - accuracy: 0.9094 - val_loss: 0.3725 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3826 - accuracy: 0.9102 - val_loss: 0.4332 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3827 - accuracy: 0.9123 - val_loss: 0.3665 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3788 - accuracy: 0.9098 - val_loss: 0.3791 - val_accuracy: 0.9134 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3731 - accuracy: 0.9132 - val_loss: 0.3847 - val_accuracy: 0.9073 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3723 - accuracy: 0.9115 - val_loss: 0.3804 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3725 - accuracy: 0.9134 - val_loss: 0.4297 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3837 - accuracy: 0.9131 - val_loss: 0.3811 - val_accuracy: 0.9164 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3769 - accuracy: 0.9137 - val_loss: 0.3917 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3715 - accuracy: 0.9117 - val_loss: 0.4020 - val_accuracy: 0.9015 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3819 - accuracy: 0.9098 - val_loss: 0.4578 - val_accuracy: 0.8807 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3738 - accuracy: 0.9110 - val_loss: 0.3708 - val_accuracy: 0.9087 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3724 - accuracy: 0.9129 - val_loss: 0.4113 - val_accuracy: 0.8965 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3707 - accuracy: 0.9124 - val_loss: 0.4117 - val_accuracy: 0.9063 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3787 - accuracy: 0.9113 - val_loss: 0.3834 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3678 - accuracy: 0.9140 - val_loss: 0.4661 - val_accuracy: 0.8630 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3623 - accuracy: 0.9134 - val_loss: 0.5383 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3810 - accuracy: 0.9128 - val_loss: 0.3517 - val_accuracy: 0.9238 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3774 - accuracy: 0.9096 - val_loss: 0.3939 - val_accuracy: 0.9114 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3708 - accuracy: 0.9132 - val_loss: 0.3528 - val_accuracy: 0.9144 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3662 - accuracy: 0.9138 - val_loss: 0.3617 - val_accuracy: 0.9180 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3749 - accuracy: 0.9126 - val_loss: 0.3500 - val_accuracy: 0.9194 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3747 - accuracy: 0.9093 - val_loss: 0.3650 - val_accuracy: 0.9156 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3630 - accuracy: 0.9132 - val_loss: 0.3681 - val_accuracy: 0.9142 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3687 - accuracy: 0.9125 - val_loss: 0.3626 - val_accuracy: 0.9164 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3740 - accuracy: 0.9157 - val_loss: 0.3842 - val_accuracy: 0.9164 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3731 - accuracy: 0.9134 - val_loss: 0.3585 - val_accuracy: 0.9198 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3728 - accuracy: 0.9161 - val_loss: 0.3610 - val_accuracy: 0.9118 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3626 - accuracy: 0.9181 - val_loss: 0.3487 - val_accuracy: 0.9190 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3707 - accuracy: 0.9104 - val_loss: 0.4113 - val_accuracy: 0.8993 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3696 - accuracy: 0.9129 - val_loss: 0.3549 - val_accuracy: 0.9210 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3709 - accuracy: 0.9115 - val_loss: 0.4814 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3783 - accuracy: 0.9099 - val_loss: 0.3602 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3632 - accuracy: 0.9135 - val_loss: 0.3672 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3611 - accuracy: 0.9126 - val_loss: 0.3582 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3603 - accuracy: 0.9148 - val_loss: 0.4027 - val_accuracy: 0.8995 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3775 - accuracy: 0.9094 - val_loss: 0.3891 - val_accuracy: 0.9083 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3568 - accuracy: 0.9158 - val_loss: 0.4018 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3643 - accuracy: 0.9138 - val_loss: 0.4018 - val_accuracy: 0.9001 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3659 - accuracy: 0.9144 - val_loss: 0.3597 - val_accuracy: 0.9168 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3723 - accuracy: 0.9150 - val_loss: 0.3495 - val_accuracy: 0.9182 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3576 - accuracy: 0.9159 - val_loss: 0.4561 - val_accuracy: 0.8803 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3372 - accuracy: 0.9240 - val_loss: 0.3379 - val_accuracy: 0.9210 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3236 - accuracy: 0.9247 - val_loss: 0.3251 - val_accuracy: 0.9222 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3103 - accuracy: 0.9252 - val_loss: 0.3172 - val_accuracy: 0.9232 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2981 - accuracy: 0.9308 - val_loss: 0.3224 - val_accuracy: 0.9186 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2925 - accuracy: 0.9296 - val_loss: 0.3642 - val_accuracy: 0.9057 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2878 - accuracy: 0.9298 - val_loss: 0.2958 - val_accuracy: 0.9246 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2816 - accuracy: 0.9293 - val_loss: 0.3011 - val_accuracy: 0.9228 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2788 - accuracy: 0.9332 - val_loss: 0.2878 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2722 - accuracy: 0.9309 - val_loss: 0.2791 - val_accuracy: 0.9262 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2661 - accuracy: 0.9329 - val_loss: 0.2840 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2571 - accuracy: 0.9356 - val_loss: 0.2714 - val_accuracy: 0.9298 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2558 - accuracy: 0.9347 - val_loss: 0.2717 - val_accuracy: 0.9302 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2548 - accuracy: 0.9375 - val_loss: 0.2715 - val_accuracy: 0.9286 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2544 - accuracy: 0.9360 - val_loss: 0.2709 - val_accuracy: 0.9310 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2565 - accuracy: 0.9360 - val_loss: 0.2699 - val_accuracy: 0.9298 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2520 - accuracy: 0.9347 - val_loss: 0.2704 - val_accuracy: 0.9294 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2510 - accuracy: 0.9355 - val_loss: 0.2701 - val_accuracy: 0.9302 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2505 - accuracy: 0.9391 - val_loss: 0.2694 - val_accuracy: 0.9310 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2518 - accuracy: 0.9359 - val_loss: 0.2705 - val_accuracy: 0.9308 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2508 - accuracy: 0.9369 - val_loss: 0.2700 - val_accuracy: 0.9308 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2510 - accuracy: 0.9360 - val_loss: 0.2696 - val_accuracy: 0.9308 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2501 - accuracy: 0.9356 - val_loss: 0.2692 - val_accuracy: 0.9314 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2487 - accuracy: 0.9358 - val_loss: 0.2689 - val_accuracy: 0.9310 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2458 - accuracy: 0.9399 - val_loss: 0.2689 - val_accuracy: 0.9312 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2456 - accuracy: 0.9414 - val_loss: 0.2690 - val_accuracy: 0.9310 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2483 - accuracy: 0.9387 - val_loss: 0.2691 - val_accuracy: 0.9310 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2502 - accuracy: 0.9354 - val_loss: 0.2689 - val_accuracy: 0.9306 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2534 - accuracy: 0.9332 - val_loss: 0.2688 - val_accuracy: 0.9310 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2511 - accuracy: 0.9350 - val_loss: 0.2688 - val_accuracy: 0.9310 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.2892 - accuracy: 0.9251\n",
      "17/17 [==============================] - 1s 28ms/step\n",
      "TP:5813, TN:9863, FP:592, FN:678, loss0.2892412543296814, acc0.9250560604272394, sn0.8955476814050224, sp0.94337637494022, f10.9015198511166254, auc0.9743057764342948\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 12s 22ms/step - loss: 3.1895 - accuracy: 0.6640 - val_loss: 2.9071 - val_accuracy: 0.6298 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 2.3974 - accuracy: 0.8043 - val_loss: 2.2008 - val_accuracy: 0.7397 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 1.7928 - accuracy: 0.8431 - val_loss: 1.5740 - val_accuracy: 0.8357 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 1.3514 - accuracy: 0.8565 - val_loss: 1.2347 - val_accuracy: 0.8361 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 1.0409 - accuracy: 0.8709 - val_loss: 0.9106 - val_accuracy: 0.8789 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.8282 - accuracy: 0.8768 - val_loss: 0.7390 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.6881 - accuracy: 0.8835 - val_loss: 0.6287 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.5993 - accuracy: 0.8908 - val_loss: 0.5384 - val_accuracy: 0.9051 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.5337 - accuracy: 0.8954 - val_loss: 0.6242 - val_accuracy: 0.8654 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.5001 - accuracy: 0.8989 - val_loss: 0.4946 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4727 - accuracy: 0.9014 - val_loss: 0.4513 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4594 - accuracy: 0.8997 - val_loss: 0.4597 - val_accuracy: 0.9003 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4379 - accuracy: 0.9013 - val_loss: 0.4252 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4269 - accuracy: 0.9025 - val_loss: 0.4319 - val_accuracy: 0.9025 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4221 - accuracy: 0.9032 - val_loss: 0.4045 - val_accuracy: 0.9112 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4143 - accuracy: 0.9044 - val_loss: 0.4112 - val_accuracy: 0.9073 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.4090 - accuracy: 0.9067 - val_loss: 0.3864 - val_accuracy: 0.9097 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4010 - accuracy: 0.9115 - val_loss: 0.4427 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4097 - accuracy: 0.9065 - val_loss: 0.3765 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3972 - accuracy: 0.9076 - val_loss: 0.5319 - val_accuracy: 0.8498 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3943 - accuracy: 0.9070 - val_loss: 0.5299 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3996 - accuracy: 0.9057 - val_loss: 0.4158 - val_accuracy: 0.8983 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3835 - accuracy: 0.9079 - val_loss: 0.3738 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3889 - accuracy: 0.9079 - val_loss: 0.4323 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3875 - accuracy: 0.9081 - val_loss: 0.3695 - val_accuracy: 0.9174 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3877 - accuracy: 0.9094 - val_loss: 0.3653 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3796 - accuracy: 0.9124 - val_loss: 0.3879 - val_accuracy: 0.9069 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3851 - accuracy: 0.9088 - val_loss: 0.3651 - val_accuracy: 0.9162 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3800 - accuracy: 0.9119 - val_loss: 0.4109 - val_accuracy: 0.8987 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3805 - accuracy: 0.9109 - val_loss: 0.3583 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3768 - accuracy: 0.9139 - val_loss: 0.3774 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3850 - accuracy: 0.9092 - val_loss: 0.3613 - val_accuracy: 0.9204 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3799 - accuracy: 0.9092 - val_loss: 0.3772 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3727 - accuracy: 0.9145 - val_loss: 0.3611 - val_accuracy: 0.9220 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3865 - accuracy: 0.9139 - val_loss: 0.3685 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3881 - accuracy: 0.9093 - val_loss: 0.3781 - val_accuracy: 0.9124 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3708 - accuracy: 0.9126 - val_loss: 0.3908 - val_accuracy: 0.9035 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3743 - accuracy: 0.9131 - val_loss: 0.3848 - val_accuracy: 0.9069 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3789 - accuracy: 0.9124 - val_loss: 0.3693 - val_accuracy: 0.9156 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3739 - accuracy: 0.9175 - val_loss: 0.4407 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3761 - accuracy: 0.9158 - val_loss: 0.4529 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3786 - accuracy: 0.9109 - val_loss: 0.3642 - val_accuracy: 0.9105 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3759 - accuracy: 0.9094 - val_loss: 0.3583 - val_accuracy: 0.9164 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3691 - accuracy: 0.9135 - val_loss: 0.3817 - val_accuracy: 0.9059 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3692 - accuracy: 0.9155 - val_loss: 0.4802 - val_accuracy: 0.8668 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3786 - accuracy: 0.9128 - val_loss: 0.3586 - val_accuracy: 0.9160 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3630 - accuracy: 0.9135 - val_loss: 0.3515 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3692 - accuracy: 0.9120 - val_loss: 0.3859 - val_accuracy: 0.9097 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3662 - accuracy: 0.9141 - val_loss: 0.4197 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3745 - accuracy: 0.9114 - val_loss: 0.3584 - val_accuracy: 0.9186 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3634 - accuracy: 0.9134 - val_loss: 0.4121 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3666 - accuracy: 0.9139 - val_loss: 0.3546 - val_accuracy: 0.9176 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3691 - accuracy: 0.9120 - val_loss: 0.3773 - val_accuracy: 0.9105 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3676 - accuracy: 0.9125 - val_loss: 0.4494 - val_accuracy: 0.8807 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3672 - accuracy: 0.9105 - val_loss: 0.3629 - val_accuracy: 0.9122 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3684 - accuracy: 0.9136 - val_loss: 0.4054 - val_accuracy: 0.8971 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3636 - accuracy: 0.9145 - val_loss: 0.3524 - val_accuracy: 0.9162 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3708 - accuracy: 0.9086 - val_loss: 0.4706 - val_accuracy: 0.8734 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3642 - accuracy: 0.9135 - val_loss: 0.3550 - val_accuracy: 0.9160 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3546 - accuracy: 0.9131 - val_loss: 0.4343 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3545 - accuracy: 0.9175 - val_loss: 0.3579 - val_accuracy: 0.9186 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3584 - accuracy: 0.9160 - val_loss: 0.4044 - val_accuracy: 0.8969 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3580 - accuracy: 0.9149 - val_loss: 0.3697 - val_accuracy: 0.9112 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3620 - accuracy: 0.9112 - val_loss: 0.3362 - val_accuracy: 0.9214 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3516 - accuracy: 0.9162 - val_loss: 0.3516 - val_accuracy: 0.9176 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3621 - accuracy: 0.9156 - val_loss: 0.3497 - val_accuracy: 0.9176 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3692 - accuracy: 0.9127 - val_loss: 0.3721 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3537 - accuracy: 0.9173 - val_loss: 0.4027 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3671 - accuracy: 0.9137 - val_loss: 0.5436 - val_accuracy: 0.8516 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3642 - accuracy: 0.9121 - val_loss: 0.3603 - val_accuracy: 0.9144 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3563 - accuracy: 0.9147 - val_loss: 0.4221 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3352 - accuracy: 0.9223 - val_loss: 0.3295 - val_accuracy: 0.9228 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3164 - accuracy: 0.9267 - val_loss: 0.3312 - val_accuracy: 0.9194 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3044 - accuracy: 0.9294 - val_loss: 0.3404 - val_accuracy: 0.9144 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2923 - accuracy: 0.9322 - val_loss: 0.3766 - val_accuracy: 0.8985 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2898 - accuracy: 0.9299 - val_loss: 0.3097 - val_accuracy: 0.9188 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2805 - accuracy: 0.9299 - val_loss: 0.2924 - val_accuracy: 0.9224 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2721 - accuracy: 0.9333 - val_loss: 0.3015 - val_accuracy: 0.9208 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2727 - accuracy: 0.9307 - val_loss: 0.2804 - val_accuracy: 0.9256 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2652 - accuracy: 0.9317 - val_loss: 0.3050 - val_accuracy: 0.9166 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2627 - accuracy: 0.9321 - val_loss: 0.2987 - val_accuracy: 0.9158 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2525 - accuracy: 0.9355 - val_loss: 0.2732 - val_accuracy: 0.9234 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2544 - accuracy: 0.9336 - val_loss: 0.2705 - val_accuracy: 0.9288 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2523 - accuracy: 0.9360 - val_loss: 0.2681 - val_accuracy: 0.9304 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2510 - accuracy: 0.9347 - val_loss: 0.2680 - val_accuracy: 0.9308 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2472 - accuracy: 0.9382 - val_loss: 0.2680 - val_accuracy: 0.9308 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2467 - accuracy: 0.9380 - val_loss: 0.2672 - val_accuracy: 0.9310 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2470 - accuracy: 0.9351 - val_loss: 0.2669 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2484 - accuracy: 0.9366 - val_loss: 0.2664 - val_accuracy: 0.9326 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2459 - accuracy: 0.9369 - val_loss: 0.2656 - val_accuracy: 0.9298 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2521 - accuracy: 0.9334 - val_loss: 0.2656 - val_accuracy: 0.9300 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2446 - accuracy: 0.9373 - val_loss: 0.2656 - val_accuracy: 0.9314 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2418 - accuracy: 0.9370 - val_loss: 0.2656 - val_accuracy: 0.9316 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2473 - accuracy: 0.9367 - val_loss: 0.2655 - val_accuracy: 0.9316 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2446 - accuracy: 0.9386 - val_loss: 0.2655 - val_accuracy: 0.9316 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2484 - accuracy: 0.9352 - val_loss: 0.2655 - val_accuracy: 0.9316 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2433 - accuracy: 0.9371 - val_loss: 0.2656 - val_accuracy: 0.9312 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2454 - accuracy: 0.9362 - val_loss: 0.2657 - val_accuracy: 0.9320 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2480 - accuracy: 0.9331 - val_loss: 0.2658 - val_accuracy: 0.9310 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2473 - accuracy: 0.9349 - val_loss: 0.2656 - val_accuracy: 0.9312 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.2893 - accuracy: 0.9243\n",
      "17/17 [==============================] - 1s 13ms/step\n",
      "TP:5816, TN:9848, FP:607, FN:675, loss0.2893131375312805, acc0.9243479287147409, sn0.8960098598058851, sp0.9419416547106647, f10.9007278922100046, auc0.9737323083037169\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 12s 22ms/step - loss: 3.2110 - accuracy: 0.6576 - val_loss: 3.1642 - val_accuracy: 0.4491 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 2.4256 - accuracy: 0.8072 - val_loss: 2.3529 - val_accuracy: 0.6406 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 1.8366 - accuracy: 0.8389 - val_loss: 1.6097 - val_accuracy: 0.8367 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 1.3915 - accuracy: 0.8567 - val_loss: 1.2129 - val_accuracy: 0.8594 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 1.0605 - accuracy: 0.8735 - val_loss: 0.9477 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.8478 - accuracy: 0.8825 - val_loss: 0.7871 - val_accuracy: 0.8682 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.7050 - accuracy: 0.8867 - val_loss: 0.6724 - val_accuracy: 0.8751 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.6140 - accuracy: 0.8866 - val_loss: 0.5844 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.5386 - accuracy: 0.8965 - val_loss: 0.5506 - val_accuracy: 0.8797 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4953 - accuracy: 0.8984 - val_loss: 0.4877 - val_accuracy: 0.9015 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4645 - accuracy: 0.9003 - val_loss: 0.4374 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4498 - accuracy: 0.9012 - val_loss: 0.5582 - val_accuracy: 0.8554 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4379 - accuracy: 0.8995 - val_loss: 0.4114 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4195 - accuracy: 0.9057 - val_loss: 0.4021 - val_accuracy: 0.9140 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4156 - accuracy: 0.9037 - val_loss: 0.3938 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.4051 - accuracy: 0.9039 - val_loss: 0.4100 - val_accuracy: 0.9110 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4031 - accuracy: 0.9032 - val_loss: 0.4480 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4001 - accuracy: 0.9074 - val_loss: 0.3717 - val_accuracy: 0.9174 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3897 - accuracy: 0.9077 - val_loss: 0.5690 - val_accuracy: 0.8327 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3949 - accuracy: 0.9054 - val_loss: 0.4196 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3986 - accuracy: 0.9044 - val_loss: 0.4424 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3880 - accuracy: 0.9100 - val_loss: 0.3826 - val_accuracy: 0.9118 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3885 - accuracy: 0.9093 - val_loss: 0.4013 - val_accuracy: 0.9035 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3881 - accuracy: 0.9097 - val_loss: 0.4566 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3790 - accuracy: 0.9108 - val_loss: 0.5180 - val_accuracy: 0.8538 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3822 - accuracy: 0.9079 - val_loss: 0.3734 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3770 - accuracy: 0.9092 - val_loss: 0.3812 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3808 - accuracy: 0.9121 - val_loss: 0.3652 - val_accuracy: 0.9174 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3837 - accuracy: 0.9050 - val_loss: 0.4759 - val_accuracy: 0.8688 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3811 - accuracy: 0.9102 - val_loss: 0.3676 - val_accuracy: 0.9118 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3651 - accuracy: 0.9126 - val_loss: 0.3538 - val_accuracy: 0.9162 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3698 - accuracy: 0.9120 - val_loss: 0.3538 - val_accuracy: 0.9198 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3768 - accuracy: 0.9107 - val_loss: 0.4106 - val_accuracy: 0.9027 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3715 - accuracy: 0.9140 - val_loss: 0.3620 - val_accuracy: 0.9170 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3699 - accuracy: 0.9123 - val_loss: 0.3683 - val_accuracy: 0.9162 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3745 - accuracy: 0.9122 - val_loss: 0.3536 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3785 - accuracy: 0.9093 - val_loss: 0.3666 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3723 - accuracy: 0.9125 - val_loss: 0.3723 - val_accuracy: 0.9114 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3728 - accuracy: 0.9109 - val_loss: 0.3744 - val_accuracy: 0.9138 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3790 - accuracy: 0.9113 - val_loss: 0.3743 - val_accuracy: 0.9116 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3679 - accuracy: 0.9126 - val_loss: 0.3710 - val_accuracy: 0.9138 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3715 - accuracy: 0.9140 - val_loss: 0.4461 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3826 - accuracy: 0.9097 - val_loss: 0.3711 - val_accuracy: 0.9148 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3691 - accuracy: 0.9118 - val_loss: 0.4981 - val_accuracy: 0.8624 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3748 - accuracy: 0.9130 - val_loss: 0.3740 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3665 - accuracy: 0.9143 - val_loss: 0.3866 - val_accuracy: 0.9063 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3792 - accuracy: 0.9100 - val_loss: 0.3970 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3708 - accuracy: 0.9128 - val_loss: 0.3668 - val_accuracy: 0.9148 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3720 - accuracy: 0.9127 - val_loss: 0.5044 - val_accuracy: 0.8554 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3745 - accuracy: 0.9104 - val_loss: 0.5178 - val_accuracy: 0.8716 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3635 - accuracy: 0.9152 - val_loss: 0.4142 - val_accuracy: 0.8957 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3800 - accuracy: 0.9112 - val_loss: 0.4308 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3669 - accuracy: 0.9131 - val_loss: 0.3595 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3661 - accuracy: 0.9136 - val_loss: 0.3932 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3678 - accuracy: 0.9137 - val_loss: 0.3523 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3576 - accuracy: 0.9143 - val_loss: 0.4086 - val_accuracy: 0.9039 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3683 - accuracy: 0.9123 - val_loss: 0.3540 - val_accuracy: 0.9198 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3738 - accuracy: 0.9138 - val_loss: 0.3693 - val_accuracy: 0.9126 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3667 - accuracy: 0.9146 - val_loss: 0.4999 - val_accuracy: 0.8498 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3773 - accuracy: 0.9109 - val_loss: 0.3946 - val_accuracy: 0.8985 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3631 - accuracy: 0.9160 - val_loss: 0.3591 - val_accuracy: 0.9116 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3606 - accuracy: 0.9164 - val_loss: 0.3492 - val_accuracy: 0.9190 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3568 - accuracy: 0.9168 - val_loss: 0.3905 - val_accuracy: 0.9021 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3714 - accuracy: 0.9112 - val_loss: 0.3912 - val_accuracy: 0.9079 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3567 - accuracy: 0.9153 - val_loss: 0.4164 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3665 - accuracy: 0.9139 - val_loss: 0.3781 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3589 - accuracy: 0.9156 - val_loss: 0.3499 - val_accuracy: 0.9190 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.3581 - accuracy: 0.9155 - val_loss: 0.4855 - val_accuracy: 0.8712 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3621 - accuracy: 0.9140 - val_loss: 0.3426 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3500 - accuracy: 0.9178 - val_loss: 0.3939 - val_accuracy: 0.9027 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3601 - accuracy: 0.9151 - val_loss: 0.3479 - val_accuracy: 0.9200 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3374 - accuracy: 0.9233 - val_loss: 0.3398 - val_accuracy: 0.9178 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3209 - accuracy: 0.9261 - val_loss: 0.3194 - val_accuracy: 0.9236 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3083 - accuracy: 0.9284 - val_loss: 0.3391 - val_accuracy: 0.9134 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2989 - accuracy: 0.9289 - val_loss: 0.3055 - val_accuracy: 0.9232 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2918 - accuracy: 0.9285 - val_loss: 0.3038 - val_accuracy: 0.9254 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2833 - accuracy: 0.9294 - val_loss: 0.3115 - val_accuracy: 0.9186 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2787 - accuracy: 0.9302 - val_loss: 0.2870 - val_accuracy: 0.9274 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2731 - accuracy: 0.9313 - val_loss: 0.3109 - val_accuracy: 0.9160 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2709 - accuracy: 0.9309 - val_loss: 0.3052 - val_accuracy: 0.9184 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2619 - accuracy: 0.9344 - val_loss: 0.2976 - val_accuracy: 0.9178 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2528 - accuracy: 0.9362 - val_loss: 0.2735 - val_accuracy: 0.9258 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2545 - accuracy: 0.9332 - val_loss: 0.2691 - val_accuracy: 0.9280 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2528 - accuracy: 0.9346 - val_loss: 0.2684 - val_accuracy: 0.9308 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2578 - accuracy: 0.9339 - val_loss: 0.2672 - val_accuracy: 0.9320 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2467 - accuracy: 0.9374 - val_loss: 0.2675 - val_accuracy: 0.9318 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2503 - accuracy: 0.9353 - val_loss: 0.2664 - val_accuracy: 0.9322 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2509 - accuracy: 0.9367 - val_loss: 0.2661 - val_accuracy: 0.9320 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2540 - accuracy: 0.9343 - val_loss: 0.2666 - val_accuracy: 0.9314 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2473 - accuracy: 0.9353 - val_loss: 0.2666 - val_accuracy: 0.9312 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2482 - accuracy: 0.9364 - val_loss: 0.2661 - val_accuracy: 0.9322 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2495 - accuracy: 0.9363 - val_loss: 0.2661 - val_accuracy: 0.9318 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2512 - accuracy: 0.9344 - val_loss: 0.2659 - val_accuracy: 0.9320 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2455 - accuracy: 0.9352 - val_loss: 0.2659 - val_accuracy: 0.9326 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2434 - accuracy: 0.9380 - val_loss: 0.2658 - val_accuracy: 0.9328 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2479 - accuracy: 0.9339 - val_loss: 0.2657 - val_accuracy: 0.9324 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2444 - accuracy: 0.9367 - val_loss: 0.2657 - val_accuracy: 0.9330 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2455 - accuracy: 0.9368 - val_loss: 0.2658 - val_accuracy: 0.9328 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2464 - accuracy: 0.9358 - val_loss: 0.2656 - val_accuracy: 0.9324 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2493 - accuracy: 0.9353 - val_loss: 0.2655 - val_accuracy: 0.9324 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.2892 - accuracy: 0.9239\n",
      "17/17 [==============================] - 1s 12ms/step\n",
      "TP:5795, TN:9861, FP:594, FN:696, loss0.2891656458377838, acc0.9238758409064086, sn0.8927746109998459, sp0.9431850789096127, f10.8998447204968945, auc0.9736778680645333\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 12s 25ms/step - loss: 3.1850 - accuracy: 0.6611 - val_loss: 3.4415 - val_accuracy: 0.4152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 2.3744 - accuracy: 0.8129 - val_loss: 2.1856 - val_accuracy: 0.7385 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 1.7888 - accuracy: 0.8426 - val_loss: 1.6620 - val_accuracy: 0.7852 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 1.3456 - accuracy: 0.8601 - val_loss: 1.1523 - val_accuracy: 0.8648 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 1.0413 - accuracy: 0.8650 - val_loss: 0.9068 - val_accuracy: 0.8728 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.8155 - accuracy: 0.8784 - val_loss: 0.7212 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.6833 - accuracy: 0.8844 - val_loss: 0.6242 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.5874 - accuracy: 0.8905 - val_loss: 0.5601 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.5235 - accuracy: 0.8962 - val_loss: 0.5947 - val_accuracy: 0.8564 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4846 - accuracy: 0.9015 - val_loss: 0.5194 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4740 - accuracy: 0.8958 - val_loss: 0.4327 - val_accuracy: 0.9112 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4411 - accuracy: 0.9024 - val_loss: 0.4672 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4314 - accuracy: 0.9047 - val_loss: 0.4520 - val_accuracy: 0.9037 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4232 - accuracy: 0.9055 - val_loss: 0.4119 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4163 - accuracy: 0.9073 - val_loss: 0.4308 - val_accuracy: 0.8961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4089 - accuracy: 0.9075 - val_loss: 0.4091 - val_accuracy: 0.9077 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4010 - accuracy: 0.9089 - val_loss: 0.4230 - val_accuracy: 0.8945 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4042 - accuracy: 0.9084 - val_loss: 0.3894 - val_accuracy: 0.9166 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4014 - accuracy: 0.9065 - val_loss: 0.3909 - val_accuracy: 0.9065 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3949 - accuracy: 0.9054 - val_loss: 0.3841 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3940 - accuracy: 0.9052 - val_loss: 0.4053 - val_accuracy: 0.9079 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3960 - accuracy: 0.9070 - val_loss: 0.3763 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3907 - accuracy: 0.9102 - val_loss: 0.4279 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3820 - accuracy: 0.9102 - val_loss: 0.3698 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3817 - accuracy: 0.9131 - val_loss: 0.3864 - val_accuracy: 0.9105 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3865 - accuracy: 0.9074 - val_loss: 0.4448 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3818 - accuracy: 0.9084 - val_loss: 0.5825 - val_accuracy: 0.8468 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3773 - accuracy: 0.9093 - val_loss: 0.3646 - val_accuracy: 0.9166 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3837 - accuracy: 0.9103 - val_loss: 0.3748 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3780 - accuracy: 0.9120 - val_loss: 0.3644 - val_accuracy: 0.9158 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3818 - accuracy: 0.9103 - val_loss: 0.3690 - val_accuracy: 0.9192 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3807 - accuracy: 0.9114 - val_loss: 0.3687 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3839 - accuracy: 0.9124 - val_loss: 0.3849 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3882 - accuracy: 0.9080 - val_loss: 0.4142 - val_accuracy: 0.8983 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3853 - accuracy: 0.9107 - val_loss: 0.4829 - val_accuracy: 0.8556 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3834 - accuracy: 0.9111 - val_loss: 0.3656 - val_accuracy: 0.9158 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3692 - accuracy: 0.9138 - val_loss: 0.3634 - val_accuracy: 0.9164 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3807 - accuracy: 0.9114 - val_loss: 0.3656 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3813 - accuracy: 0.9102 - val_loss: 0.4300 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3782 - accuracy: 0.9122 - val_loss: 0.4087 - val_accuracy: 0.8989 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3686 - accuracy: 0.9152 - val_loss: 0.4658 - val_accuracy: 0.8738 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3923 - accuracy: 0.9070 - val_loss: 0.4162 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3708 - accuracy: 0.9137 - val_loss: 0.3988 - val_accuracy: 0.9051 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3763 - accuracy: 0.9127 - val_loss: 0.4629 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3755 - accuracy: 0.9119 - val_loss: 0.3610 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3714 - accuracy: 0.9128 - val_loss: 0.4383 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3788 - accuracy: 0.9139 - val_loss: 0.4362 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3758 - accuracy: 0.9137 - val_loss: 0.4383 - val_accuracy: 0.8827 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3722 - accuracy: 0.9138 - val_loss: 0.3731 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3745 - accuracy: 0.9120 - val_loss: 0.4314 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3744 - accuracy: 0.9103 - val_loss: 0.3643 - val_accuracy: 0.9200 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3757 - accuracy: 0.9138 - val_loss: 0.4120 - val_accuracy: 0.9015 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3667 - accuracy: 0.9161 - val_loss: 0.3582 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3692 - accuracy: 0.9159 - val_loss: 0.3668 - val_accuracy: 0.9138 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3731 - accuracy: 0.9129 - val_loss: 0.3817 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3677 - accuracy: 0.9138 - val_loss: 0.3952 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3742 - accuracy: 0.9165 - val_loss: 0.3509 - val_accuracy: 0.9240 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3717 - accuracy: 0.9149 - val_loss: 0.3884 - val_accuracy: 0.9079 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3694 - accuracy: 0.9139 - val_loss: 0.3703 - val_accuracy: 0.9138 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3789 - accuracy: 0.9106 - val_loss: 0.3548 - val_accuracy: 0.9200 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3770 - accuracy: 0.9112 - val_loss: 0.5454 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3655 - accuracy: 0.9143 - val_loss: 0.3669 - val_accuracy: 0.9162 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3702 - accuracy: 0.9122 - val_loss: 0.3829 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3755 - accuracy: 0.9113 - val_loss: 0.4159 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3638 - accuracy: 0.9137 - val_loss: 0.4007 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3670 - accuracy: 0.9167 - val_loss: 0.3756 - val_accuracy: 0.9140 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3731 - accuracy: 0.9146 - val_loss: 0.4218 - val_accuracy: 0.9059 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3696 - accuracy: 0.9150 - val_loss: 0.3915 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3664 - accuracy: 0.9132 - val_loss: 0.3521 - val_accuracy: 0.9190 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3657 - accuracy: 0.9158 - val_loss: 0.3729 - val_accuracy: 0.9126 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3703 - accuracy: 0.9117 - val_loss: 0.5925 - val_accuracy: 0.8297 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3502 - accuracy: 0.9197 - val_loss: 0.3511 - val_accuracy: 0.9202 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3311 - accuracy: 0.9244 - val_loss: 0.3558 - val_accuracy: 0.9148 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3214 - accuracy: 0.9226 - val_loss: 0.3484 - val_accuracy: 0.9146 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3122 - accuracy: 0.9259 - val_loss: 0.3453 - val_accuracy: 0.9099 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.2942 - accuracy: 0.9284 - val_loss: 0.3173 - val_accuracy: 0.9188 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2870 - accuracy: 0.9291 - val_loss: 0.3076 - val_accuracy: 0.9208 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2840 - accuracy: 0.9299 - val_loss: 0.3026 - val_accuracy: 0.9178 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2772 - accuracy: 0.9308 - val_loss: 0.3224 - val_accuracy: 0.9116 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2703 - accuracy: 0.9301 - val_loss: 0.2999 - val_accuracy: 0.9188 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2681 - accuracy: 0.9299 - val_loss: 0.3195 - val_accuracy: 0.9138 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2614 - accuracy: 0.9346 - val_loss: 0.2778 - val_accuracy: 0.9254 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2570 - accuracy: 0.9320 - val_loss: 0.2748 - val_accuracy: 0.9288 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2569 - accuracy: 0.9343 - val_loss: 0.2746 - val_accuracy: 0.9298 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2568 - accuracy: 0.9326 - val_loss: 0.2730 - val_accuracy: 0.9296 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2562 - accuracy: 0.9338 - val_loss: 0.2730 - val_accuracy: 0.9300 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2564 - accuracy: 0.9341 - val_loss: 0.2718 - val_accuracy: 0.9300 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2545 - accuracy: 0.9364 - val_loss: 0.2719 - val_accuracy: 0.9296 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2518 - accuracy: 0.9358 - val_loss: 0.2729 - val_accuracy: 0.9294 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2495 - accuracy: 0.9339 - val_loss: 0.2715 - val_accuracy: 0.9300 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2502 - accuracy: 0.9362 - val_loss: 0.2710 - val_accuracy: 0.9300 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2464 - accuracy: 0.9379 - val_loss: 0.2710 - val_accuracy: 0.9294 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2485 - accuracy: 0.9371 - val_loss: 0.2711 - val_accuracy: 0.9292 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2512 - accuracy: 0.9353 - val_loss: 0.2710 - val_accuracy: 0.9294 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2515 - accuracy: 0.9362 - val_loss: 0.2708 - val_accuracy: 0.9294 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2511 - accuracy: 0.9341 - val_loss: 0.2709 - val_accuracy: 0.9290 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2532 - accuracy: 0.9343 - val_loss: 0.2709 - val_accuracy: 0.9290 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2476 - accuracy: 0.9353 - val_loss: 0.2709 - val_accuracy: 0.9292 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2499 - accuracy: 0.9365 - val_loss: 0.2708 - val_accuracy: 0.9298 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2509 - accuracy: 0.9381 - val_loss: 0.2707 - val_accuracy: 0.9294 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.2890 - accuracy: 0.9251\n",
      "17/17 [==============================] - 1s 12ms/step\n",
      "TP:5801, TN:9876, FP:579, FN:690, loss0.28897666931152344, acc0.925115071403281, sn0.8936989678015714, sp0.9446197991391678, f10.9014062621396938, auc0.9741246405187008\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 11s 25ms/step - loss: 3.2447 - accuracy: 0.6404 - val_loss: 3.1527 - val_accuracy: 0.4055 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 2.4688 - accuracy: 0.7778 - val_loss: 2.2537 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 1.8703 - accuracy: 0.8236 - val_loss: 1.6344 - val_accuracy: 0.8339 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 1.4244 - accuracy: 0.8439 - val_loss: 1.2787 - val_accuracy: 0.8379 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 1.0844 - accuracy: 0.8622 - val_loss: 0.9626 - val_accuracy: 0.8702 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.8710 - accuracy: 0.8736 - val_loss: 0.9844 - val_accuracy: 0.7702 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.7228 - accuracy: 0.8778 - val_loss: 0.6602 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.6210 - accuracy: 0.8858 - val_loss: 0.5739 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.5584 - accuracy: 0.8901 - val_loss: 0.6795 - val_accuracy: 0.8524 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.5118 - accuracy: 0.8936 - val_loss: 0.5223 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4809 - accuracy: 0.8984 - val_loss: 0.4666 - val_accuracy: 0.9001 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4579 - accuracy: 0.9020 - val_loss: 0.4891 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.4429 - accuracy: 0.9003 - val_loss: 0.4212 - val_accuracy: 0.9101 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4319 - accuracy: 0.9026 - val_loss: 0.4476 - val_accuracy: 0.9019 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4234 - accuracy: 0.9039 - val_loss: 0.4136 - val_accuracy: 0.9114 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4192 - accuracy: 0.9046 - val_loss: 0.5501 - val_accuracy: 0.8472 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4084 - accuracy: 0.9090 - val_loss: 0.4067 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4132 - accuracy: 0.9065 - val_loss: 0.4105 - val_accuracy: 0.9120 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3992 - accuracy: 0.9091 - val_loss: 0.3871 - val_accuracy: 0.9140 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4053 - accuracy: 0.9056 - val_loss: 0.3920 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4029 - accuracy: 0.9080 - val_loss: 0.3970 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3942 - accuracy: 0.9089 - val_loss: 0.4139 - val_accuracy: 0.8997 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3934 - accuracy: 0.9102 - val_loss: 0.3824 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3823 - accuracy: 0.9126 - val_loss: 0.4247 - val_accuracy: 0.8955 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3948 - accuracy: 0.9105 - val_loss: 0.3843 - val_accuracy: 0.9122 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3986 - accuracy: 0.9064 - val_loss: 0.3788 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3853 - accuracy: 0.9097 - val_loss: 0.3787 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3805 - accuracy: 0.9109 - val_loss: 0.4589 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3844 - accuracy: 0.9113 - val_loss: 0.3894 - val_accuracy: 0.9122 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3880 - accuracy: 0.9088 - val_loss: 0.3647 - val_accuracy: 0.9164 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3776 - accuracy: 0.9128 - val_loss: 0.4124 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3818 - accuracy: 0.9101 - val_loss: 0.3654 - val_accuracy: 0.9166 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3790 - accuracy: 0.9119 - val_loss: 0.4009 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3779 - accuracy: 0.9098 - val_loss: 0.4223 - val_accuracy: 0.8999 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3775 - accuracy: 0.9110 - val_loss: 0.3642 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3811 - accuracy: 0.9091 - val_loss: 0.3896 - val_accuracy: 0.9049 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3689 - accuracy: 0.9104 - val_loss: 0.3753 - val_accuracy: 0.9140 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3779 - accuracy: 0.9133 - val_loss: 0.4365 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3764 - accuracy: 0.9134 - val_loss: 0.3714 - val_accuracy: 0.9140 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3783 - accuracy: 0.9118 - val_loss: 0.4190 - val_accuracy: 0.8987 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3721 - accuracy: 0.9120 - val_loss: 0.4576 - val_accuracy: 0.8791 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3753 - accuracy: 0.9124 - val_loss: 0.4013 - val_accuracy: 0.9057 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3762 - accuracy: 0.9117 - val_loss: 0.3586 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3667 - accuracy: 0.9126 - val_loss: 0.3825 - val_accuracy: 0.9110 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3667 - accuracy: 0.9116 - val_loss: 0.3897 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3648 - accuracy: 0.9134 - val_loss: 0.4927 - val_accuracy: 0.8742 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3659 - accuracy: 0.9135 - val_loss: 0.3710 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3651 - accuracy: 0.9165 - val_loss: 0.3583 - val_accuracy: 0.9160 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3732 - accuracy: 0.9109 - val_loss: 0.4088 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3619 - accuracy: 0.9166 - val_loss: 0.5668 - val_accuracy: 0.8263 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3758 - accuracy: 0.9105 - val_loss: 0.3779 - val_accuracy: 0.9069 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3640 - accuracy: 0.9167 - val_loss: 0.3587 - val_accuracy: 0.9170 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3711 - accuracy: 0.9148 - val_loss: 0.3716 - val_accuracy: 0.9087 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3645 - accuracy: 0.9140 - val_loss: 0.3598 - val_accuracy: 0.9170 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3582 - accuracy: 0.9154 - val_loss: 0.3587 - val_accuracy: 0.9188 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3698 - accuracy: 0.9155 - val_loss: 0.3712 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3742 - accuracy: 0.9115 - val_loss: 0.3656 - val_accuracy: 0.9182 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3610 - accuracy: 0.9150 - val_loss: 0.3612 - val_accuracy: 0.9142 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3759 - accuracy: 0.9132 - val_loss: 0.3412 - val_accuracy: 0.9216 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3591 - accuracy: 0.9167 - val_loss: 0.3924 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3756 - accuracy: 0.9126 - val_loss: 0.3752 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3641 - accuracy: 0.9155 - val_loss: 0.4104 - val_accuracy: 0.8935 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3717 - accuracy: 0.9134 - val_loss: 0.3644 - val_accuracy: 0.9180 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3643 - accuracy: 0.9156 - val_loss: 0.4279 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3703 - accuracy: 0.9140 - val_loss: 0.3750 - val_accuracy: 0.9162 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3616 - accuracy: 0.9155 - val_loss: 0.3601 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3602 - accuracy: 0.9154 - val_loss: 0.3774 - val_accuracy: 0.9055 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3658 - accuracy: 0.9103 - val_loss: 0.4899 - val_accuracy: 0.8759 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3649 - accuracy: 0.9134 - val_loss: 0.3460 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3529 - accuracy: 0.9158 - val_loss: 0.3452 - val_accuracy: 0.9210 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3594 - accuracy: 0.9170 - val_loss: 0.3427 - val_accuracy: 0.9228 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3334 - accuracy: 0.9252 - val_loss: 0.3544 - val_accuracy: 0.9164 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3208 - accuracy: 0.9263 - val_loss: 0.3619 - val_accuracy: 0.9126 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3157 - accuracy: 0.9268 - val_loss: 0.3161 - val_accuracy: 0.9222 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3011 - accuracy: 0.9286 - val_loss: 0.3195 - val_accuracy: 0.9204 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.2844 - accuracy: 0.9305 - val_loss: 0.3257 - val_accuracy: 0.9168 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2862 - accuracy: 0.9312 - val_loss: 0.3029 - val_accuracy: 0.9208 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2799 - accuracy: 0.9292 - val_loss: 0.2858 - val_accuracy: 0.9254 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2729 - accuracy: 0.9297 - val_loss: 0.2966 - val_accuracy: 0.9216 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2660 - accuracy: 0.9312 - val_loss: 0.2835 - val_accuracy: 0.9236 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2688 - accuracy: 0.9293 - val_loss: 0.2730 - val_accuracy: 0.9274 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2563 - accuracy: 0.9350 - val_loss: 0.2736 - val_accuracy: 0.9282 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2575 - accuracy: 0.9344 - val_loss: 0.2738 - val_accuracy: 0.9288 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.2536 - accuracy: 0.9365 - val_loss: 0.2722 - val_accuracy: 0.9300 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2548 - accuracy: 0.9336 - val_loss: 0.2707 - val_accuracy: 0.9296 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2549 - accuracy: 0.9344 - val_loss: 0.2697 - val_accuracy: 0.9298 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2474 - accuracy: 0.9345 - val_loss: 0.2695 - val_accuracy: 0.9292 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2496 - accuracy: 0.9376 - val_loss: 0.2688 - val_accuracy: 0.9290 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2494 - accuracy: 0.9357 - val_loss: 0.2694 - val_accuracy: 0.9290 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2513 - accuracy: 0.9343 - val_loss: 0.2678 - val_accuracy: 0.9302 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2476 - accuracy: 0.9381 - val_loss: 0.2669 - val_accuracy: 0.9304 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2471 - accuracy: 0.9359 - val_loss: 0.2669 - val_accuracy: 0.9296 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.2513 - accuracy: 0.9376 - val_loss: 0.2670 - val_accuracy: 0.9300 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2516 - accuracy: 0.9351 - val_loss: 0.2672 - val_accuracy: 0.9310 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2495 - accuracy: 0.9373 - val_loss: 0.2672 - val_accuracy: 0.9308 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2497 - accuracy: 0.9338 - val_loss: 0.2670 - val_accuracy: 0.9308 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2508 - accuracy: 0.9366 - val_loss: 0.2670 - val_accuracy: 0.9306 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2486 - accuracy: 0.9368 - val_loss: 0.2670 - val_accuracy: 0.9302 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2520 - accuracy: 0.9340 - val_loss: 0.2668 - val_accuracy: 0.9308 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2505 - accuracy: 0.9359 - val_loss: 0.2671 - val_accuracy: 0.9304 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.2889 - accuracy: 0.9254\n",
      "17/17 [==============================] - 1s 13ms/step\n",
      "TP:5812, TN:9870, FP:585, FN:679, loss0.28892481327056885, acc0.9254101262834887, sn0.895393621938068, sp0.9440459110473458, f10.9019242706393544, auc0.9738825807517321\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 12s 24ms/step - loss: 3.2268 - accuracy: 0.6557 - val_loss: 3.3494 - val_accuracy: 0.4376 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 2.4363 - accuracy: 0.8094 - val_loss: 2.3858 - val_accuracy: 0.6211 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 1.8538 - accuracy: 0.8415 - val_loss: 1.6181 - val_accuracy: 0.8389 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 1.4064 - accuracy: 0.8586 - val_loss: 1.2148 - val_accuracy: 0.8628 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 1.0817 - accuracy: 0.8679 - val_loss: 0.9379 - val_accuracy: 0.8771 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.8484 - accuracy: 0.8798 - val_loss: 0.7961 - val_accuracy: 0.8648 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.7109 - accuracy: 0.8835 - val_loss: 0.6437 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.5997 - accuracy: 0.8949 - val_loss: 0.8799 - val_accuracy: 0.7796 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.5393 - accuracy: 0.8949 - val_loss: 0.6161 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.5080 - accuracy: 0.8929 - val_loss: 0.5070 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4679 - accuracy: 0.8991 - val_loss: 0.4990 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.4397 - accuracy: 0.9053 - val_loss: 0.4466 - val_accuracy: 0.9019 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4395 - accuracy: 0.9007 - val_loss: 0.4990 - val_accuracy: 0.8696 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4320 - accuracy: 0.9008 - val_loss: 0.4165 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4139 - accuracy: 0.9084 - val_loss: 0.4184 - val_accuracy: 0.9013 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.4085 - accuracy: 0.9061 - val_loss: 0.3786 - val_accuracy: 0.9134 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4100 - accuracy: 0.9073 - val_loss: 0.4024 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4035 - accuracy: 0.9083 - val_loss: 0.4222 - val_accuracy: 0.9003 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3978 - accuracy: 0.9082 - val_loss: 0.4011 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4033 - accuracy: 0.9061 - val_loss: 0.4346 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3894 - accuracy: 0.9067 - val_loss: 0.3695 - val_accuracy: 0.9138 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3874 - accuracy: 0.9100 - val_loss: 0.3984 - val_accuracy: 0.9003 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3867 - accuracy: 0.9073 - val_loss: 0.3993 - val_accuracy: 0.9087 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3951 - accuracy: 0.9072 - val_loss: 0.4204 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3883 - accuracy: 0.9069 - val_loss: 0.4402 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3978 - accuracy: 0.9056 - val_loss: 0.4372 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3887 - accuracy: 0.9078 - val_loss: 0.3919 - val_accuracy: 0.9069 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3829 - accuracy: 0.9109 - val_loss: 0.3773 - val_accuracy: 0.9148 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3853 - accuracy: 0.9109 - val_loss: 0.3837 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3890 - accuracy: 0.9126 - val_loss: 0.4305 - val_accuracy: 0.8979 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3862 - accuracy: 0.9107 - val_loss: 0.4894 - val_accuracy: 0.8582 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3814 - accuracy: 0.9088 - val_loss: 0.3613 - val_accuracy: 0.9146 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3906 - accuracy: 0.9056 - val_loss: 0.3777 - val_accuracy: 0.9142 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3739 - accuracy: 0.9129 - val_loss: 0.4141 - val_accuracy: 0.8969 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3789 - accuracy: 0.9113 - val_loss: 0.3782 - val_accuracy: 0.9148 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3860 - accuracy: 0.9088 - val_loss: 0.3685 - val_accuracy: 0.9142 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3739 - accuracy: 0.9129 - val_loss: 0.3648 - val_accuracy: 0.9160 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3776 - accuracy: 0.9091 - val_loss: 0.3601 - val_accuracy: 0.9182 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3791 - accuracy: 0.9111 - val_loss: 0.4053 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3808 - accuracy: 0.9136 - val_loss: 0.3786 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3769 - accuracy: 0.9115 - val_loss: 0.3668 - val_accuracy: 0.9148 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3761 - accuracy: 0.9106 - val_loss: 0.3832 - val_accuracy: 0.9116 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3765 - accuracy: 0.9114 - val_loss: 0.6219 - val_accuracy: 0.8147 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3723 - accuracy: 0.9123 - val_loss: 0.4039 - val_accuracy: 0.9043 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3690 - accuracy: 0.9151 - val_loss: 0.3606 - val_accuracy: 0.9172 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3801 - accuracy: 0.9115 - val_loss: 0.3784 - val_accuracy: 0.9099 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3784 - accuracy: 0.9104 - val_loss: 0.3945 - val_accuracy: 0.9013 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3691 - accuracy: 0.9132 - val_loss: 0.3492 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3693 - accuracy: 0.9140 - val_loss: 0.3649 - val_accuracy: 0.9138 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3692 - accuracy: 0.9129 - val_loss: 0.3511 - val_accuracy: 0.9176 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3713 - accuracy: 0.9114 - val_loss: 0.3502 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3702 - accuracy: 0.9138 - val_loss: 0.4366 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3671 - accuracy: 0.9127 - val_loss: 0.3738 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3671 - accuracy: 0.9151 - val_loss: 0.3564 - val_accuracy: 0.9158 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3649 - accuracy: 0.9146 - val_loss: 0.3554 - val_accuracy: 0.9194 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3707 - accuracy: 0.9126 - val_loss: 0.3499 - val_accuracy: 0.9216 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3702 - accuracy: 0.9108 - val_loss: 0.3871 - val_accuracy: 0.9045 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3631 - accuracy: 0.9137 - val_loss: 0.3580 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3660 - accuracy: 0.9099 - val_loss: 0.3587 - val_accuracy: 0.9162 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3556 - accuracy: 0.9155 - val_loss: 0.3598 - val_accuracy: 0.9156 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3624 - accuracy: 0.9158 - val_loss: 0.3781 - val_accuracy: 0.9116 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3668 - accuracy: 0.9132 - val_loss: 0.3540 - val_accuracy: 0.9160 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3629 - accuracy: 0.9136 - val_loss: 0.3672 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3698 - accuracy: 0.9100 - val_loss: 0.3553 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3574 - accuracy: 0.9153 - val_loss: 0.4332 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3583 - accuracy: 0.9159 - val_loss: 0.3465 - val_accuracy: 0.9222 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3658 - accuracy: 0.9145 - val_loss: 0.3663 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3572 - accuracy: 0.9185 - val_loss: 0.3722 - val_accuracy: 0.9110 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3613 - accuracy: 0.9169 - val_loss: 0.3610 - val_accuracy: 0.9134 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3627 - accuracy: 0.9152 - val_loss: 0.3603 - val_accuracy: 0.9158 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.3776 - accuracy: 0.9116 - val_loss: 0.3636 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3395 - accuracy: 0.9213 - val_loss: 0.3446 - val_accuracy: 0.9168 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3171 - accuracy: 0.9279 - val_loss: 0.3296 - val_accuracy: 0.9194 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3091 - accuracy: 0.9267 - val_loss: 0.3473 - val_accuracy: 0.9105 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3019 - accuracy: 0.9295 - val_loss: 0.3167 - val_accuracy: 0.9226 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2897 - accuracy: 0.9258 - val_loss: 0.3286 - val_accuracy: 0.9156 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2875 - accuracy: 0.9288 - val_loss: 0.3068 - val_accuracy: 0.9188 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2806 - accuracy: 0.9291 - val_loss: 0.2898 - val_accuracy: 0.9224 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2725 - accuracy: 0.9317 - val_loss: 0.2863 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.2720 - accuracy: 0.9293 - val_loss: 0.2985 - val_accuracy: 0.9182 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2608 - accuracy: 0.9351 - val_loss: 0.2808 - val_accuracy: 0.9232 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2559 - accuracy: 0.9339 - val_loss: 0.2724 - val_accuracy: 0.9274 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2568 - accuracy: 0.9321 - val_loss: 0.2702 - val_accuracy: 0.9280 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2543 - accuracy: 0.9359 - val_loss: 0.2693 - val_accuracy: 0.9284 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2519 - accuracy: 0.9357 - val_loss: 0.2689 - val_accuracy: 0.9288 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2514 - accuracy: 0.9360 - val_loss: 0.2679 - val_accuracy: 0.9286 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2526 - accuracy: 0.9353 - val_loss: 0.2670 - val_accuracy: 0.9292 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2506 - accuracy: 0.9341 - val_loss: 0.2664 - val_accuracy: 0.9302 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2490 - accuracy: 0.9341 - val_loss: 0.2663 - val_accuracy: 0.9298 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2500 - accuracy: 0.9366 - val_loss: 0.2667 - val_accuracy: 0.9290 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2497 - accuracy: 0.9352 - val_loss: 0.2650 - val_accuracy: 0.9290 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2438 - accuracy: 0.9371 - val_loss: 0.2653 - val_accuracy: 0.9296 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2466 - accuracy: 0.9372 - val_loss: 0.2657 - val_accuracy: 0.9298 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2465 - accuracy: 0.9351 - val_loss: 0.2658 - val_accuracy: 0.9292 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2488 - accuracy: 0.9354 - val_loss: 0.2660 - val_accuracy: 0.9290 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2449 - accuracy: 0.9368 - val_loss: 0.2658 - val_accuracy: 0.9290 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2479 - accuracy: 0.9354 - val_loss: 0.2659 - val_accuracy: 0.9302 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2435 - accuracy: 0.9400 - val_loss: 0.2656 - val_accuracy: 0.9294 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.2463 - accuracy: 0.9363 - val_loss: 0.2656 - val_accuracy: 0.9298 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2477 - accuracy: 0.9373 - val_loss: 0.2657 - val_accuracy: 0.9294 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 0.2860 - accuracy: 0.9242\n",
      "17/17 [==============================] - 1s 13ms/step\n",
      "TP:5822, TN:9839, FP:616, FN:669, loss0.28595972061157227, acc0.9241708957866163, sn0.8969342166076105, sp0.9410808225729316, f10.9006110294686364, auc0.9740366549541686\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 11s 25ms/step - loss: 3.2734 - accuracy: 0.6494 - val_loss: 3.5256 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 2.4816 - accuracy: 0.8051 - val_loss: 2.3688 - val_accuracy: 0.6717 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 1.8955 - accuracy: 0.8473 - val_loss: 1.6720 - val_accuracy: 0.8416 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 1.4482 - accuracy: 0.8590 - val_loss: 1.2911 - val_accuracy: 0.8448 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 1.1158 - accuracy: 0.8661 - val_loss: 1.0440 - val_accuracy: 0.8462 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.8821 - accuracy: 0.8778 - val_loss: 0.8507 - val_accuracy: 0.8580 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.7335 - accuracy: 0.8827 - val_loss: 0.6602 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.6196 - accuracy: 0.8906 - val_loss: 0.6355 - val_accuracy: 0.8732 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.5415 - accuracy: 0.8989 - val_loss: 0.6082 - val_accuracy: 0.8632 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.5104 - accuracy: 0.8967 - val_loss: 0.4791 - val_accuracy: 0.9043 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.4653 - accuracy: 0.9005 - val_loss: 0.5480 - val_accuracy: 0.8765 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.4524 - accuracy: 0.9037 - val_loss: 0.4425 - val_accuracy: 0.9087 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4294 - accuracy: 0.9054 - val_loss: 0.5357 - val_accuracy: 0.8546 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4247 - accuracy: 0.9036 - val_loss: 0.4848 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.4201 - accuracy: 0.9049 - val_loss: 0.4251 - val_accuracy: 0.9055 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4016 - accuracy: 0.9087 - val_loss: 0.4022 - val_accuracy: 0.9069 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4066 - accuracy: 0.9053 - val_loss: 0.3895 - val_accuracy: 0.9122 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4039 - accuracy: 0.9066 - val_loss: 0.3895 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3974 - accuracy: 0.9088 - val_loss: 0.3986 - val_accuracy: 0.9063 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3953 - accuracy: 0.9046 - val_loss: 0.4197 - val_accuracy: 0.9057 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3951 - accuracy: 0.9091 - val_loss: 0.3882 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3856 - accuracy: 0.9091 - val_loss: 0.4099 - val_accuracy: 0.9019 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3991 - accuracy: 0.9073 - val_loss: 0.3885 - val_accuracy: 0.9146 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3900 - accuracy: 0.9102 - val_loss: 0.4459 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3919 - accuracy: 0.9057 - val_loss: 0.4137 - val_accuracy: 0.8993 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3910 - accuracy: 0.9085 - val_loss: 0.3746 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3813 - accuracy: 0.9120 - val_loss: 0.3651 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3897 - accuracy: 0.9070 - val_loss: 0.4561 - val_accuracy: 0.8742 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3869 - accuracy: 0.9067 - val_loss: 0.4079 - val_accuracy: 0.8987 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3840 - accuracy: 0.9096 - val_loss: 0.4051 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3897 - accuracy: 0.9059 - val_loss: 0.4396 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3819 - accuracy: 0.9092 - val_loss: 0.4268 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3769 - accuracy: 0.9101 - val_loss: 0.4340 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3793 - accuracy: 0.9105 - val_loss: 0.3620 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3719 - accuracy: 0.9137 - val_loss: 0.3648 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3718 - accuracy: 0.9108 - val_loss: 0.4300 - val_accuracy: 0.9019 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3822 - accuracy: 0.9114 - val_loss: 0.4026 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.3748 - accuracy: 0.9119 - val_loss: 0.3672 - val_accuracy: 0.9126 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3809 - accuracy: 0.9112 - val_loss: 0.4198 - val_accuracy: 0.8989 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3855 - accuracy: 0.9092 - val_loss: 0.3887 - val_accuracy: 0.9055 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3803 - accuracy: 0.9109 - val_loss: 0.3734 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3695 - accuracy: 0.9157 - val_loss: 0.6131 - val_accuracy: 0.8006 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3795 - accuracy: 0.9095 - val_loss: 0.3931 - val_accuracy: 0.9049 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3772 - accuracy: 0.9084 - val_loss: 0.4278 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3701 - accuracy: 0.9116 - val_loss: 0.3832 - val_accuracy: 0.9053 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3678 - accuracy: 0.9152 - val_loss: 0.4690 - val_accuracy: 0.8781 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3768 - accuracy: 0.9126 - val_loss: 0.3794 - val_accuracy: 0.9105 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3791 - accuracy: 0.9114 - val_loss: 0.3738 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3767 - accuracy: 0.9128 - val_loss: 0.3675 - val_accuracy: 0.9138 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3699 - accuracy: 0.9145 - val_loss: 0.3591 - val_accuracy: 0.9170 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3744 - accuracy: 0.9150 - val_loss: 0.3639 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3704 - accuracy: 0.9140 - val_loss: 0.4707 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3680 - accuracy: 0.9114 - val_loss: 0.4025 - val_accuracy: 0.9007 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3769 - accuracy: 0.9103 - val_loss: 0.3744 - val_accuracy: 0.9134 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3570 - accuracy: 0.9157 - val_loss: 0.3955 - val_accuracy: 0.9035 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3676 - accuracy: 0.9151 - val_loss: 0.3625 - val_accuracy: 0.9140 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3689 - accuracy: 0.9129 - val_loss: 0.3738 - val_accuracy: 0.9116 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3638 - accuracy: 0.9158 - val_loss: 0.3514 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3695 - accuracy: 0.9130 - val_loss: 0.3607 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3669 - accuracy: 0.9129 - val_loss: 0.4397 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3579 - accuracy: 0.9144 - val_loss: 0.3558 - val_accuracy: 0.9198 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3623 - accuracy: 0.9148 - val_loss: 0.3487 - val_accuracy: 0.9232 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3690 - accuracy: 0.9147 - val_loss: 0.3807 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3757 - accuracy: 0.9146 - val_loss: 0.3636 - val_accuracy: 0.9144 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3671 - accuracy: 0.9143 - val_loss: 0.3507 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3611 - accuracy: 0.9160 - val_loss: 0.3533 - val_accuracy: 0.9142 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3632 - accuracy: 0.9116 - val_loss: 0.3603 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3701 - accuracy: 0.9118 - val_loss: 0.3629 - val_accuracy: 0.9190 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3599 - accuracy: 0.9133 - val_loss: 0.3695 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3654 - accuracy: 0.9137 - val_loss: 0.3733 - val_accuracy: 0.9110 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3622 - accuracy: 0.9183 - val_loss: 0.4540 - val_accuracy: 0.8751 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3399 - accuracy: 0.9215 - val_loss: 0.3368 - val_accuracy: 0.9212 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3202 - accuracy: 0.9241 - val_loss: 0.3432 - val_accuracy: 0.9154 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3074 - accuracy: 0.9299 - val_loss: 0.3563 - val_accuracy: 0.9101 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3051 - accuracy: 0.9255 - val_loss: 0.3263 - val_accuracy: 0.9182 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2918 - accuracy: 0.9296 - val_loss: 0.3118 - val_accuracy: 0.9210 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2842 - accuracy: 0.9268 - val_loss: 0.3178 - val_accuracy: 0.9156 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2774 - accuracy: 0.9288 - val_loss: 0.3041 - val_accuracy: 0.9176 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2773 - accuracy: 0.9299 - val_loss: 0.3329 - val_accuracy: 0.9103 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2683 - accuracy: 0.9310 - val_loss: 0.2857 - val_accuracy: 0.9252 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2622 - accuracy: 0.9314 - val_loss: 0.2999 - val_accuracy: 0.9204 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2601 - accuracy: 0.9320 - val_loss: 0.2777 - val_accuracy: 0.9262 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2610 - accuracy: 0.9311 - val_loss: 0.2710 - val_accuracy: 0.9302 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2585 - accuracy: 0.9343 - val_loss: 0.2692 - val_accuracy: 0.9304 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2592 - accuracy: 0.9314 - val_loss: 0.2690 - val_accuracy: 0.9302 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2538 - accuracy: 0.9340 - val_loss: 0.2685 - val_accuracy: 0.9314 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2516 - accuracy: 0.9344 - val_loss: 0.2669 - val_accuracy: 0.9312 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2510 - accuracy: 0.9366 - val_loss: 0.2676 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2487 - accuracy: 0.9381 - val_loss: 0.2671 - val_accuracy: 0.9320 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2548 - accuracy: 0.9332 - val_loss: 0.2675 - val_accuracy: 0.9316 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2509 - accuracy: 0.9338 - val_loss: 0.2669 - val_accuracy: 0.9318 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2480 - accuracy: 0.9355 - val_loss: 0.2670 - val_accuracy: 0.9316 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.2509 - accuracy: 0.9381 - val_loss: 0.2668 - val_accuracy: 0.9318 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2487 - accuracy: 0.9332 - val_loss: 0.2670 - val_accuracy: 0.9318 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.2504 - accuracy: 0.9326 - val_loss: 0.2669 - val_accuracy: 0.9320 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.2447 - accuracy: 0.9368 - val_loss: 0.2670 - val_accuracy: 0.9316 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.2479 - accuracy: 0.9347 - val_loss: 0.2667 - val_accuracy: 0.9324 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2507 - accuracy: 0.9326 - val_loss: 0.2668 - val_accuracy: 0.9320 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.2433 - accuracy: 0.9380 - val_loss: 0.2669 - val_accuracy: 0.9322 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.2490 - accuracy: 0.9350 - val_loss: 0.2668 - val_accuracy: 0.9322 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.2859 - accuracy: 0.9254\n",
      "17/17 [==============================] - 1s 13ms/step\n",
      "TP:5823, TN:9858, FP:597, FN:668, loss0.28591975569725037, acc0.9253511153074472, sn0.8970882760745648, sp0.9428981348637016, f10.9020215320269537, auc0.9746747308066843\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 13s 29ms/step - loss: 3.2476 - accuracy: 0.6489 - val_loss: 3.1909 - val_accuracy: 0.5072 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 2.4588 - accuracy: 0.7961 - val_loss: 2.2137 - val_accuracy: 0.7499 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 1.8526 - accuracy: 0.8444 - val_loss: 1.6554 - val_accuracy: 0.8221 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 1.4028 - accuracy: 0.8601 - val_loss: 1.2629 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 1.0796 - accuracy: 0.8682 - val_loss: 0.9629 - val_accuracy: 0.8664 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.8556 - accuracy: 0.8754 - val_loss: 0.8262 - val_accuracy: 0.8668 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.7065 - accuracy: 0.8886 - val_loss: 0.6505 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5987 - accuracy: 0.8946 - val_loss: 0.6004 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5278 - accuracy: 0.8996 - val_loss: 0.5717 - val_accuracy: 0.8797 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.4930 - accuracy: 0.8985 - val_loss: 0.4954 - val_accuracy: 0.8987 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.4650 - accuracy: 0.9003 - val_loss: 0.4623 - val_accuracy: 0.9039 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4449 - accuracy: 0.9043 - val_loss: 0.4320 - val_accuracy: 0.9079 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4282 - accuracy: 0.9049 - val_loss: 0.4164 - val_accuracy: 0.9077 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.4208 - accuracy: 0.9026 - val_loss: 0.4568 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4129 - accuracy: 0.9069 - val_loss: 0.3807 - val_accuracy: 0.9164 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.4010 - accuracy: 0.9084 - val_loss: 0.4392 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3972 - accuracy: 0.9063 - val_loss: 0.3898 - val_accuracy: 0.9162 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.4058 - accuracy: 0.9063 - val_loss: 0.3777 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3977 - accuracy: 0.9051 - val_loss: 0.4305 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.3929 - accuracy: 0.9073 - val_loss: 0.3710 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.3807 - accuracy: 0.9094 - val_loss: 0.4025 - val_accuracy: 0.9001 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3922 - accuracy: 0.9066 - val_loss: 0.5051 - val_accuracy: 0.8630 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.3985 - accuracy: 0.9055 - val_loss: 0.3789 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3819 - accuracy: 0.9097 - val_loss: 0.3700 - val_accuracy: 0.9126 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3821 - accuracy: 0.9114 - val_loss: 0.3567 - val_accuracy: 0.9180 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3831 - accuracy: 0.9110 - val_loss: 0.3881 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3793 - accuracy: 0.9119 - val_loss: 0.3633 - val_accuracy: 0.9192 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3898 - accuracy: 0.9097 - val_loss: 0.3899 - val_accuracy: 0.9083 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3814 - accuracy: 0.9101 - val_loss: 0.3992 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3908 - accuracy: 0.9080 - val_loss: 0.3677 - val_accuracy: 0.9174 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3838 - accuracy: 0.9078 - val_loss: 0.4403 - val_accuracy: 0.8837 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3677 - accuracy: 0.9150 - val_loss: 0.4707 - val_accuracy: 0.8644 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3872 - accuracy: 0.9106 - val_loss: 0.4814 - val_accuracy: 0.8686 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3813 - accuracy: 0.9121 - val_loss: 0.3862 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3827 - accuracy: 0.9074 - val_loss: 0.3557 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3659 - accuracy: 0.9172 - val_loss: 0.4476 - val_accuracy: 0.8738 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3731 - accuracy: 0.9120 - val_loss: 0.4474 - val_accuracy: 0.8805 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3840 - accuracy: 0.9097 - val_loss: 0.3929 - val_accuracy: 0.9063 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3750 - accuracy: 0.9118 - val_loss: 0.3795 - val_accuracy: 0.9083 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3758 - accuracy: 0.9099 - val_loss: 0.4145 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3876 - accuracy: 0.9108 - val_loss: 0.3802 - val_accuracy: 0.9116 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3792 - accuracy: 0.9126 - val_loss: 0.3733 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3789 - accuracy: 0.9111 - val_loss: 0.3624 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3768 - accuracy: 0.9108 - val_loss: 0.4675 - val_accuracy: 0.8744 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3792 - accuracy: 0.9109 - val_loss: 0.3804 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3798 - accuracy: 0.9111 - val_loss: 0.3961 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3766 - accuracy: 0.9121 - val_loss: 0.3622 - val_accuracy: 0.9140 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3694 - accuracy: 0.9128 - val_loss: 0.3659 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3741 - accuracy: 0.9124 - val_loss: 0.4128 - val_accuracy: 0.9019 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3636 - accuracy: 0.9150 - val_loss: 0.4148 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3745 - accuracy: 0.9124 - val_loss: 0.3826 - val_accuracy: 0.9140 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3809 - accuracy: 0.9114 - val_loss: 0.3528 - val_accuracy: 0.9184 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3667 - accuracy: 0.9138 - val_loss: 0.3710 - val_accuracy: 0.9126 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3694 - accuracy: 0.9138 - val_loss: 0.4280 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3798 - accuracy: 0.9095 - val_loss: 0.3593 - val_accuracy: 0.9198 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3759 - accuracy: 0.9114 - val_loss: 0.3709 - val_accuracy: 0.9144 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3660 - accuracy: 0.9142 - val_loss: 0.4113 - val_accuracy: 0.8999 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3680 - accuracy: 0.9115 - val_loss: 0.4890 - val_accuracy: 0.8686 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3597 - accuracy: 0.9162 - val_loss: 0.3917 - val_accuracy: 0.9001 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3660 - accuracy: 0.9146 - val_loss: 0.3529 - val_accuracy: 0.9198 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3662 - accuracy: 0.9123 - val_loss: 0.3787 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3660 - accuracy: 0.9129 - val_loss: 0.4986 - val_accuracy: 0.8576 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3668 - accuracy: 0.9138 - val_loss: 0.3583 - val_accuracy: 0.9182 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3693 - accuracy: 0.9135 - val_loss: 0.3688 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3707 - accuracy: 0.9142 - val_loss: 0.3685 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3660 - accuracy: 0.9134 - val_loss: 0.3724 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3698 - accuracy: 0.9143 - val_loss: 0.3795 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3610 - accuracy: 0.9145 - val_loss: 0.3463 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3620 - accuracy: 0.9142 - val_loss: 0.4095 - val_accuracy: 0.9007 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3626 - accuracy: 0.9138 - val_loss: 0.4600 - val_accuracy: 0.8744 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3630 - accuracy: 0.9141 - val_loss: 0.3711 - val_accuracy: 0.9077 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3273 - accuracy: 0.9231 - val_loss: 0.3537 - val_accuracy: 0.9126 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3167 - accuracy: 0.9247 - val_loss: 0.3240 - val_accuracy: 0.9200 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3036 - accuracy: 0.9278 - val_loss: 0.3168 - val_accuracy: 0.9208 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.2979 - accuracy: 0.9260 - val_loss: 0.3506 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.2908 - accuracy: 0.9285 - val_loss: 0.3057 - val_accuracy: 0.9200 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2832 - accuracy: 0.9297 - val_loss: 0.2978 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2789 - accuracy: 0.9302 - val_loss: 0.3002 - val_accuracy: 0.9176 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2707 - accuracy: 0.9330 - val_loss: 0.2755 - val_accuracy: 0.9262 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.2654 - accuracy: 0.9330 - val_loss: 0.2767 - val_accuracy: 0.9260 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2643 - accuracy: 0.9314 - val_loss: 0.2876 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.2543 - accuracy: 0.9322 - val_loss: 0.2708 - val_accuracy: 0.9274 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.2536 - accuracy: 0.9347 - val_loss: 0.2692 - val_accuracy: 0.9266 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.2525 - accuracy: 0.9344 - val_loss: 0.2683 - val_accuracy: 0.9294 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2523 - accuracy: 0.9350 - val_loss: 0.2678 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2516 - accuracy: 0.9333 - val_loss: 0.2674 - val_accuracy: 0.9292 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2494 - accuracy: 0.9355 - val_loss: 0.2671 - val_accuracy: 0.9302 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.2469 - accuracy: 0.9369 - val_loss: 0.2665 - val_accuracy: 0.9304 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.2514 - accuracy: 0.9334 - val_loss: 0.2668 - val_accuracy: 0.9292 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.2481 - accuracy: 0.9349 - val_loss: 0.2666 - val_accuracy: 0.9288 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.2481 - accuracy: 0.9357 - val_loss: 0.2658 - val_accuracy: 0.9302 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.2453 - accuracy: 0.9369 - val_loss: 0.2658 - val_accuracy: 0.9306 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2452 - accuracy: 0.9375 - val_loss: 0.2657 - val_accuracy: 0.9312 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.2491 - accuracy: 0.9341 - val_loss: 0.2657 - val_accuracy: 0.9306 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.2442 - accuracy: 0.9369 - val_loss: 0.2655 - val_accuracy: 0.9308 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2439 - accuracy: 0.9378 - val_loss: 0.2655 - val_accuracy: 0.9310 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.2476 - accuracy: 0.9350 - val_loss: 0.2656 - val_accuracy: 0.9308 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.2505 - accuracy: 0.9347 - val_loss: 0.2655 - val_accuracy: 0.9312 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2463 - accuracy: 0.9361 - val_loss: 0.2656 - val_accuracy: 0.9310 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.2464 - accuracy: 0.9370 - val_loss: 0.2653 - val_accuracy: 0.9306 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 4s 8ms/step - loss: 0.2866 - accuracy: 0.9243\n",
      "17/17 [==============================] - 1s 18ms/step\n",
      "TP:5789, TN:9874, FP:581, FN:702, loss0.286615252494812, acc0.9242889177386994, sn0.8918502541981205, sp0.9444285031085605, f10.9002410387994713, auc0.9738528150775813\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 15s 42ms/step - loss: 3.1872 - accuracy: 0.6625 - val_loss: 4.2900 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 2.3700 - accuracy: 0.8198 - val_loss: 2.4986 - val_accuracy: 0.5301 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 1.7967 - accuracy: 0.8442 - val_loss: 1.5558 - val_accuracy: 0.8482 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 1.3477 - accuracy: 0.8625 - val_loss: 1.1613 - val_accuracy: 0.8634 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 1.0339 - accuracy: 0.8711 - val_loss: 0.9152 - val_accuracy: 0.8704 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.8324 - accuracy: 0.8752 - val_loss: 0.7904 - val_accuracy: 0.8592 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.6896 - accuracy: 0.8827 - val_loss: 0.6583 - val_accuracy: 0.8728 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5996 - accuracy: 0.8862 - val_loss: 0.7136 - val_accuracy: 0.8315 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.5312 - accuracy: 0.8953 - val_loss: 0.5295 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5005 - accuracy: 0.8929 - val_loss: 0.4896 - val_accuracy: 0.8977 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.4703 - accuracy: 0.8986 - val_loss: 0.4478 - val_accuracy: 0.9077 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.4495 - accuracy: 0.9030 - val_loss: 0.4409 - val_accuracy: 0.9055 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.4352 - accuracy: 0.9032 - val_loss: 0.4201 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.4358 - accuracy: 0.9018 - val_loss: 0.4128 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.4156 - accuracy: 0.9070 - val_loss: 0.4886 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4218 - accuracy: 0.9066 - val_loss: 0.4324 - val_accuracy: 0.9007 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.4083 - accuracy: 0.9072 - val_loss: 0.4401 - val_accuracy: 0.8983 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.4059 - accuracy: 0.9056 - val_loss: 0.4021 - val_accuracy: 0.9069 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.4045 - accuracy: 0.9051 - val_loss: 0.3925 - val_accuracy: 0.9118 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.4114 - accuracy: 0.9059 - val_loss: 0.4120 - val_accuracy: 0.9027 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3946 - accuracy: 0.9105 - val_loss: 0.3926 - val_accuracy: 0.9142 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3952 - accuracy: 0.9057 - val_loss: 0.3969 - val_accuracy: 0.9043 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3998 - accuracy: 0.9045 - val_loss: 0.5020 - val_accuracy: 0.8664 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3839 - accuracy: 0.9117 - val_loss: 0.3711 - val_accuracy: 0.9144 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3910 - accuracy: 0.9089 - val_loss: 0.3814 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3867 - accuracy: 0.9104 - val_loss: 0.4103 - val_accuracy: 0.9007 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3883 - accuracy: 0.9089 - val_loss: 0.3694 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3822 - accuracy: 0.9105 - val_loss: 0.5121 - val_accuracy: 0.8594 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3845 - accuracy: 0.9084 - val_loss: 0.3620 - val_accuracy: 0.9164 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3866 - accuracy: 0.9067 - val_loss: 0.3724 - val_accuracy: 0.9099 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3759 - accuracy: 0.9144 - val_loss: 0.3731 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3829 - accuracy: 0.9111 - val_loss: 0.3621 - val_accuracy: 0.9180 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3856 - accuracy: 0.9090 - val_loss: 0.3631 - val_accuracy: 0.9198 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3779 - accuracy: 0.9130 - val_loss: 0.3786 - val_accuracy: 0.9140 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.3841 - accuracy: 0.9120 - val_loss: 0.4569 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3858 - accuracy: 0.9121 - val_loss: 0.4403 - val_accuracy: 0.8983 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.3854 - accuracy: 0.9096 - val_loss: 0.3782 - val_accuracy: 0.9124 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3762 - accuracy: 0.9141 - val_loss: 0.3645 - val_accuracy: 0.9180 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3764 - accuracy: 0.9116 - val_loss: 0.3803 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.3794 - accuracy: 0.9149 - val_loss: 0.3834 - val_accuracy: 0.9144 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3911 - accuracy: 0.9105 - val_loss: 0.3971 - val_accuracy: 0.8999 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.3748 - accuracy: 0.9135 - val_loss: 0.3894 - val_accuracy: 0.9083 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.3848 - accuracy: 0.9091 - val_loss: 0.3961 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.3838 - accuracy: 0.9127 - val_loss: 0.3791 - val_accuracy: 0.9120 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3783 - accuracy: 0.9098 - val_loss: 0.4044 - val_accuracy: 0.9025 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3701 - accuracy: 0.9146 - val_loss: 0.4020 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3744 - accuracy: 0.9138 - val_loss: 0.4008 - val_accuracy: 0.9009 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3805 - accuracy: 0.9128 - val_loss: 0.3637 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3774 - accuracy: 0.9113 - val_loss: 0.3940 - val_accuracy: 0.9065 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3719 - accuracy: 0.9126 - val_loss: 0.4423 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3806 - accuracy: 0.9102 - val_loss: 0.3847 - val_accuracy: 0.9110 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3759 - accuracy: 0.9138 - val_loss: 0.5424 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3787 - accuracy: 0.9104 - val_loss: 0.3577 - val_accuracy: 0.9174 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3662 - accuracy: 0.9155 - val_loss: 0.4346 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3754 - accuracy: 0.9112 - val_loss: 0.3949 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3719 - accuracy: 0.9133 - val_loss: 0.3968 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3657 - accuracy: 0.9144 - val_loss: 0.3787 - val_accuracy: 0.9073 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3784 - accuracy: 0.9119 - val_loss: 0.3576 - val_accuracy: 0.9172 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3752 - accuracy: 0.9102 - val_loss: 0.3487 - val_accuracy: 0.9210 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3656 - accuracy: 0.9161 - val_loss: 0.4608 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3686 - accuracy: 0.9129 - val_loss: 0.3783 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3770 - accuracy: 0.9108 - val_loss: 0.3824 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3724 - accuracy: 0.9144 - val_loss: 0.3794 - val_accuracy: 0.9148 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3721 - accuracy: 0.9154 - val_loss: 0.3602 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3735 - accuracy: 0.9136 - val_loss: 0.4098 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3736 - accuracy: 0.9179 - val_loss: 0.4143 - val_accuracy: 0.9039 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3802 - accuracy: 0.9134 - val_loss: 0.3726 - val_accuracy: 0.9140 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3701 - accuracy: 0.9146 - val_loss: 0.4260 - val_accuracy: 0.8977 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3718 - accuracy: 0.9154 - val_loss: 0.4060 - val_accuracy: 0.9057 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3696 - accuracy: 0.9144 - val_loss: 0.3790 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3620 - accuracy: 0.9159 - val_loss: 0.3759 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3417 - accuracy: 0.9228 - val_loss: 0.3429 - val_accuracy: 0.9214 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3259 - accuracy: 0.9244 - val_loss: 0.3665 - val_accuracy: 0.9108 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3178 - accuracy: 0.9251 - val_loss: 0.3415 - val_accuracy: 0.9154 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3056 - accuracy: 0.9285 - val_loss: 0.3163 - val_accuracy: 0.9216 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3001 - accuracy: 0.9276 - val_loss: 0.3222 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.2933 - accuracy: 0.9279 - val_loss: 0.3498 - val_accuracy: 0.9083 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.2843 - accuracy: 0.9302 - val_loss: 0.3004 - val_accuracy: 0.9226 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.2796 - accuracy: 0.9284 - val_loss: 0.2974 - val_accuracy: 0.9202 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.2786 - accuracy: 0.9308 - val_loss: 0.2926 - val_accuracy: 0.9226 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.2696 - accuracy: 0.9320 - val_loss: 0.2950 - val_accuracy: 0.9232 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.2647 - accuracy: 0.9341 - val_loss: 0.2784 - val_accuracy: 0.9280 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.2599 - accuracy: 0.9360 - val_loss: 0.2779 - val_accuracy: 0.9274 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.2597 - accuracy: 0.9330 - val_loss: 0.2770 - val_accuracy: 0.9272 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.2586 - accuracy: 0.9338 - val_loss: 0.2766 - val_accuracy: 0.9276 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2574 - accuracy: 0.9353 - val_loss: 0.2774 - val_accuracy: 0.9284 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.2623 - accuracy: 0.9323 - val_loss: 0.2766 - val_accuracy: 0.9274 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2633 - accuracy: 0.9331 - val_loss: 0.2756 - val_accuracy: 0.9264 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2570 - accuracy: 0.9355 - val_loss: 0.2746 - val_accuracy: 0.9272 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2556 - accuracy: 0.9352 - val_loss: 0.2746 - val_accuracy: 0.9278 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2609 - accuracy: 0.9318 - val_loss: 0.2739 - val_accuracy: 0.9272 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.2520 - accuracy: 0.9357 - val_loss: 0.2740 - val_accuracy: 0.9276 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2533 - accuracy: 0.9359 - val_loss: 0.2739 - val_accuracy: 0.9276 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.2503 - accuracy: 0.9366 - val_loss: 0.2738 - val_accuracy: 0.9272 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.2565 - accuracy: 0.9353 - val_loss: 0.2736 - val_accuracy: 0.9274 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2519 - accuracy: 0.9364 - val_loss: 0.2737 - val_accuracy: 0.9278 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2523 - accuracy: 0.9382 - val_loss: 0.2737 - val_accuracy: 0.9280 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.2557 - accuracy: 0.9362 - val_loss: 0.2737 - val_accuracy: 0.9278 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.2551 - accuracy: 0.9350 - val_loss: 0.2737 - val_accuracy: 0.9278 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.2521 - accuracy: 0.9364 - val_loss: 0.2738 - val_accuracy: 0.9280 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.2935 - accuracy: 0.9249\n",
      "17/17 [==============================] - 1s 13ms/step\n",
      "TP:5819, TN:9854, FP:601, FN:672, loss0.29349610209465027, acc0.9248790274991149, sn0.8964720382067478, sp0.9425155428024868, f10.9014019053520254, auc0.97349372611056\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 12s 31ms/step - loss: 3.2622 - accuracy: 0.6458 - val_loss: 3.2248 - val_accuracy: 0.4763 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 2.4891 - accuracy: 0.7946 - val_loss: 2.7094 - val_accuracy: 0.4569 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 1.8928 - accuracy: 0.8440 - val_loss: 1.8145 - val_accuracy: 0.7371 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 1.4415 - accuracy: 0.8568 - val_loss: 1.2652 - val_accuracy: 0.8626 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 1.1260 - accuracy: 0.8569 - val_loss: 1.0749 - val_accuracy: 0.8223 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.8848 - accuracy: 0.8750 - val_loss: 0.8005 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7189 - accuracy: 0.8835 - val_loss: 0.7269 - val_accuracy: 0.8606 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.6261 - accuracy: 0.8835 - val_loss: 0.6009 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5434 - accuracy: 0.8966 - val_loss: 0.5786 - val_accuracy: 0.8748 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5012 - accuracy: 0.8978 - val_loss: 0.4896 - val_accuracy: 0.9027 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.4765 - accuracy: 0.8998 - val_loss: 0.4587 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.4562 - accuracy: 0.9005 - val_loss: 0.4456 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.4458 - accuracy: 0.9004 - val_loss: 0.4320 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.4248 - accuracy: 0.9026 - val_loss: 0.4481 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.4027 - accuracy: 0.9122 - val_loss: 0.3910 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.4099 - accuracy: 0.9060 - val_loss: 0.3896 - val_accuracy: 0.9134 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.4051 - accuracy: 0.9063 - val_loss: 0.3834 - val_accuracy: 0.9148 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3997 - accuracy: 0.9098 - val_loss: 0.4706 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3992 - accuracy: 0.9077 - val_loss: 0.3839 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3937 - accuracy: 0.9099 - val_loss: 0.3687 - val_accuracy: 0.9158 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3891 - accuracy: 0.9101 - val_loss: 0.5175 - val_accuracy: 0.8450 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3872 - accuracy: 0.9095 - val_loss: 0.3743 - val_accuracy: 0.9126 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3937 - accuracy: 0.9046 - val_loss: 0.3686 - val_accuracy: 0.9118 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3724 - accuracy: 0.9111 - val_loss: 0.3560 - val_accuracy: 0.9176 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3785 - accuracy: 0.9114 - val_loss: 0.4162 - val_accuracy: 0.9039 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3761 - accuracy: 0.9103 - val_loss: 0.3548 - val_accuracy: 0.9220 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3794 - accuracy: 0.9114 - val_loss: 0.3998 - val_accuracy: 0.9073 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3869 - accuracy: 0.9084 - val_loss: 0.5731 - val_accuracy: 0.8261 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3824 - accuracy: 0.9076 - val_loss: 0.4722 - val_accuracy: 0.8588 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3741 - accuracy: 0.9114 - val_loss: 0.3706 - val_accuracy: 0.9047 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3771 - accuracy: 0.9081 - val_loss: 0.3590 - val_accuracy: 0.9158 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3788 - accuracy: 0.9094 - val_loss: 0.3596 - val_accuracy: 0.9164 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3718 - accuracy: 0.9144 - val_loss: 0.3698 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3792 - accuracy: 0.9114 - val_loss: 0.3567 - val_accuracy: 0.9192 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3686 - accuracy: 0.9141 - val_loss: 0.3513 - val_accuracy: 0.9194 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3783 - accuracy: 0.9148 - val_loss: 0.3695 - val_accuracy: 0.9142 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3858 - accuracy: 0.9084 - val_loss: 0.3619 - val_accuracy: 0.9166 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3808 - accuracy: 0.9086 - val_loss: 0.3652 - val_accuracy: 0.9164 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3686 - accuracy: 0.9104 - val_loss: 0.3612 - val_accuracy: 0.9118 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3705 - accuracy: 0.9129 - val_loss: 0.4205 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3759 - accuracy: 0.9082 - val_loss: 0.3805 - val_accuracy: 0.9059 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3615 - accuracy: 0.9128 - val_loss: 0.3640 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3759 - accuracy: 0.9155 - val_loss: 0.4091 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3684 - accuracy: 0.9127 - val_loss: 0.3868 - val_accuracy: 0.9059 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3647 - accuracy: 0.9168 - val_loss: 0.3594 - val_accuracy: 0.9144 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3871 - accuracy: 0.9086 - val_loss: 0.4192 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3727 - accuracy: 0.9127 - val_loss: 0.3971 - val_accuracy: 0.9019 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3635 - accuracy: 0.9127 - val_loss: 0.4100 - val_accuracy: 0.8971 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3692 - accuracy: 0.9108 - val_loss: 0.3664 - val_accuracy: 0.9134 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3661 - accuracy: 0.9115 - val_loss: 0.3586 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3638 - accuracy: 0.9126 - val_loss: 0.3537 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3654 - accuracy: 0.9134 - val_loss: 0.4121 - val_accuracy: 0.8995 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3648 - accuracy: 0.9135 - val_loss: 0.3478 - val_accuracy: 0.9184 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3717 - accuracy: 0.9114 - val_loss: 0.3790 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3634 - accuracy: 0.9150 - val_loss: 0.3734 - val_accuracy: 0.9051 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3605 - accuracy: 0.9136 - val_loss: 0.3882 - val_accuracy: 0.9079 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3664 - accuracy: 0.9146 - val_loss: 0.3816 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3640 - accuracy: 0.9130 - val_loss: 0.3639 - val_accuracy: 0.9124 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3594 - accuracy: 0.9146 - val_loss: 0.3462 - val_accuracy: 0.9204 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3664 - accuracy: 0.9157 - val_loss: 0.3958 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3587 - accuracy: 0.9147 - val_loss: 0.4371 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3613 - accuracy: 0.9138 - val_loss: 0.3532 - val_accuracy: 0.9212 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3640 - accuracy: 0.9136 - val_loss: 0.3709 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3590 - accuracy: 0.9162 - val_loss: 0.3893 - val_accuracy: 0.8987 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3593 - accuracy: 0.9140 - val_loss: 0.3623 - val_accuracy: 0.9184 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3665 - accuracy: 0.9130 - val_loss: 0.3962 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.3525 - accuracy: 0.9185 - val_loss: 0.3585 - val_accuracy: 0.9146 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3671 - accuracy: 0.9120 - val_loss: 0.5766 - val_accuracy: 0.8434 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3513 - accuracy: 0.9162 - val_loss: 0.3510 - val_accuracy: 0.9146 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3590 - accuracy: 0.9144 - val_loss: 0.3472 - val_accuracy: 0.9228 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3616 - accuracy: 0.9126 - val_loss: 0.3840 - val_accuracy: 0.9045 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3402 - accuracy: 0.9241 - val_loss: 0.3491 - val_accuracy: 0.9164 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3212 - accuracy: 0.9242 - val_loss: 0.3271 - val_accuracy: 0.9190 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3124 - accuracy: 0.9255 - val_loss: 0.3195 - val_accuracy: 0.9218 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.2996 - accuracy: 0.9269 - val_loss: 0.3309 - val_accuracy: 0.9142 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.2930 - accuracy: 0.9278 - val_loss: 0.3021 - val_accuracy: 0.9220 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.2867 - accuracy: 0.9280 - val_loss: 0.2895 - val_accuracy: 0.9238 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.2798 - accuracy: 0.9293 - val_loss: 0.2887 - val_accuracy: 0.9250 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.2700 - accuracy: 0.9324 - val_loss: 0.2894 - val_accuracy: 0.9234 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.2683 - accuracy: 0.9296 - val_loss: 0.2947 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.2638 - accuracy: 0.9311 - val_loss: 0.2700 - val_accuracy: 0.9254 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.2588 - accuracy: 0.9326 - val_loss: 0.2689 - val_accuracy: 0.9268 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.2566 - accuracy: 0.9332 - val_loss: 0.2680 - val_accuracy: 0.9282 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.2520 - accuracy: 0.9346 - val_loss: 0.2668 - val_accuracy: 0.9280 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.2520 - accuracy: 0.9356 - val_loss: 0.2648 - val_accuracy: 0.9282 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.2524 - accuracy: 0.9332 - val_loss: 0.2641 - val_accuracy: 0.9294 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.2555 - accuracy: 0.9344 - val_loss: 0.2645 - val_accuracy: 0.9298 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.2488 - accuracy: 0.9344 - val_loss: 0.2645 - val_accuracy: 0.9298 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.2518 - accuracy: 0.9341 - val_loss: 0.2636 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.2526 - accuracy: 0.9350 - val_loss: 0.2627 - val_accuracy: 0.9302 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.2513 - accuracy: 0.9357 - val_loss: 0.2619 - val_accuracy: 0.9314 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.2509 - accuracy: 0.9346 - val_loss: 0.2621 - val_accuracy: 0.9306 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.2493 - accuracy: 0.9345 - val_loss: 0.2620 - val_accuracy: 0.9304 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.2461 - accuracy: 0.9358 - val_loss: 0.2620 - val_accuracy: 0.9306 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.2436 - accuracy: 0.9360 - val_loss: 0.2621 - val_accuracy: 0.9304 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.2469 - accuracy: 0.9345 - val_loss: 0.2622 - val_accuracy: 0.9302 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.2471 - accuracy: 0.9362 - val_loss: 0.2624 - val_accuracy: 0.9308 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.2468 - accuracy: 0.9367 - val_loss: 0.2621 - val_accuracy: 0.9310 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.2495 - accuracy: 0.9342 - val_loss: 0.2623 - val_accuracy: 0.9302 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.2459 - accuracy: 0.9379 - val_loss: 0.2624 - val_accuracy: 0.9304 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 6s 10ms/step - loss: 0.2847 - accuracy: 0.9243\n",
      "17/17 [==============================] - 1s 21ms/step\n",
      "TP:5802, TN:9862, FP:593, FN:689, loss0.2847291827201843, acc0.9243479287147409, sn0.8938530272685257, sp0.9432807269249163, f10.9005121837653267, auc0.9740241076910302\n",
      "Average Test loss:  0.28823415338993075\n",
      "Average Accuracy:  0.9246842912781779\n",
      "Average Sensitivity:  0.894962255430596\n",
      "Average Specificity:  0.9431372549019608\n",
      "Average F1 Score:  0.9010210686014988\n",
      "Average AUC Score:  0.9739805208713003\n",
      "AUC for ROC curve 1: 0.9743\n",
      "AUC for ROC curve 2: 0.9743\n",
      "AUC for ROC curve 3: 0.9737\n",
      "AUC for ROC curve 4: 0.9737\n",
      "AUC for ROC curve 5: 0.9737\n",
      "AUC for ROC curve 6: 0.9737\n",
      "AUC for ROC curve 7: 0.9741\n",
      "AUC for ROC curve 8: 0.9741\n",
      "AUC for ROC curve 9: 0.9739\n",
      "AUC for ROC curve 10: 0.9739\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, f1_score,roc_auc_score\n",
    "losses = []\n",
    "accuracies = []\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "f1_scores = []\n",
    "auc_scores = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "\n",
    "num_trainings = 10\n",
    "for i in range(num_trainings):\n",
    "    model = create_model(x_train1.shape[1:], x_train2.shape[1:], x_train3.shape[1:])\n",
    "    model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "    history = model.fit([x_train1, x_train2, x_train3], y_train, batch_size=128, epochs=100,\n",
    "                        validation_data=([x_val1, x_val2, x_val3], y_val), callbacks=[lr_scheduler])\n",
    "    loss, accuracy = model.evaluate([x_test1, x_test2, x_test3], y_test)\n",
    "    y_prob = model.predict([x_test1, x_test2, x_test3], batch_size=1024, verbose=1)\n",
    "\n",
    "    y_true = y_test.argmax(axis=-1)\n",
    "    y_pred = np.argmax(y_prob, axis=-1)\n",
    "\n",
    "    C = confusion_matrix(y_true, y_pred, labels=(1, 0))\n",
    "    TP, TN, FP, FN = C[0, 0], C[1, 1], C[1, 0], C[0, 1]\n",
    "    acc, sn, sp = 1. * (TP + TN) / (TP + TN + FP + FN), 1. * TP / (TP + FN), 1. * TN / (TN + FP)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    sn = TP / (TP + FN)  \n",
    "    sp = TN / (TN + FP) \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = sn\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    auc_scores.append(roc_auc)\n",
    "    \n",
    "    print(\"TP:{}, TN:{}, FP:{}, FN:{}, loss{}, acc{}, sn{}, sp{}, f1{}, auc{}\".format(TP, TN, FP, FN, loss, acc, sn, sp, f1, roc_auc))\n",
    "    losses.append(loss)\n",
    "    accuracies.append(acc)\n",
    "    sensitivities.append(sn)\n",
    "    specificities.append(sp)\n",
    "    f1_scores.append(f1)\n",
    "    auc_scores.append(roc_auc)\n",
    "\n",
    "avg_loss = np.mean(losses)\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_sensitivity = np.mean(sensitivities)\n",
    "avg_specificity = np.mean(specificities)\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "avg_auc_score = np.mean(auc_scores)\n",
    "\n",
    "print(\"Average Test loss: \", avg_loss)\n",
    "print(\"Average Accuracy: \", avg_accuracy)\n",
    "print(\"Average Sensitivity: \", avg_sensitivity)\n",
    "print(\"Average Specificity: \", avg_specificity)\n",
    "print(\"Average F1 Score: \", avg_f1_score)\n",
    "print(\"Average AUC Score: \", avg_auc_score)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = np.zeros_like(mean_fpr)\n",
    "for i in range(num_trainings):\n",
    "    mean_tpr += np.interp(mean_fpr, fprs[i], tprs[i])\n",
    "    plt.plot(fprs[i], tprs[i], alpha=0.3, label='ROC curve {} (AUC = {:.4f})'.format(i+1, auc_scores[i]))\n",
    "    print('AUC for ROC curve {}: {:.4f}'.format(i+1, auc_scores[i]))\n",
    "mean_tpr /= num_trainings\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--', label='Mean ROC (AUC = {:.4f})'.format(mean_auc), lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f9963-cfa7-47f5-8701-2a24e58e20bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gcn",
   "language": "python",
   "name": "gcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
