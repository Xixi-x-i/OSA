{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "-028b2NqE02R",
   "metadata": {
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1693232083105,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "-028b2NqE02R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 22:33:19.757624: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.Session(config=config).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a034672d",
   "metadata": {
    "executionInfo": {
     "elapsed": 1150,
     "status": "ok",
     "timestamp": 1693232086282,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "a034672d"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import BatchNormalization, LeakyReLU, MaxPooling1D, Dropout, Flatten, Dense, Conv1D,Reshape,multiply,GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from scipy.interpolate import splev, splrep\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591596f3",
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1693232087740,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "591596f3"
   },
   "outputs": [],
   "source": [
    "base_dir = \"./dataset\"\n",
    "ir = 3 \n",
    "before = 2\n",
    "after = 2\n",
    "\n",
    "scaler = lambda arr: (arr - np.min(arr)) / (np.max(arr) - np.min(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cef782d",
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1693232089719,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "0cef782d"
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "def interpolate_numpy_array(arr, desired_length):\n",
    "    cs = CubicSpline(np.linspace(0, 1, len(arr)), arr)\n",
    "    x_new = np.linspace(0, 1, desired_length)\n",
    "    interpolated_arr = cs(x_new)\n",
    "    return interpolated_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "KXj-pyPoXKm3",
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1693232167282,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "KXj-pyPoXKm3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def load_data():\n",
    "    tm = np.arange(0, (before + 1 + after) * 60, step=1 / float(ir))\n",
    "    with open(os.path.join(base_dir, \"apnea.pkl\"), 'rb') as f:\n",
    "        apnea_ecg = pickle.load(f)\n",
    "    x_train1,x_train2,x_train3 = [],[],[]\n",
    "    o_train, y_train = apnea_ecg[\"o_train\"], apnea_ecg[\"y_train\"]\n",
    "    groups_train = apnea_ecg[\"groups_train\"]\n",
    "    for i in range(len(o_train)):\n",
    "        min_distance_list, max_distance_list= o_train[i]\n",
    "        min_distance_list_inter = interpolate_numpy_array(min_distance_list,900)\n",
    "        max_distance_list_inter = interpolate_numpy_array(max_distance_list,900)\n",
    "        x_train1.append([min_distance_list_inter, max_distance_list_inter])\n",
    "        x_train2.append([min_distance_list_inter[180:720], max_distance_list_inter[180:720]])\n",
    "        x_train3.append([min_distance_list_inter[360:540], max_distance_list_inter[360:540]])\n",
    "    x_training1,x_training2,x_training3,y_training,groups_training = [],[],[],[],[]\n",
    "    x_val1,x_val2,x_val3,y_val,groups_val = [],[],[],[],[]\n",
    "\n",
    "    trainlist = random.sample(range(len(o_train)),int(len(o_train)*0.7))\n",
    "    num=[i for i in range(16713)]\n",
    "    vallist = set(num) - set(trainlist)\n",
    "    vallist = list(vallist)\n",
    "    for i in trainlist:\n",
    "        x_training1.append(x_train1[i])\n",
    "        x_training2.append(x_train2[i])\n",
    "        x_training3.append(x_train3[i])\n",
    "        y_training.append(y_train[i])\n",
    "        groups_training.append(groups_train[i])\n",
    "    for i in vallist:\n",
    "        x_val1.append(x_train1[i])\n",
    "        x_val2.append(x_train2[i])\n",
    "        x_val3.append(x_train3[i])\n",
    "        y_val.append(y_train[i])\n",
    "        groups_val.append(groups_train[i])\n",
    "\n",
    "    x_training1 = np.array(x_training1, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_training2 = np.array(x_training2, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_training3 = np.array(x_training3, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    y_training = np.array(y_training, dtype=\"float32\")\n",
    "    x_val1 = np.array(x_val1, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_val2 = np.array(x_val2, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_val3 = np.array(x_val3, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    y_val = np.array(y_val, dtype=\"float32\")\n",
    "\n",
    "    x_test1,x_test2,x_test3 = [],[],[]\n",
    "    o_test, y_test = apnea_ecg[\"o_test\"], apnea_ecg[\"y_test\"]\n",
    "    groups_test = apnea_ecg[\"groups_test\"]\n",
    "    for i in range(len(o_test)):\n",
    "        min_distance_list, max_distance_list = o_test[i]\n",
    "        min_distance_list_inter = interpolate_numpy_array(min_distance_list,900)\n",
    "        max_distance_list_inter = interpolate_numpy_array(max_distance_list,900)\n",
    "        x_test1.append([min_distance_list_inter, max_distance_list_inter])\n",
    "        x_test2.append([min_distance_list_inter[180:720], max_distance_list_inter[180:720]])\n",
    "        x_test3.append([min_distance_list_inter[360:540], max_distance_list_inter[360:540]])\n",
    "    x_test1 = np.array(x_test1, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_test2 = np.array(x_test2, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_test3 = np.array(x_test3, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    y_test = np.array(y_test, dtype=\"float32\")\n",
    "\n",
    "    return x_training1, x_training2, x_training3, y_training, groups_training, x_val1, x_val2, x_val3, y_val, groups_val, x_test1, x_test2, x_test3, y_test, groups_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ef5b79-3b27-4888-9bb6-ad2415d780d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, ratio=4,**kwargs):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.channels = input_shape[-1]\n",
    "        self.fc1 = tf.keras.layers.Dense(self.channels // self.ratio, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(self.channels, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        max_pool = tf.reduce_max(inputs, axis=[1, 2], keepdims=True)\n",
    "        avg_pool = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n",
    "        max_pool = self.fc1(max_pool)\n",
    "        avg_pool = self.fc1(avg_pool)\n",
    "        attention = self.fc2(tf.keras.layers.add([max_pool, avg_pool]))\n",
    "        return inputs * attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9c50e53-c397-4432-bb00-4ec3a202a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = keras.layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71576d5f-5bfa-4321-bd05-f1a9b3c2d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualAttentionBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(ResidualAttentionBlock, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv1D(num_output_features, kernel_size=1, strides=1, padding='valid', use_bias=False)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv1D(num_output_features, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv3 = tf.keras.layers.Conv1D(num_output_features, kernel_size=1, strides=1, padding='valid', use_bias=False)\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        residual = x       \n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = self.sigmoid(out)      \n",
    "\n",
    "        out = out * residual + residual\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd7222a-ca10-4ac3-b7ca-6272cbbd2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers=2, d_model=64, nhead=1, dim_feedforward=128, dropout=0.30):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.precnnlayer = layers.Dense(d_model)\n",
    "        self.multi_head_attention = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model)\n",
    "\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(dim_feedforward, activation='relu'),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "\n",
    "        self.layer_norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "        self.pred_layer = tf.keras.Sequential([\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.precnnlayer(x)\n",
    "        x += self.multi_head_attention(x, x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm1(x)\n",
    "        ffn_output = self.ffn(x)\n",
    "        x += ffn_output\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.pred_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "GnDFx0fGCy1m",
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1693232096445,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "GnDFx0fGCy1m"
   },
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling1D\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, GRU, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "def create_model(input_b_shape, weight=1e-3,rate=1):\n",
    "    leaky_relu = LeakyReLU()\n",
    "\n",
    "    # SCNN-2\n",
    "    input2 = Input(shape=input_b_shape)\n",
    "    x2 = BatchNormalization()(input2)\n",
    "\n",
    "    x2 = Conv1D(16, kernel_size=9, strides=4, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x2)\n",
    "    \n",
    "    x2 = leaky_relu(x2)\n",
    "    x2 = MaxPooling1D(pool_size=3)(x2)\n",
    "    x2 = Dropout(0.5)(x2)\n",
    "\n",
    "    x2 = Conv1D(32, kernel_size=5, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = leaky_relu(x2)\n",
    "    x2 = MaxPooling1D(pool_size=3)(x2)\n",
    "    x2 = Dropout(0.5)(x2)\n",
    "\n",
    "    x2 = Conv1D(64, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = leaky_relu(x2)\n",
    "    x2 = Dropout(0.5)(x2)\n",
    "\n",
    "    x2 = Conv1D(128, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = leaky_relu(x2)\n",
    "    x2 = Dropout(0.5)(x2)\n",
    "\n",
    "    x2 = Conv1D(256, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = leaky_relu(x2)   \n",
    "    x2 = MaxPooling1D(pool_size=3)(x2)    \n",
    "    x2 = Dropout(0.5)(x2)\n",
    "\n",
    "    attention = ResidualAttentionBlock(256, 256)\n",
    "    x2 = attention(x2)\n",
    "\n",
    "    concat=ChannelAttention()(x2)\n",
    "    x = GlobalAveragePooling1D()(concat)\n",
    "    dp = Dropout(0.5)(x)\n",
    "    outputs = Dense(2, activation='softmax', name=\"Output_Layer\")(dp)\n",
    "    model = Model(inputs=input2, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c830eb3",
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1693232100397,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "6c830eb3"
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch > 70 and \\\n",
    "            (epoch - 1) % 10 == 0:\n",
    "        lr *= 0.1\n",
    "    print(\"Learning rate: \", lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded3f606",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1693232101699,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "ded3f606"
   },
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    \"\"\"Plot performance curve\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    axes[0].plot(history[\"loss\"], \"r-\", history[\"val_loss\"], \"b-\", linewidth=0.5)\n",
    "    axes[0].set_title(\"Loss\")\n",
    "    axes[1].plot(history[\"accuracy\"], \"r-\", history[\"val_accuracy\"], \"b-\", linewidth=0.5)\n",
    "    axes[1].set_title(\"Accuracy\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "v6XhEYeu7cgM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45661,
     "status": "ok",
     "timestamp": 1693233004292,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "v6XhEYeu7cgM",
    "outputId": "4f452c32-a1f2-4c9e-b7bc-05ca348f3613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape (11699, 900, 2) (11699, 540, 2) (11699, 180, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    x_train1, x_train2, x_train3, y_train, groups_train, x_val1, x_val2, x_val3, y_val, groups_val, x_test1, x_test2, x_test3, y_test, groups_test= load_data()\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes=2)  # Convert to two categories\n",
    "    y_val = keras.utils.to_categorical(y_val, num_classes=2)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes=2)\n",
    "\n",
    "    print('input_shape', x_train1.shape, x_train2.shape, x_train3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae98c6d-d470-4371-b7bb-6707c20168f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 21s 49ms/step - loss: 1.7364 - accuracy: 0.5706 - val_loss: 1.5048 - val_accuracy: 0.5844 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.4386 - accuracy: 0.6152 - val_loss: 1.3960 - val_accuracy: 0.5826 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.2691 - accuracy: 0.6363 - val_loss: 1.2575 - val_accuracy: 0.5866 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 1.1372 - accuracy: 0.6485 - val_loss: 1.1183 - val_accuracy: 0.5975 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 1.0278 - accuracy: 0.6603 - val_loss: 1.0089 - val_accuracy: 0.6195 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.9382 - accuracy: 0.6797 - val_loss: 0.9231 - val_accuracy: 0.6643 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.8636 - accuracy: 0.6918 - val_loss: 0.8612 - val_accuracy: 0.6504 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.8018 - accuracy: 0.7142 - val_loss: 0.7554 - val_accuracy: 0.7509 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.7427 - accuracy: 0.7275 - val_loss: 0.7032 - val_accuracy: 0.7513 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 4s 39ms/step - loss: 0.6824 - accuracy: 0.7503 - val_loss: 0.6499 - val_accuracy: 0.7702 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.6412 - accuracy: 0.7672 - val_loss: 0.6354 - val_accuracy: 0.7948 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.6037 - accuracy: 0.7802 - val_loss: 0.5558 - val_accuracy: 0.8133 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.5724 - accuracy: 0.7860 - val_loss: 0.5282 - val_accuracy: 0.8161 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.5355 - accuracy: 0.8064 - val_loss: 0.5075 - val_accuracy: 0.8285 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.5078 - accuracy: 0.8214 - val_loss: 0.4654 - val_accuracy: 0.8462 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.4832 - accuracy: 0.8332 - val_loss: 0.4503 - val_accuracy: 0.8592 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.4582 - accuracy: 0.8455 - val_loss: 0.4394 - val_accuracy: 0.8598 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.4390 - accuracy: 0.8552 - val_loss: 0.4052 - val_accuracy: 0.8732 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4354 - accuracy: 0.8532 - val_loss: 0.3964 - val_accuracy: 0.8742 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4286 - accuracy: 0.8580 - val_loss: 0.3937 - val_accuracy: 0.8736 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4181 - accuracy: 0.8608 - val_loss: 0.3936 - val_accuracy: 0.8716 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4073 - accuracy: 0.8590 - val_loss: 0.4091 - val_accuracy: 0.8682 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.4063 - accuracy: 0.8613 - val_loss: 0.3804 - val_accuracy: 0.8767 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.4008 - accuracy: 0.8619 - val_loss: 0.3730 - val_accuracy: 0.8759 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3917 - accuracy: 0.8691 - val_loss: 0.3555 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3846 - accuracy: 0.8698 - val_loss: 0.3563 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3861 - accuracy: 0.8689 - val_loss: 0.3703 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3796 - accuracy: 0.8685 - val_loss: 0.3525 - val_accuracy: 0.8785 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3786 - accuracy: 0.8679 - val_loss: 0.3401 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3785 - accuracy: 0.8708 - val_loss: 0.3594 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3781 - accuracy: 0.8703 - val_loss: 0.3449 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3724 - accuracy: 0.8731 - val_loss: 0.3416 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3688 - accuracy: 0.8728 - val_loss: 0.3599 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3714 - accuracy: 0.8708 - val_loss: 0.3367 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3670 - accuracy: 0.8746 - val_loss: 0.3444 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3644 - accuracy: 0.8745 - val_loss: 0.3553 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3720 - accuracy: 0.8712 - val_loss: 0.3484 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3629 - accuracy: 0.8746 - val_loss: 0.3378 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3632 - accuracy: 0.8729 - val_loss: 0.3354 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3612 - accuracy: 0.8764 - val_loss: 0.3557 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3643 - accuracy: 0.8714 - val_loss: 0.3497 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3660 - accuracy: 0.8738 - val_loss: 0.3450 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3543 - accuracy: 0.8826 - val_loss: 0.3563 - val_accuracy: 0.8777 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3583 - accuracy: 0.8783 - val_loss: 0.3356 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3593 - accuracy: 0.8748 - val_loss: 0.3525 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3599 - accuracy: 0.8732 - val_loss: 0.3375 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3513 - accuracy: 0.8811 - val_loss: 0.3304 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3622 - accuracy: 0.8714 - val_loss: 0.3426 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3569 - accuracy: 0.8770 - val_loss: 0.3265 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3540 - accuracy: 0.8790 - val_loss: 0.3304 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3532 - accuracy: 0.8761 - val_loss: 0.3389 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3604 - accuracy: 0.8760 - val_loss: 0.3234 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3616 - accuracy: 0.8752 - val_loss: 0.3284 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3509 - accuracy: 0.8798 - val_loss: 0.3217 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3504 - accuracy: 0.8782 - val_loss: 0.3238 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3549 - accuracy: 0.8765 - val_loss: 0.3257 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3540 - accuracy: 0.8784 - val_loss: 0.3235 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3494 - accuracy: 0.8805 - val_loss: 0.3195 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3521 - accuracy: 0.8799 - val_loss: 0.3355 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3523 - accuracy: 0.8775 - val_loss: 0.3222 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3549 - accuracy: 0.8764 - val_loss: 0.3403 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3462 - accuracy: 0.8831 - val_loss: 0.3365 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3534 - accuracy: 0.8785 - val_loss: 0.3227 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3500 - accuracy: 0.8809 - val_loss: 0.3182 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3537 - accuracy: 0.8776 - val_loss: 0.3305 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3554 - accuracy: 0.8746 - val_loss: 0.3507 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3549 - accuracy: 0.8783 - val_loss: 0.3176 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3472 - accuracy: 0.8801 - val_loss: 0.3271 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3517 - accuracy: 0.8791 - val_loss: 0.3267 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3472 - accuracy: 0.8788 - val_loss: 0.3243 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3442 - accuracy: 0.8813 - val_loss: 0.3219 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3445 - accuracy: 0.8810 - val_loss: 0.3174 - val_accuracy: 0.8953 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3356 - accuracy: 0.8825 - val_loss: 0.3206 - val_accuracy: 0.8939 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3305 - accuracy: 0.8857 - val_loss: 0.3207 - val_accuracy: 0.8945 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3371 - accuracy: 0.8803 - val_loss: 0.3160 - val_accuracy: 0.8949 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3321 - accuracy: 0.8820 - val_loss: 0.3142 - val_accuracy: 0.8949 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3350 - accuracy: 0.8832 - val_loss: 0.3163 - val_accuracy: 0.8925 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3301 - accuracy: 0.8843 - val_loss: 0.3129 - val_accuracy: 0.8955 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3244 - accuracy: 0.8865 - val_loss: 0.3143 - val_accuracy: 0.8951 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3258 - accuracy: 0.8857 - val_loss: 0.3156 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3253 - accuracy: 0.8854 - val_loss: 0.3102 - val_accuracy: 0.8949 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3221 - accuracy: 0.8907 - val_loss: 0.3116 - val_accuracy: 0.8945 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3265 - accuracy: 0.8861 - val_loss: 0.3118 - val_accuracy: 0.8951 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3151 - accuracy: 0.8916 - val_loss: 0.3128 - val_accuracy: 0.8945 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3242 - accuracy: 0.8873 - val_loss: 0.3127 - val_accuracy: 0.8949 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3234 - accuracy: 0.8847 - val_loss: 0.3125 - val_accuracy: 0.8967 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3238 - accuracy: 0.8855 - val_loss: 0.3113 - val_accuracy: 0.8967 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3150 - accuracy: 0.8901 - val_loss: 0.3117 - val_accuracy: 0.8969 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3196 - accuracy: 0.8893 - val_loss: 0.3120 - val_accuracy: 0.8961 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3174 - accuracy: 0.8877 - val_loss: 0.3125 - val_accuracy: 0.8957 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3234 - accuracy: 0.8849 - val_loss: 0.3118 - val_accuracy: 0.8967 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3233 - accuracy: 0.8894 - val_loss: 0.3117 - val_accuracy: 0.8969 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3201 - accuracy: 0.8871 - val_loss: 0.3116 - val_accuracy: 0.8973 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3242 - accuracy: 0.8853 - val_loss: 0.3114 - val_accuracy: 0.8967 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3201 - accuracy: 0.8885 - val_loss: 0.3113 - val_accuracy: 0.8967 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3179 - accuracy: 0.8861 - val_loss: 0.3111 - val_accuracy: 0.8967 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3189 - accuracy: 0.8885 - val_loss: 0.3112 - val_accuracy: 0.8971 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3268 - accuracy: 0.8869 - val_loss: 0.3112 - val_accuracy: 0.8971 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3185 - accuracy: 0.8883 - val_loss: 0.3111 - val_accuracy: 0.8973 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.3239 - accuracy: 0.8861 - val_loss: 0.3111 - val_accuracy: 0.8971 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 0.2800 - accuracy: 0.9023\n",
      "17/17 [==============================] - 1s 15ms/step\n",
      "TP:5547, TN:9744, FP:711, FN:944, loss0.2799815535545349, acc0.9023368346512451, sn0.8545678631951934, sp0.9319942611190818, f10.8701858969330928, auc0.9613902809621768\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 15s 34ms/step - loss: 1.7443 - accuracy: 0.5646 - val_loss: 1.6064 - val_accuracy: 0.4210 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 1.4542 - accuracy: 0.6018 - val_loss: 1.5816 - val_accuracy: 0.3849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 1.2894 - accuracy: 0.6147 - val_loss: 1.4027 - val_accuracy: 0.3859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 1.1498 - accuracy: 0.6355 - val_loss: 1.2184 - val_accuracy: 0.4182 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 1.0346 - accuracy: 0.6450 - val_loss: 1.1048 - val_accuracy: 0.4601 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.9319 - accuracy: 0.6734 - val_loss: 1.0504 - val_accuracy: 0.4910 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.8605 - accuracy: 0.6810 - val_loss: 0.9744 - val_accuracy: 0.5351 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.7854 - accuracy: 0.7188 - val_loss: 0.8186 - val_accuracy: 0.6570 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.7240 - accuracy: 0.7351 - val_loss: 0.7604 - val_accuracy: 0.6891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6788 - accuracy: 0.7454 - val_loss: 0.7247 - val_accuracy: 0.7066 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6381 - accuracy: 0.7644 - val_loss: 0.6313 - val_accuracy: 0.7603 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6052 - accuracy: 0.7803 - val_loss: 0.5432 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5701 - accuracy: 0.7895 - val_loss: 0.5301 - val_accuracy: 0.8101 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.5438 - accuracy: 0.8025 - val_loss: 0.5318 - val_accuracy: 0.8141 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5196 - accuracy: 0.8114 - val_loss: 0.5026 - val_accuracy: 0.8265 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5011 - accuracy: 0.8180 - val_loss: 0.5089 - val_accuracy: 0.8201 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.4811 - accuracy: 0.8302 - val_loss: 0.4368 - val_accuracy: 0.8492 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.4614 - accuracy: 0.8373 - val_loss: 0.4145 - val_accuracy: 0.8584 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.4399 - accuracy: 0.8492 - val_loss: 0.4417 - val_accuracy: 0.8528 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.4357 - accuracy: 0.8479 - val_loss: 0.4093 - val_accuracy: 0.8626 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.4227 - accuracy: 0.8529 - val_loss: 0.3847 - val_accuracy: 0.8732 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.4188 - accuracy: 0.8528 - val_loss: 0.3878 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.4059 - accuracy: 0.8590 - val_loss: 0.3723 - val_accuracy: 0.8738 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.4103 - accuracy: 0.8615 - val_loss: 0.3666 - val_accuracy: 0.8738 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.4027 - accuracy: 0.8604 - val_loss: 0.3851 - val_accuracy: 0.8751 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3977 - accuracy: 0.8610 - val_loss: 0.3674 - val_accuracy: 0.8777 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3894 - accuracy: 0.8663 - val_loss: 0.3608 - val_accuracy: 0.8797 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3861 - accuracy: 0.8671 - val_loss: 0.3540 - val_accuracy: 0.8777 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3934 - accuracy: 0.8620 - val_loss: 0.3780 - val_accuracy: 0.8704 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3837 - accuracy: 0.8682 - val_loss: 0.3623 - val_accuracy: 0.8789 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3870 - accuracy: 0.8643 - val_loss: 0.3443 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3842 - accuracy: 0.8689 - val_loss: 0.3532 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3857 - accuracy: 0.8651 - val_loss: 0.3551 - val_accuracy: 0.8837 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3810 - accuracy: 0.8666 - val_loss: 0.3428 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3718 - accuracy: 0.8746 - val_loss: 0.3474 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3752 - accuracy: 0.8713 - val_loss: 0.3617 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3716 - accuracy: 0.8743 - val_loss: 0.3502 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3704 - accuracy: 0.8696 - val_loss: 0.3389 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3684 - accuracy: 0.8742 - val_loss: 0.3407 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3665 - accuracy: 0.8741 - val_loss: 0.3513 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3645 - accuracy: 0.8726 - val_loss: 0.3427 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3756 - accuracy: 0.8707 - val_loss: 0.3297 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3628 - accuracy: 0.8736 - val_loss: 0.3373 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3644 - accuracy: 0.8751 - val_loss: 0.3398 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3625 - accuracy: 0.8759 - val_loss: 0.3358 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3629 - accuracy: 0.8742 - val_loss: 0.3445 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3690 - accuracy: 0.8737 - val_loss: 0.3432 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3616 - accuracy: 0.8776 - val_loss: 0.3312 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3668 - accuracy: 0.8741 - val_loss: 0.3482 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.3600 - accuracy: 0.8766 - val_loss: 0.3333 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3709 - accuracy: 0.8719 - val_loss: 0.3404 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3601 - accuracy: 0.8769 - val_loss: 0.3355 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3650 - accuracy: 0.8723 - val_loss: 0.3569 - val_accuracy: 0.8769 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3536 - accuracy: 0.8753 - val_loss: 0.3348 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.3600 - accuracy: 0.8778 - val_loss: 0.3274 - val_accuracy: 0.8935 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3549 - accuracy: 0.8783 - val_loss: 0.3467 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3582 - accuracy: 0.8774 - val_loss: 0.3359 - val_accuracy: 0.8837 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3556 - accuracy: 0.8769 - val_loss: 0.3534 - val_accuracy: 0.8821 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3600 - accuracy: 0.8765 - val_loss: 0.3433 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3559 - accuracy: 0.8780 - val_loss: 0.3341 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3582 - accuracy: 0.8777 - val_loss: 0.3309 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3521 - accuracy: 0.8785 - val_loss: 0.3304 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3523 - accuracy: 0.8798 - val_loss: 0.3344 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3595 - accuracy: 0.8770 - val_loss: 0.3307 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3515 - accuracy: 0.8815 - val_loss: 0.3210 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3520 - accuracy: 0.8791 - val_loss: 0.3215 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3567 - accuracy: 0.8793 - val_loss: 0.3317 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3578 - accuracy: 0.8770 - val_loss: 0.3409 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3635 - accuracy: 0.8738 - val_loss: 0.3426 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3443 - accuracy: 0.8824 - val_loss: 0.3167 - val_accuracy: 0.8969 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3547 - accuracy: 0.8775 - val_loss: 0.3232 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3465 - accuracy: 0.8793 - val_loss: 0.3250 - val_accuracy: 0.8897 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3380 - accuracy: 0.8866 - val_loss: 0.3248 - val_accuracy: 0.8925 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3357 - accuracy: 0.8875 - val_loss: 0.3240 - val_accuracy: 0.8917 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3376 - accuracy: 0.8822 - val_loss: 0.3229 - val_accuracy: 0.8925 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3338 - accuracy: 0.8833 - val_loss: 0.3192 - val_accuracy: 0.8943 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3319 - accuracy: 0.8825 - val_loss: 0.3173 - val_accuracy: 0.8941 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3324 - accuracy: 0.8863 - val_loss: 0.3166 - val_accuracy: 0.8923 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3238 - accuracy: 0.8888 - val_loss: 0.3148 - val_accuracy: 0.8927 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3333 - accuracy: 0.8830 - val_loss: 0.3107 - val_accuracy: 0.8943 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3261 - accuracy: 0.8877 - val_loss: 0.3158 - val_accuracy: 0.8955 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3273 - accuracy: 0.8842 - val_loss: 0.3132 - val_accuracy: 0.8949 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3236 - accuracy: 0.8876 - val_loss: 0.3129 - val_accuracy: 0.8955 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3296 - accuracy: 0.8842 - val_loss: 0.3118 - val_accuracy: 0.8959 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3252 - accuracy: 0.8901 - val_loss: 0.3115 - val_accuracy: 0.8965 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3228 - accuracy: 0.8870 - val_loss: 0.3117 - val_accuracy: 0.8961 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3219 - accuracy: 0.8857 - val_loss: 0.3122 - val_accuracy: 0.8959 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3277 - accuracy: 0.8892 - val_loss: 0.3120 - val_accuracy: 0.8959 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3237 - accuracy: 0.8881 - val_loss: 0.3114 - val_accuracy: 0.8961 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3277 - accuracy: 0.8870 - val_loss: 0.3118 - val_accuracy: 0.8965 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3215 - accuracy: 0.8885 - val_loss: 0.3118 - val_accuracy: 0.8961 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3291 - accuracy: 0.8887 - val_loss: 0.3116 - val_accuracy: 0.8961 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3290 - accuracy: 0.8843 - val_loss: 0.3118 - val_accuracy: 0.8957 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3283 - accuracy: 0.8827 - val_loss: 0.3117 - val_accuracy: 0.8957 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3202 - accuracy: 0.8901 - val_loss: 0.3117 - val_accuracy: 0.8961 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3241 - accuracy: 0.8884 - val_loss: 0.3121 - val_accuracy: 0.8959 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3228 - accuracy: 0.8853 - val_loss: 0.3118 - val_accuracy: 0.8961 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3251 - accuracy: 0.8876 - val_loss: 0.3122 - val_accuracy: 0.8953 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3235 - accuracy: 0.8897 - val_loss: 0.3118 - val_accuracy: 0.8961 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3286 - accuracy: 0.8842 - val_loss: 0.3118 - val_accuracy: 0.8959 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 9ms/step - loss: 0.2825 - accuracy: 0.9029\n",
      "17/17 [==============================] - 1s 8ms/step\n",
      "TP:5477, TN:9823, FP:632, FN:1014, loss0.28247901797294617, acc0.902867933435619, sn0.8437837005083962, sp0.9395504543280727, f10.8693650793650795, auc0.960953432855307\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 16s 40ms/step - loss: 1.7009 - accuracy: 0.5648 - val_loss: 1.4969 - val_accuracy: 0.5776 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.4181 - accuracy: 0.6095 - val_loss: 1.3578 - val_accuracy: 0.5937 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 1.2445 - accuracy: 0.6299 - val_loss: 1.2168 - val_accuracy: 0.5915 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.1005 - accuracy: 0.6533 - val_loss: 1.0753 - val_accuracy: 0.6115 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.9893 - accuracy: 0.6639 - val_loss: 0.9721 - val_accuracy: 0.6187 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.9042 - accuracy: 0.6807 - val_loss: 0.8880 - val_accuracy: 0.6534 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.8289 - accuracy: 0.6984 - val_loss: 0.7936 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.7698 - accuracy: 0.7212 - val_loss: 0.7943 - val_accuracy: 0.6488 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.7111 - accuracy: 0.7348 - val_loss: 0.6779 - val_accuracy: 0.7585 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.6647 - accuracy: 0.7554 - val_loss: 0.6040 - val_accuracy: 0.7992 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6263 - accuracy: 0.7660 - val_loss: 0.5654 - val_accuracy: 0.8051 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.5916 - accuracy: 0.7794 - val_loss: 0.5393 - val_accuracy: 0.8049 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.5684 - accuracy: 0.7859 - val_loss: 0.5263 - val_accuracy: 0.8143 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.5408 - accuracy: 0.8004 - val_loss: 0.5030 - val_accuracy: 0.8229 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.5102 - accuracy: 0.8145 - val_loss: 0.5060 - val_accuracy: 0.8247 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.4831 - accuracy: 0.8272 - val_loss: 0.4335 - val_accuracy: 0.8594 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4639 - accuracy: 0.8390 - val_loss: 0.4319 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4480 - accuracy: 0.8458 - val_loss: 0.4341 - val_accuracy: 0.8626 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4340 - accuracy: 0.8497 - val_loss: 0.4171 - val_accuracy: 0.8606 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4335 - accuracy: 0.8490 - val_loss: 0.3916 - val_accuracy: 0.8730 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4202 - accuracy: 0.8544 - val_loss: 0.3878 - val_accuracy: 0.8702 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4157 - accuracy: 0.8566 - val_loss: 0.3936 - val_accuracy: 0.8753 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4041 - accuracy: 0.8622 - val_loss: 0.3669 - val_accuracy: 0.8805 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4097 - accuracy: 0.8561 - val_loss: 0.3643 - val_accuracy: 0.8791 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3950 - accuracy: 0.8653 - val_loss: 0.3694 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3913 - accuracy: 0.8659 - val_loss: 0.3735 - val_accuracy: 0.8767 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3892 - accuracy: 0.8637 - val_loss: 0.3565 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3877 - accuracy: 0.8690 - val_loss: 0.3801 - val_accuracy: 0.8767 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3845 - accuracy: 0.8670 - val_loss: 0.3622 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3797 - accuracy: 0.8694 - val_loss: 0.3486 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3765 - accuracy: 0.8686 - val_loss: 0.3383 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3741 - accuracy: 0.8735 - val_loss: 0.3555 - val_accuracy: 0.8803 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3742 - accuracy: 0.8702 - val_loss: 0.3421 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3677 - accuracy: 0.8732 - val_loss: 0.3557 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3683 - accuracy: 0.8741 - val_loss: 0.3507 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3710 - accuracy: 0.8711 - val_loss: 0.3633 - val_accuracy: 0.8813 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3624 - accuracy: 0.8726 - val_loss: 0.3411 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3690 - accuracy: 0.8720 - val_loss: 0.3463 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3642 - accuracy: 0.8744 - val_loss: 0.3591 - val_accuracy: 0.8809 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3662 - accuracy: 0.8721 - val_loss: 0.3477 - val_accuracy: 0.8805 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3609 - accuracy: 0.8757 - val_loss: 0.3515 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3604 - accuracy: 0.8758 - val_loss: 0.3438 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3639 - accuracy: 0.8732 - val_loss: 0.3370 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3651 - accuracy: 0.8725 - val_loss: 0.3393 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3578 - accuracy: 0.8755 - val_loss: 0.3416 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3673 - accuracy: 0.8716 - val_loss: 0.3290 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3583 - accuracy: 0.8773 - val_loss: 0.3408 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3565 - accuracy: 0.8768 - val_loss: 0.3504 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3573 - accuracy: 0.8782 - val_loss: 0.3543 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3563 - accuracy: 0.8779 - val_loss: 0.3408 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3531 - accuracy: 0.8755 - val_loss: 0.3502 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3526 - accuracy: 0.8746 - val_loss: 0.3329 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3603 - accuracy: 0.8735 - val_loss: 0.3465 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.3514 - accuracy: 0.8774 - val_loss: 0.3294 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3594 - accuracy: 0.8726 - val_loss: 0.3348 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3537 - accuracy: 0.8796 - val_loss: 0.3385 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3483 - accuracy: 0.8767 - val_loss: 0.3315 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3528 - accuracy: 0.8755 - val_loss: 0.3370 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3496 - accuracy: 0.8780 - val_loss: 0.3217 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3530 - accuracy: 0.8792 - val_loss: 0.3314 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3528 - accuracy: 0.8774 - val_loss: 0.3332 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3457 - accuracy: 0.8817 - val_loss: 0.3447 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.3543 - accuracy: 0.8760 - val_loss: 0.3377 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3525 - accuracy: 0.8779 - val_loss: 0.3280 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3457 - accuracy: 0.8808 - val_loss: 0.3322 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3550 - accuracy: 0.8792 - val_loss: 0.3259 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3504 - accuracy: 0.8837 - val_loss: 0.3222 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3441 - accuracy: 0.8788 - val_loss: 0.3303 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3516 - accuracy: 0.8793 - val_loss: 0.3293 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3539 - accuracy: 0.8797 - val_loss: 0.3451 - val_accuracy: 0.8821 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3533 - accuracy: 0.8761 - val_loss: 0.3283 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3412 - accuracy: 0.8826 - val_loss: 0.3253 - val_accuracy: 0.8901 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3367 - accuracy: 0.8839 - val_loss: 0.3220 - val_accuracy: 0.8925 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3394 - accuracy: 0.8824 - val_loss: 0.3224 - val_accuracy: 0.8923 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3307 - accuracy: 0.8855 - val_loss: 0.3218 - val_accuracy: 0.8909 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3321 - accuracy: 0.8837 - val_loss: 0.3208 - val_accuracy: 0.8935 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3336 - accuracy: 0.8860 - val_loss: 0.3175 - val_accuracy: 0.8913 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3282 - accuracy: 0.8841 - val_loss: 0.3196 - val_accuracy: 0.8913 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3314 - accuracy: 0.8838 - val_loss: 0.3137 - val_accuracy: 0.8931 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3284 - accuracy: 0.8848 - val_loss: 0.3118 - val_accuracy: 0.8939 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3212 - accuracy: 0.8902 - val_loss: 0.3117 - val_accuracy: 0.8935 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3263 - accuracy: 0.8891 - val_loss: 0.3133 - val_accuracy: 0.8931 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3296 - accuracy: 0.8856 - val_loss: 0.3137 - val_accuracy: 0.8941 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3249 - accuracy: 0.8854 - val_loss: 0.3132 - val_accuracy: 0.8943 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3230 - accuracy: 0.8885 - val_loss: 0.3136 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3263 - accuracy: 0.8854 - val_loss: 0.3135 - val_accuracy: 0.8943 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3231 - accuracy: 0.8883 - val_loss: 0.3136 - val_accuracy: 0.8941 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3252 - accuracy: 0.8844 - val_loss: 0.3135 - val_accuracy: 0.8943 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3212 - accuracy: 0.8895 - val_loss: 0.3132 - val_accuracy: 0.8941 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3213 - accuracy: 0.8870 - val_loss: 0.3136 - val_accuracy: 0.8941 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3150 - accuracy: 0.8887 - val_loss: 0.3137 - val_accuracy: 0.8935 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3210 - accuracy: 0.8884 - val_loss: 0.3139 - val_accuracy: 0.8937 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3304 - accuracy: 0.8843 - val_loss: 0.3140 - val_accuracy: 0.8937 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3221 - accuracy: 0.8879 - val_loss: 0.3140 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3214 - accuracy: 0.8861 - val_loss: 0.3139 - val_accuracy: 0.8937 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3220 - accuracy: 0.8869 - val_loss: 0.3137 - val_accuracy: 0.8937 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3194 - accuracy: 0.8882 - val_loss: 0.3136 - val_accuracy: 0.8937 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3212 - accuracy: 0.8860 - val_loss: 0.3137 - val_accuracy: 0.8939 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3241 - accuracy: 0.8878 - val_loss: 0.3138 - val_accuracy: 0.8939 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3227 - accuracy: 0.8902 - val_loss: 0.3139 - val_accuracy: 0.8945 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 9ms/step - loss: 0.2823 - accuracy: 0.9031\n",
      "17/17 [==============================] - 1s 9ms/step\n",
      "TP:5535, TN:9769, FP:686, FN:956, loss0.282308429479599, acc0.9031039773397852, sn0.8527191495917424, sp0.9343854615016738, f10.8708307111390811, auc0.9609446505078841\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 16s 42ms/step - loss: 1.6744 - accuracy: 0.5675 - val_loss: 1.5070 - val_accuracy: 0.6107 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 1.3935 - accuracy: 0.6101 - val_loss: 1.3694 - val_accuracy: 0.4866 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 1.2117 - accuracy: 0.6407 - val_loss: 1.2415 - val_accuracy: 0.5323 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 1.0656 - accuracy: 0.6704 - val_loss: 1.1100 - val_accuracy: 0.5804 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.9432 - accuracy: 0.7055 - val_loss: 0.9153 - val_accuracy: 0.6893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.8361 - accuracy: 0.7319 - val_loss: 0.8080 - val_accuracy: 0.7252 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.7613 - accuracy: 0.7496 - val_loss: 0.6998 - val_accuracy: 0.7742 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.6976 - accuracy: 0.7687 - val_loss: 0.6257 - val_accuracy: 0.7990 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.6505 - accuracy: 0.7797 - val_loss: 0.5722 - val_accuracy: 0.8119 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6051 - accuracy: 0.7928 - val_loss: 0.5471 - val_accuracy: 0.8169 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.5637 - accuracy: 0.8101 - val_loss: 0.4993 - val_accuracy: 0.8367 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.5339 - accuracy: 0.8194 - val_loss: 0.4806 - val_accuracy: 0.8442 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.5176 - accuracy: 0.8212 - val_loss: 0.4676 - val_accuracy: 0.8464 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4959 - accuracy: 0.8290 - val_loss: 0.4418 - val_accuracy: 0.8536 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4752 - accuracy: 0.8363 - val_loss: 0.4360 - val_accuracy: 0.8526 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4594 - accuracy: 0.8419 - val_loss: 0.4229 - val_accuracy: 0.8580 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4447 - accuracy: 0.8506 - val_loss: 0.4055 - val_accuracy: 0.8678 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4355 - accuracy: 0.8514 - val_loss: 0.4286 - val_accuracy: 0.8554 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4288 - accuracy: 0.8538 - val_loss: 0.3905 - val_accuracy: 0.8702 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4246 - accuracy: 0.8542 - val_loss: 0.3851 - val_accuracy: 0.8714 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4171 - accuracy: 0.8572 - val_loss: 0.3968 - val_accuracy: 0.8724 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4098 - accuracy: 0.8601 - val_loss: 0.3837 - val_accuracy: 0.8694 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4019 - accuracy: 0.8600 - val_loss: 0.3839 - val_accuracy: 0.8706 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4066 - accuracy: 0.8571 - val_loss: 0.3659 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3990 - accuracy: 0.8616 - val_loss: 0.3769 - val_accuracy: 0.8740 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3910 - accuracy: 0.8647 - val_loss: 0.3773 - val_accuracy: 0.8700 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3891 - accuracy: 0.8655 - val_loss: 0.3819 - val_accuracy: 0.8728 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3878 - accuracy: 0.8680 - val_loss: 0.3927 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3861 - accuracy: 0.8658 - val_loss: 0.3709 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3816 - accuracy: 0.8682 - val_loss: 0.3527 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3829 - accuracy: 0.8692 - val_loss: 0.3489 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3782 - accuracy: 0.8666 - val_loss: 0.3749 - val_accuracy: 0.8748 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3766 - accuracy: 0.8726 - val_loss: 0.3436 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3827 - accuracy: 0.8668 - val_loss: 0.3612 - val_accuracy: 0.8781 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3751 - accuracy: 0.8737 - val_loss: 0.3569 - val_accuracy: 0.8821 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3763 - accuracy: 0.8732 - val_loss: 0.3583 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3731 - accuracy: 0.8706 - val_loss: 0.3466 - val_accuracy: 0.8805 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3722 - accuracy: 0.8702 - val_loss: 0.3465 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3725 - accuracy: 0.8708 - val_loss: 0.3646 - val_accuracy: 0.8807 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3753 - accuracy: 0.8690 - val_loss: 0.3400 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3682 - accuracy: 0.8751 - val_loss: 0.3383 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3769 - accuracy: 0.8673 - val_loss: 0.3463 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3686 - accuracy: 0.8716 - val_loss: 0.3553 - val_accuracy: 0.8805 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3663 - accuracy: 0.8724 - val_loss: 0.3444 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3640 - accuracy: 0.8722 - val_loss: 0.3329 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 36ms/step - loss: 0.3696 - accuracy: 0.8723 - val_loss: 0.3324 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3669 - accuracy: 0.8741 - val_loss: 0.3470 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.3686 - accuracy: 0.8720 - val_loss: 0.3539 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3725 - accuracy: 0.8710 - val_loss: 0.3366 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3646 - accuracy: 0.8735 - val_loss: 0.3453 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3625 - accuracy: 0.8747 - val_loss: 0.3451 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3611 - accuracy: 0.8761 - val_loss: 0.3427 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3705 - accuracy: 0.8728 - val_loss: 0.3350 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3618 - accuracy: 0.8769 - val_loss: 0.3448 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3548 - accuracy: 0.8762 - val_loss: 0.3575 - val_accuracy: 0.8801 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3544 - accuracy: 0.8789 - val_loss: 0.3382 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3583 - accuracy: 0.8738 - val_loss: 0.3286 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3653 - accuracy: 0.8750 - val_loss: 0.3510 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3546 - accuracy: 0.8785 - val_loss: 0.3350 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3631 - accuracy: 0.8742 - val_loss: 0.3343 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3657 - accuracy: 0.8711 - val_loss: 0.3665 - val_accuracy: 0.8797 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3588 - accuracy: 0.8758 - val_loss: 0.3432 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3597 - accuracy: 0.8762 - val_loss: 0.3412 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3609 - accuracy: 0.8746 - val_loss: 0.3510 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3569 - accuracy: 0.8767 - val_loss: 0.3421 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3573 - accuracy: 0.8781 - val_loss: 0.3381 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3676 - accuracy: 0.8730 - val_loss: 0.3442 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3503 - accuracy: 0.8791 - val_loss: 0.3361 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3628 - accuracy: 0.8749 - val_loss: 0.3421 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3557 - accuracy: 0.8734 - val_loss: 0.3415 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3530 - accuracy: 0.8799 - val_loss: 0.3430 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3451 - accuracy: 0.8820 - val_loss: 0.3362 - val_accuracy: 0.8899 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3426 - accuracy: 0.8823 - val_loss: 0.3315 - val_accuracy: 0.8909 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3443 - accuracy: 0.8815 - val_loss: 0.3279 - val_accuracy: 0.8927 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3379 - accuracy: 0.8842 - val_loss: 0.3290 - val_accuracy: 0.8933 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3391 - accuracy: 0.8819 - val_loss: 0.3254 - val_accuracy: 0.8925 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3404 - accuracy: 0.8806 - val_loss: 0.3284 - val_accuracy: 0.8927 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3333 - accuracy: 0.8852 - val_loss: 0.3226 - val_accuracy: 0.8935 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3329 - accuracy: 0.8858 - val_loss: 0.3276 - val_accuracy: 0.8913 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3345 - accuracy: 0.8826 - val_loss: 0.3201 - val_accuracy: 0.8951 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3328 - accuracy: 0.8825 - val_loss: 0.3223 - val_accuracy: 0.8943 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3302 - accuracy: 0.8839 - val_loss: 0.3211 - val_accuracy: 0.8945 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3325 - accuracy: 0.8832 - val_loss: 0.3215 - val_accuracy: 0.8945 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3336 - accuracy: 0.8833 - val_loss: 0.3206 - val_accuracy: 0.8953 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3334 - accuracy: 0.8796 - val_loss: 0.3206 - val_accuracy: 0.8953 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3333 - accuracy: 0.8826 - val_loss: 0.3211 - val_accuracy: 0.8949 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3278 - accuracy: 0.8864 - val_loss: 0.3204 - val_accuracy: 0.8961 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3304 - accuracy: 0.8828 - val_loss: 0.3197 - val_accuracy: 0.8961 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3268 - accuracy: 0.8881 - val_loss: 0.3206 - val_accuracy: 0.8963 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3300 - accuracy: 0.8827 - val_loss: 0.3209 - val_accuracy: 0.8961 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3292 - accuracy: 0.8832 - val_loss: 0.3198 - val_accuracy: 0.8959 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3231 - accuracy: 0.8871 - val_loss: 0.3198 - val_accuracy: 0.8959 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3303 - accuracy: 0.8867 - val_loss: 0.3202 - val_accuracy: 0.8963 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3297 - accuracy: 0.8854 - val_loss: 0.3200 - val_accuracy: 0.8955 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3302 - accuracy: 0.8804 - val_loss: 0.3202 - val_accuracy: 0.8957 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3329 - accuracy: 0.8847 - val_loss: 0.3201 - val_accuracy: 0.8961 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3291 - accuracy: 0.8855 - val_loss: 0.3199 - val_accuracy: 0.8963 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3276 - accuracy: 0.8862 - val_loss: 0.3199 - val_accuracy: 0.8959 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3256 - accuracy: 0.8884 - val_loss: 0.3200 - val_accuracy: 0.8963 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3249 - accuracy: 0.8843 - val_loss: 0.3198 - val_accuracy: 0.8963 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 9ms/step - loss: 0.2856 - accuracy: 0.9030\n",
      "17/17 [==============================] - 1s 8ms/step\n",
      "TP:5515, TN:9788, FP:667, FN:976, loss0.28556734323501587, acc0.9030449663637437, sn0.8496379602526575, sp0.9362027737924438, f10.8703542965359427, auc0.9606879510392974\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 17s 41ms/step - loss: 1.7077 - accuracy: 0.5810 - val_loss: 1.6301 - val_accuracy: 0.3869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.4263 - accuracy: 0.6157 - val_loss: 1.4509 - val_accuracy: 0.3849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.2578 - accuracy: 0.6327 - val_loss: 1.3068 - val_accuracy: 0.4178 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.1230 - accuracy: 0.6489 - val_loss: 1.1903 - val_accuracy: 0.3979 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 1.0117 - accuracy: 0.6663 - val_loss: 1.1130 - val_accuracy: 0.4204 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.9243 - accuracy: 0.6790 - val_loss: 1.0766 - val_accuracy: 0.4844 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.8555 - accuracy: 0.6896 - val_loss: 1.0435 - val_accuracy: 0.4872 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.7983 - accuracy: 0.7042 - val_loss: 1.0778 - val_accuracy: 0.4635 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.7455 - accuracy: 0.7201 - val_loss: 0.9971 - val_accuracy: 0.4860 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.6993 - accuracy: 0.7336 - val_loss: 0.9241 - val_accuracy: 0.5441 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6638 - accuracy: 0.7463 - val_loss: 0.6978 - val_accuracy: 0.7194 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.6348 - accuracy: 0.7602 - val_loss: 0.6422 - val_accuracy: 0.7439 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.6140 - accuracy: 0.7655 - val_loss: 0.5842 - val_accuracy: 0.7677 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.5871 - accuracy: 0.7726 - val_loss: 0.5426 - val_accuracy: 0.7908 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.5650 - accuracy: 0.7831 - val_loss: 0.5356 - val_accuracy: 0.7936 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.5494 - accuracy: 0.7866 - val_loss: 0.5183 - val_accuracy: 0.8045 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.5316 - accuracy: 0.7962 - val_loss: 0.4872 - val_accuracy: 0.8237 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.5103 - accuracy: 0.8078 - val_loss: 0.4742 - val_accuracy: 0.8315 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4871 - accuracy: 0.8202 - val_loss: 0.4522 - val_accuracy: 0.8462 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.4686 - accuracy: 0.8297 - val_loss: 0.4802 - val_accuracy: 0.8381 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.4535 - accuracy: 0.8409 - val_loss: 0.4850 - val_accuracy: 0.8301 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.4423 - accuracy: 0.8448 - val_loss: 0.4222 - val_accuracy: 0.8562 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.4291 - accuracy: 0.8471 - val_loss: 0.4177 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4252 - accuracy: 0.8479 - val_loss: 0.3899 - val_accuracy: 0.8668 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4157 - accuracy: 0.8563 - val_loss: 0.3746 - val_accuracy: 0.8765 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4125 - accuracy: 0.8573 - val_loss: 0.3556 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4015 - accuracy: 0.8608 - val_loss: 0.3806 - val_accuracy: 0.8698 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3946 - accuracy: 0.8624 - val_loss: 0.3628 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3950 - accuracy: 0.8614 - val_loss: 0.3699 - val_accuracy: 0.8789 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3948 - accuracy: 0.8590 - val_loss: 0.3505 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3917 - accuracy: 0.8660 - val_loss: 0.3504 - val_accuracy: 0.8809 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3826 - accuracy: 0.8655 - val_loss: 0.3725 - val_accuracy: 0.8781 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3872 - accuracy: 0.8696 - val_loss: 0.3446 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3831 - accuracy: 0.8670 - val_loss: 0.3405 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3791 - accuracy: 0.8672 - val_loss: 0.3802 - val_accuracy: 0.8781 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3856 - accuracy: 0.8649 - val_loss: 0.3567 - val_accuracy: 0.8797 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3726 - accuracy: 0.8696 - val_loss: 0.3460 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3674 - accuracy: 0.8736 - val_loss: 0.3536 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3690 - accuracy: 0.8735 - val_loss: 0.3351 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3714 - accuracy: 0.8721 - val_loss: 0.4031 - val_accuracy: 0.8702 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3726 - accuracy: 0.8715 - val_loss: 0.3428 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3598 - accuracy: 0.8740 - val_loss: 0.3410 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3743 - accuracy: 0.8680 - val_loss: 0.3282 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3626 - accuracy: 0.8733 - val_loss: 0.3385 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3699 - accuracy: 0.8671 - val_loss: 0.3496 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3589 - accuracy: 0.8749 - val_loss: 0.3424 - val_accuracy: 0.8837 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3651 - accuracy: 0.8702 - val_loss: 0.3521 - val_accuracy: 0.8813 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3602 - accuracy: 0.8770 - val_loss: 0.3525 - val_accuracy: 0.8827 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3609 - accuracy: 0.8720 - val_loss: 0.3344 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3658 - accuracy: 0.8714 - val_loss: 0.3235 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3633 - accuracy: 0.8737 - val_loss: 0.3355 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3630 - accuracy: 0.8702 - val_loss: 0.3430 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3519 - accuracy: 0.8807 - val_loss: 0.3389 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3594 - accuracy: 0.8737 - val_loss: 0.3425 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3551 - accuracy: 0.8768 - val_loss: 0.3768 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3611 - accuracy: 0.8732 - val_loss: 0.3387 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3546 - accuracy: 0.8743 - val_loss: 0.3277 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3598 - accuracy: 0.8737 - val_loss: 0.3448 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3586 - accuracy: 0.8737 - val_loss: 0.3224 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3611 - accuracy: 0.8747 - val_loss: 0.3351 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3555 - accuracy: 0.8777 - val_loss: 0.3541 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3557 - accuracy: 0.8779 - val_loss: 0.3337 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3527 - accuracy: 0.8772 - val_loss: 0.3411 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3527 - accuracy: 0.8811 - val_loss: 0.3325 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3526 - accuracy: 0.8783 - val_loss: 0.4122 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3579 - accuracy: 0.8738 - val_loss: 0.3450 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3560 - accuracy: 0.8762 - val_loss: 0.3399 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3492 - accuracy: 0.8782 - val_loss: 0.3297 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3553 - accuracy: 0.8792 - val_loss: 0.3363 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3500 - accuracy: 0.8791 - val_loss: 0.3439 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3463 - accuracy: 0.8807 - val_loss: 0.3369 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3434 - accuracy: 0.8805 - val_loss: 0.3364 - val_accuracy: 0.8863 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3395 - accuracy: 0.8819 - val_loss: 0.3279 - val_accuracy: 0.8907 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3393 - accuracy: 0.8851 - val_loss: 0.3274 - val_accuracy: 0.8919 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3414 - accuracy: 0.8826 - val_loss: 0.3225 - val_accuracy: 0.8923 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3370 - accuracy: 0.8838 - val_loss: 0.3215 - val_accuracy: 0.8921 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3339 - accuracy: 0.8852 - val_loss: 0.3199 - val_accuracy: 0.8935 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3351 - accuracy: 0.8838 - val_loss: 0.3199 - val_accuracy: 0.8933 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3309 - accuracy: 0.8830 - val_loss: 0.3169 - val_accuracy: 0.8953 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3366 - accuracy: 0.8812 - val_loss: 0.3143 - val_accuracy: 0.8961 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3297 - accuracy: 0.8839 - val_loss: 0.3194 - val_accuracy: 0.8953 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3244 - accuracy: 0.8885 - val_loss: 0.3148 - val_accuracy: 0.8973 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3323 - accuracy: 0.8856 - val_loss: 0.3147 - val_accuracy: 0.8975 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3316 - accuracy: 0.8814 - val_loss: 0.3145 - val_accuracy: 0.8975 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3267 - accuracy: 0.8883 - val_loss: 0.3136 - val_accuracy: 0.8973 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3353 - accuracy: 0.8850 - val_loss: 0.3141 - val_accuracy: 0.8969 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3304 - accuracy: 0.8861 - val_loss: 0.3139 - val_accuracy: 0.8971 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3285 - accuracy: 0.8867 - val_loss: 0.3143 - val_accuracy: 0.8965 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3293 - accuracy: 0.8822 - val_loss: 0.3141 - val_accuracy: 0.8971 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3242 - accuracy: 0.8847 - val_loss: 0.3145 - val_accuracy: 0.8963 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3233 - accuracy: 0.8861 - val_loss: 0.3131 - val_accuracy: 0.8967 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3249 - accuracy: 0.8839 - val_loss: 0.3132 - val_accuracy: 0.8969 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3256 - accuracy: 0.8862 - val_loss: 0.3131 - val_accuracy: 0.8969 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3282 - accuracy: 0.8852 - val_loss: 0.3129 - val_accuracy: 0.8969 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3225 - accuracy: 0.8849 - val_loss: 0.3132 - val_accuracy: 0.8971 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3249 - accuracy: 0.8878 - val_loss: 0.3134 - val_accuracy: 0.8969 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3232 - accuracy: 0.8885 - val_loss: 0.3135 - val_accuracy: 0.8971 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3254 - accuracy: 0.8849 - val_loss: 0.3137 - val_accuracy: 0.8969 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3248 - accuracy: 0.8882 - val_loss: 0.3135 - val_accuracy: 0.8969 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3287 - accuracy: 0.8849 - val_loss: 0.3137 - val_accuracy: 0.8969 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 9ms/step - loss: 0.2805 - accuracy: 0.9039\n",
      "17/17 [==============================] - 1s 9ms/step\n",
      "TP:5510, TN:9808, FP:647, FN:981, loss0.28051164746284485, acc0.9039301310043668, sn0.8488676629178863, sp0.9381157340985175, f10.8712839974699557, auc0.9614094812955525\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 16s 41ms/step - loss: 1.7391 - accuracy: 0.5664 - val_loss: 1.5083 - val_accuracy: 0.6095 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 1.4339 - accuracy: 0.6173 - val_loss: 1.4270 - val_accuracy: 0.5048 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.2714 - accuracy: 0.6348 - val_loss: 1.2905 - val_accuracy: 0.5201 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 1.1395 - accuracy: 0.6474 - val_loss: 1.1261 - val_accuracy: 0.6195 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 1.0259 - accuracy: 0.6689 - val_loss: 0.9997 - val_accuracy: 0.6815 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.9351 - accuracy: 0.6866 - val_loss: 0.8939 - val_accuracy: 0.7078 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.8571 - accuracy: 0.6951 - val_loss: 0.8044 - val_accuracy: 0.7519 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.7873 - accuracy: 0.7195 - val_loss: 0.7116 - val_accuracy: 0.7930 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.7215 - accuracy: 0.7478 - val_loss: 0.6451 - val_accuracy: 0.8034 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.6844 - accuracy: 0.7541 - val_loss: 0.6159 - val_accuracy: 0.7950 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6312 - accuracy: 0.7769 - val_loss: 0.5911 - val_accuracy: 0.7956 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6011 - accuracy: 0.7817 - val_loss: 0.5496 - val_accuracy: 0.8077 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.5691 - accuracy: 0.7963 - val_loss: 0.5118 - val_accuracy: 0.8315 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.5255 - accuracy: 0.8167 - val_loss: 0.4744 - val_accuracy: 0.8456 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4961 - accuracy: 0.8299 - val_loss: 0.4985 - val_accuracy: 0.8416 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4779 - accuracy: 0.8366 - val_loss: 0.4521 - val_accuracy: 0.8572 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4634 - accuracy: 0.8410 - val_loss: 0.4353 - val_accuracy: 0.8574 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4363 - accuracy: 0.8537 - val_loss: 0.4014 - val_accuracy: 0.8751 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4327 - accuracy: 0.8525 - val_loss: 0.4074 - val_accuracy: 0.8688 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4235 - accuracy: 0.8531 - val_loss: 0.3802 - val_accuracy: 0.8791 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4187 - accuracy: 0.8600 - val_loss: 0.3969 - val_accuracy: 0.8710 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4151 - accuracy: 0.8579 - val_loss: 0.3748 - val_accuracy: 0.8769 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4015 - accuracy: 0.8633 - val_loss: 0.3630 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3984 - accuracy: 0.8660 - val_loss: 0.3645 - val_accuracy: 0.8793 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3908 - accuracy: 0.8650 - val_loss: 0.3721 - val_accuracy: 0.8785 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3939 - accuracy: 0.8669 - val_loss: 0.3742 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3909 - accuracy: 0.8618 - val_loss: 0.3838 - val_accuracy: 0.8751 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3906 - accuracy: 0.8643 - val_loss: 0.3743 - val_accuracy: 0.8748 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3852 - accuracy: 0.8700 - val_loss: 0.3596 - val_accuracy: 0.8815 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3847 - accuracy: 0.8673 - val_loss: 0.3512 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3720 - accuracy: 0.8720 - val_loss: 0.3459 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3740 - accuracy: 0.8751 - val_loss: 0.3308 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3766 - accuracy: 0.8673 - val_loss: 0.3383 - val_accuracy: 0.8821 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3764 - accuracy: 0.8692 - val_loss: 0.3307 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3696 - accuracy: 0.8748 - val_loss: 0.3353 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3651 - accuracy: 0.8747 - val_loss: 0.3267 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3671 - accuracy: 0.8732 - val_loss: 0.3356 - val_accuracy: 0.8837 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3626 - accuracy: 0.8767 - val_loss: 0.3252 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3619 - accuracy: 0.8753 - val_loss: 0.3393 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3620 - accuracy: 0.8745 - val_loss: 0.3340 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3705 - accuracy: 0.8700 - val_loss: 0.3308 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3623 - accuracy: 0.8768 - val_loss: 0.3283 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3663 - accuracy: 0.8712 - val_loss: 0.3544 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3641 - accuracy: 0.8764 - val_loss: 0.3235 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3612 - accuracy: 0.8767 - val_loss: 0.3197 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3660 - accuracy: 0.8716 - val_loss: 0.3512 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3624 - accuracy: 0.8725 - val_loss: 0.3602 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3671 - accuracy: 0.8737 - val_loss: 0.3318 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3633 - accuracy: 0.8761 - val_loss: 0.3365 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3619 - accuracy: 0.8738 - val_loss: 0.3273 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3591 - accuracy: 0.8761 - val_loss: 0.3211 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3532 - accuracy: 0.8790 - val_loss: 0.3271 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3546 - accuracy: 0.8765 - val_loss: 0.3153 - val_accuracy: 0.8957 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3568 - accuracy: 0.8775 - val_loss: 0.3390 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3577 - accuracy: 0.8789 - val_loss: 0.3206 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3599 - accuracy: 0.8782 - val_loss: 0.3323 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3555 - accuracy: 0.8759 - val_loss: 0.3220 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3544 - accuracy: 0.8768 - val_loss: 0.3284 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3564 - accuracy: 0.8794 - val_loss: 0.3254 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3584 - accuracy: 0.8779 - val_loss: 0.3178 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3507 - accuracy: 0.8786 - val_loss: 0.3242 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3572 - accuracy: 0.8755 - val_loss: 0.3351 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3481 - accuracy: 0.8800 - val_loss: 0.3155 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3505 - accuracy: 0.8807 - val_loss: 0.3168 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3582 - accuracy: 0.8776 - val_loss: 0.3447 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3581 - accuracy: 0.8769 - val_loss: 0.3415 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3557 - accuracy: 0.8761 - val_loss: 0.3528 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3498 - accuracy: 0.8820 - val_loss: 0.3381 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3524 - accuracy: 0.8795 - val_loss: 0.3597 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3497 - accuracy: 0.8797 - val_loss: 0.3295 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3527 - accuracy: 0.8762 - val_loss: 0.3326 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3468 - accuracy: 0.8798 - val_loss: 0.3223 - val_accuracy: 0.8897 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3371 - accuracy: 0.8792 - val_loss: 0.3170 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3418 - accuracy: 0.8826 - val_loss: 0.3171 - val_accuracy: 0.8931 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3357 - accuracy: 0.8855 - val_loss: 0.3149 - val_accuracy: 0.8959 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3341 - accuracy: 0.8841 - val_loss: 0.3114 - val_accuracy: 0.8955 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3260 - accuracy: 0.8863 - val_loss: 0.3131 - val_accuracy: 0.8941 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3274 - accuracy: 0.8887 - val_loss: 0.3130 - val_accuracy: 0.8953 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3319 - accuracy: 0.8823 - val_loss: 0.3135 - val_accuracy: 0.8945 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3304 - accuracy: 0.8826 - val_loss: 0.3086 - val_accuracy: 0.8963 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3272 - accuracy: 0.8861 - val_loss: 0.3082 - val_accuracy: 0.8959 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3276 - accuracy: 0.8872 - val_loss: 0.3090 - val_accuracy: 0.8967 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3253 - accuracy: 0.8863 - val_loss: 0.3092 - val_accuracy: 0.8967 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3291 - accuracy: 0.8835 - val_loss: 0.3094 - val_accuracy: 0.8969 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3246 - accuracy: 0.8886 - val_loss: 0.3092 - val_accuracy: 0.8959 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3266 - accuracy: 0.8850 - val_loss: 0.3093 - val_accuracy: 0.8965 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3261 - accuracy: 0.8880 - val_loss: 0.3095 - val_accuracy: 0.8961 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3236 - accuracy: 0.8875 - val_loss: 0.3091 - val_accuracy: 0.8951 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3233 - accuracy: 0.8856 - val_loss: 0.3089 - val_accuracy: 0.8963 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3306 - accuracy: 0.8855 - val_loss: 0.3085 - val_accuracy: 0.8955 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3231 - accuracy: 0.8856 - val_loss: 0.3090 - val_accuracy: 0.8961 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3244 - accuracy: 0.8861 - val_loss: 0.3089 - val_accuracy: 0.8955 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3286 - accuracy: 0.8826 - val_loss: 0.3090 - val_accuracy: 0.8953 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3235 - accuracy: 0.8861 - val_loss: 0.3090 - val_accuracy: 0.8955 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3238 - accuracy: 0.8867 - val_loss: 0.3090 - val_accuracy: 0.8953 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3325 - accuracy: 0.8835 - val_loss: 0.3087 - val_accuracy: 0.8953 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3258 - accuracy: 0.8856 - val_loss: 0.3089 - val_accuracy: 0.8955 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3233 - accuracy: 0.8838 - val_loss: 0.3089 - val_accuracy: 0.8953 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3283 - accuracy: 0.8853 - val_loss: 0.3089 - val_accuracy: 0.8953 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3223 - accuracy: 0.8880 - val_loss: 0.3086 - val_accuracy: 0.8953 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 9ms/step - loss: 0.2800 - accuracy: 0.9036\n",
      "17/17 [==============================] - 1s 8ms/step\n",
      "TP:5589, TN:9723, FP:732, FN:902, loss0.27995163202285767, acc0.9035760651481175, sn0.8610383608072716, sp0.9299856527977044, f10.8724633156415861, auc0.9623045292230769\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 17s 41ms/step - loss: 1.7776 - accuracy: 0.5591 - val_loss: 1.5599 - val_accuracy: 0.5481 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 1.4684 - accuracy: 0.5977 - val_loss: 1.5058 - val_accuracy: 0.3927 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.2983 - accuracy: 0.6225 - val_loss: 1.3291 - val_accuracy: 0.4553 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.1663 - accuracy: 0.6321 - val_loss: 1.1506 - val_accuracy: 0.6075 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 1.0519 - accuracy: 0.6583 - val_loss: 1.0132 - val_accuracy: 0.6889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.9584 - accuracy: 0.6721 - val_loss: 0.8853 - val_accuracy: 0.7583 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.8653 - accuracy: 0.7069 - val_loss: 0.7573 - val_accuracy: 0.7958 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.7802 - accuracy: 0.7384 - val_loss: 0.7082 - val_accuracy: 0.7720 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.7140 - accuracy: 0.7566 - val_loss: 0.6354 - val_accuracy: 0.7980 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.6551 - accuracy: 0.7767 - val_loss: 0.6064 - val_accuracy: 0.7952 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.6097 - accuracy: 0.7940 - val_loss: 0.5678 - val_accuracy: 0.8253 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.5744 - accuracy: 0.8055 - val_loss: 0.5345 - val_accuracy: 0.8305 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.5330 - accuracy: 0.8221 - val_loss: 0.5194 - val_accuracy: 0.8385 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.5142 - accuracy: 0.8269 - val_loss: 0.4745 - val_accuracy: 0.8496 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4885 - accuracy: 0.8362 - val_loss: 0.4682 - val_accuracy: 0.8492 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4663 - accuracy: 0.8441 - val_loss: 0.4535 - val_accuracy: 0.8538 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4605 - accuracy: 0.8440 - val_loss: 0.4326 - val_accuracy: 0.8628 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4479 - accuracy: 0.8472 - val_loss: 0.4220 - val_accuracy: 0.8678 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4417 - accuracy: 0.8485 - val_loss: 0.4023 - val_accuracy: 0.8696 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4299 - accuracy: 0.8531 - val_loss: 0.4112 - val_accuracy: 0.8658 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4246 - accuracy: 0.8594 - val_loss: 0.3864 - val_accuracy: 0.8726 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4165 - accuracy: 0.8591 - val_loss: 0.3840 - val_accuracy: 0.8757 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4063 - accuracy: 0.8617 - val_loss: 0.3759 - val_accuracy: 0.8742 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3995 - accuracy: 0.8620 - val_loss: 0.3785 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3976 - accuracy: 0.8614 - val_loss: 0.3890 - val_accuracy: 0.8708 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3890 - accuracy: 0.8673 - val_loss: 0.3662 - val_accuracy: 0.8769 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3966 - accuracy: 0.8598 - val_loss: 0.3784 - val_accuracy: 0.8757 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3903 - accuracy: 0.8670 - val_loss: 0.3622 - val_accuracy: 0.8815 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3812 - accuracy: 0.8708 - val_loss: 0.3629 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3858 - accuracy: 0.8672 - val_loss: 0.3613 - val_accuracy: 0.8805 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3765 - accuracy: 0.8706 - val_loss: 0.3421 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3850 - accuracy: 0.8652 - val_loss: 0.3392 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3758 - accuracy: 0.8716 - val_loss: 0.3421 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3772 - accuracy: 0.8690 - val_loss: 0.3447 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3742 - accuracy: 0.8687 - val_loss: 0.3600 - val_accuracy: 0.8746 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3748 - accuracy: 0.8740 - val_loss: 0.3569 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3685 - accuracy: 0.8735 - val_loss: 0.3557 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3655 - accuracy: 0.8755 - val_loss: 0.3484 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3644 - accuracy: 0.8747 - val_loss: 0.3412 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3785 - accuracy: 0.8710 - val_loss: 0.3490 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3737 - accuracy: 0.8685 - val_loss: 0.3448 - val_accuracy: 0.8831 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3731 - accuracy: 0.8711 - val_loss: 0.3417 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3712 - accuracy: 0.8705 - val_loss: 0.3435 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3733 - accuracy: 0.8726 - val_loss: 0.3337 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3665 - accuracy: 0.8747 - val_loss: 0.3394 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3613 - accuracy: 0.8745 - val_loss: 0.3438 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3688 - accuracy: 0.8736 - val_loss: 0.3446 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3648 - accuracy: 0.8722 - val_loss: 0.3518 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3581 - accuracy: 0.8784 - val_loss: 0.3450 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3607 - accuracy: 0.8748 - val_loss: 0.3417 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3650 - accuracy: 0.8735 - val_loss: 0.3292 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3610 - accuracy: 0.8763 - val_loss: 0.3538 - val_accuracy: 0.8827 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3577 - accuracy: 0.8784 - val_loss: 0.3370 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3588 - accuracy: 0.8758 - val_loss: 0.3335 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3551 - accuracy: 0.8785 - val_loss: 0.3541 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3568 - accuracy: 0.8755 - val_loss: 0.3410 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3603 - accuracy: 0.8756 - val_loss: 0.3400 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3558 - accuracy: 0.8735 - val_loss: 0.3628 - val_accuracy: 0.8797 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3593 - accuracy: 0.8780 - val_loss: 0.3335 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3560 - accuracy: 0.8783 - val_loss: 0.3372 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3576 - accuracy: 0.8757 - val_loss: 0.3284 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3605 - accuracy: 0.8703 - val_loss: 0.3237 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3574 - accuracy: 0.8765 - val_loss: 0.3509 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3551 - accuracy: 0.8777 - val_loss: 0.3401 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3553 - accuracy: 0.8774 - val_loss: 0.3459 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3607 - accuracy: 0.8745 - val_loss: 0.3450 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3583 - accuracy: 0.8751 - val_loss: 0.3219 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3519 - accuracy: 0.8808 - val_loss: 0.3326 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 0.3534 - accuracy: 0.8771 - val_loss: 0.3311 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3580 - accuracy: 0.8749 - val_loss: 0.3337 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3550 - accuracy: 0.8762 - val_loss: 0.3288 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3466 - accuracy: 0.8773 - val_loss: 0.3208 - val_accuracy: 0.8951 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3399 - accuracy: 0.8804 - val_loss: 0.3177 - val_accuracy: 0.8937 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3361 - accuracy: 0.8842 - val_loss: 0.3195 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3317 - accuracy: 0.8855 - val_loss: 0.3199 - val_accuracy: 0.8925 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3372 - accuracy: 0.8849 - val_loss: 0.3213 - val_accuracy: 0.8925 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3342 - accuracy: 0.8842 - val_loss: 0.3169 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3312 - accuracy: 0.8875 - val_loss: 0.3170 - val_accuracy: 0.8915 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3295 - accuracy: 0.8859 - val_loss: 0.3147 - val_accuracy: 0.8943 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3259 - accuracy: 0.8827 - val_loss: 0.3131 - val_accuracy: 0.8931 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3321 - accuracy: 0.8819 - val_loss: 0.3178 - val_accuracy: 0.8913 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3264 - accuracy: 0.8850 - val_loss: 0.3139 - val_accuracy: 0.8935 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3280 - accuracy: 0.8828 - val_loss: 0.3130 - val_accuracy: 0.8935 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3253 - accuracy: 0.8856 - val_loss: 0.3129 - val_accuracy: 0.8943 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3318 - accuracy: 0.8848 - val_loss: 0.3124 - val_accuracy: 0.8945 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3311 - accuracy: 0.8832 - val_loss: 0.3122 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3265 - accuracy: 0.8848 - val_loss: 0.3115 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3348 - accuracy: 0.8820 - val_loss: 0.3114 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3284 - accuracy: 0.8858 - val_loss: 0.3118 - val_accuracy: 0.8941 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3297 - accuracy: 0.8848 - val_loss: 0.3115 - val_accuracy: 0.8943 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3299 - accuracy: 0.8839 - val_loss: 0.3112 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3237 - accuracy: 0.8839 - val_loss: 0.3114 - val_accuracy: 0.8943 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3290 - accuracy: 0.8832 - val_loss: 0.3114 - val_accuracy: 0.8947 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3237 - accuracy: 0.8873 - val_loss: 0.3115 - val_accuracy: 0.8953 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3284 - accuracy: 0.8838 - val_loss: 0.3114 - val_accuracy: 0.8953 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3257 - accuracy: 0.8883 - val_loss: 0.3115 - val_accuracy: 0.8939 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3315 - accuracy: 0.8843 - val_loss: 0.3114 - val_accuracy: 0.8939 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3248 - accuracy: 0.8883 - val_loss: 0.3115 - val_accuracy: 0.8939 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3262 - accuracy: 0.8856 - val_loss: 0.3114 - val_accuracy: 0.8949 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3277 - accuracy: 0.8855 - val_loss: 0.3113 - val_accuracy: 0.8943 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 9ms/step - loss: 0.2812 - accuracy: 0.9034\n",
      "17/17 [==============================] - 1s 8ms/step\n",
      "TP:5559, TN:9750, FP:705, FN:932, loss0.28117966651916504, acc0.903399032219993, sn0.8564165767986442, sp0.9325681492109039, f10.8716581732653861, auc0.9612247793932531\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 16s 41ms/step - loss: 1.7613 - accuracy: 0.5559 - val_loss: 1.5381 - val_accuracy: 0.5692 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 1.4649 - accuracy: 0.6090 - val_loss: 1.4768 - val_accuracy: 0.4767 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.2973 - accuracy: 0.6248 - val_loss: 1.3874 - val_accuracy: 0.4132 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.1586 - accuracy: 0.6383 - val_loss: 1.1924 - val_accuracy: 0.5024 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.0388 - accuracy: 0.6610 - val_loss: 1.0851 - val_accuracy: 0.5355 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.9510 - accuracy: 0.6790 - val_loss: 1.0068 - val_accuracy: 0.5477 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.8809 - accuracy: 0.6858 - val_loss: 0.9683 - val_accuracy: 0.5636 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.8161 - accuracy: 0.6985 - val_loss: 1.0705 - val_accuracy: 0.5154 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.7680 - accuracy: 0.7123 - val_loss: 0.8851 - val_accuracy: 0.5562 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.7199 - accuracy: 0.7243 - val_loss: 0.8947 - val_accuracy: 0.5259 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.6835 - accuracy: 0.7367 - val_loss: 0.7769 - val_accuracy: 0.6354 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6433 - accuracy: 0.7545 - val_loss: 0.7225 - val_accuracy: 0.6713 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.6134 - accuracy: 0.7702 - val_loss: 0.6072 - val_accuracy: 0.7625 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.5876 - accuracy: 0.7786 - val_loss: 0.5577 - val_accuracy: 0.7930 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.5672 - accuracy: 0.7790 - val_loss: 0.5801 - val_accuracy: 0.7802 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.5440 - accuracy: 0.7960 - val_loss: 0.5287 - val_accuracy: 0.8022 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.5274 - accuracy: 0.8009 - val_loss: 0.5361 - val_accuracy: 0.8018 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4980 - accuracy: 0.8181 - val_loss: 0.4521 - val_accuracy: 0.8438 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.4796 - accuracy: 0.8273 - val_loss: 0.4465 - val_accuracy: 0.8408 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4613 - accuracy: 0.8352 - val_loss: 0.4092 - val_accuracy: 0.8620 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4479 - accuracy: 0.8429 - val_loss: 0.4064 - val_accuracy: 0.8676 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4396 - accuracy: 0.8427 - val_loss: 0.3955 - val_accuracy: 0.8732 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4225 - accuracy: 0.8532 - val_loss: 0.4113 - val_accuracy: 0.8622 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.4198 - accuracy: 0.8517 - val_loss: 0.4338 - val_accuracy: 0.8612 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4148 - accuracy: 0.8584 - val_loss: 0.3924 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.4096 - accuracy: 0.8572 - val_loss: 0.3739 - val_accuracy: 0.8831 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.4028 - accuracy: 0.8601 - val_loss: 0.3545 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3956 - accuracy: 0.8645 - val_loss: 0.3581 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3949 - accuracy: 0.8651 - val_loss: 0.3637 - val_accuracy: 0.8803 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3869 - accuracy: 0.8670 - val_loss: 0.3572 - val_accuracy: 0.8821 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3850 - accuracy: 0.8666 - val_loss: 0.3454 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3818 - accuracy: 0.8720 - val_loss: 0.3483 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3794 - accuracy: 0.8688 - val_loss: 0.3510 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3799 - accuracy: 0.8665 - val_loss: 0.3697 - val_accuracy: 0.8809 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3802 - accuracy: 0.8667 - val_loss: 0.3536 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3730 - accuracy: 0.8693 - val_loss: 0.3477 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3712 - accuracy: 0.8745 - val_loss: 0.3504 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3719 - accuracy: 0.8714 - val_loss: 0.3596 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3615 - accuracy: 0.8720 - val_loss: 0.3440 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3711 - accuracy: 0.8695 - val_loss: 0.3607 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3681 - accuracy: 0.8737 - val_loss: 0.3358 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3618 - accuracy: 0.8790 - val_loss: 0.3506 - val_accuracy: 0.8813 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3709 - accuracy: 0.8682 - val_loss: 0.3358 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3693 - accuracy: 0.8686 - val_loss: 0.3424 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3694 - accuracy: 0.8745 - val_loss: 0.3455 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3663 - accuracy: 0.8707 - val_loss: 0.3241 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3571 - accuracy: 0.8753 - val_loss: 0.3260 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3597 - accuracy: 0.8784 - val_loss: 0.3321 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3586 - accuracy: 0.8814 - val_loss: 0.3300 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3562 - accuracy: 0.8776 - val_loss: 0.3306 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3585 - accuracy: 0.8764 - val_loss: 0.3383 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3577 - accuracy: 0.8754 - val_loss: 0.3572 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3564 - accuracy: 0.8766 - val_loss: 0.3398 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3538 - accuracy: 0.8762 - val_loss: 0.3351 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3641 - accuracy: 0.8725 - val_loss: 0.3381 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3560 - accuracy: 0.8800 - val_loss: 0.3753 - val_accuracy: 0.8730 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3520 - accuracy: 0.8767 - val_loss: 0.3339 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3599 - accuracy: 0.8769 - val_loss: 0.3248 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3566 - accuracy: 0.8770 - val_loss: 0.3414 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3562 - accuracy: 0.8791 - val_loss: 0.3309 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3509 - accuracy: 0.8804 - val_loss: 0.3313 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3474 - accuracy: 0.8794 - val_loss: 0.3446 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3492 - accuracy: 0.8769 - val_loss: 0.3242 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3508 - accuracy: 0.8787 - val_loss: 0.3485 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3528 - accuracy: 0.8788 - val_loss: 0.3251 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3508 - accuracy: 0.8789 - val_loss: 0.3366 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3562 - accuracy: 0.8764 - val_loss: 0.3240 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3473 - accuracy: 0.8803 - val_loss: 0.3433 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3481 - accuracy: 0.8817 - val_loss: 0.3229 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3538 - accuracy: 0.8795 - val_loss: 0.3536 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3490 - accuracy: 0.8796 - val_loss: 0.3157 - val_accuracy: 0.8955 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3445 - accuracy: 0.8814 - val_loss: 0.3267 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3409 - accuracy: 0.8825 - val_loss: 0.3220 - val_accuracy: 0.8925 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3335 - accuracy: 0.8854 - val_loss: 0.3230 - val_accuracy: 0.8943 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3328 - accuracy: 0.8835 - val_loss: 0.3209 - val_accuracy: 0.8919 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3370 - accuracy: 0.8837 - val_loss: 0.3169 - val_accuracy: 0.8933 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3321 - accuracy: 0.8838 - val_loss: 0.3200 - val_accuracy: 0.8919 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3297 - accuracy: 0.8846 - val_loss: 0.3159 - val_accuracy: 0.8937 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3233 - accuracy: 0.8898 - val_loss: 0.3164 - val_accuracy: 0.8925 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3278 - accuracy: 0.8867 - val_loss: 0.3135 - val_accuracy: 0.8951 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3250 - accuracy: 0.8873 - val_loss: 0.3218 - val_accuracy: 0.8947 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3285 - accuracy: 0.8877 - val_loss: 0.3162 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3202 - accuracy: 0.8866 - val_loss: 0.3161 - val_accuracy: 0.8941 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3287 - accuracy: 0.8853 - val_loss: 0.3159 - val_accuracy: 0.8951 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3262 - accuracy: 0.8833 - val_loss: 0.3152 - val_accuracy: 0.8943 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3286 - accuracy: 0.8868 - val_loss: 0.3147 - val_accuracy: 0.8951 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3178 - accuracy: 0.8882 - val_loss: 0.3152 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3197 - accuracy: 0.8877 - val_loss: 0.3148 - val_accuracy: 0.8949 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3204 - accuracy: 0.8881 - val_loss: 0.3146 - val_accuracy: 0.8949 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3219 - accuracy: 0.8885 - val_loss: 0.3143 - val_accuracy: 0.8953 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3271 - accuracy: 0.8859 - val_loss: 0.3139 - val_accuracy: 0.8951 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3230 - accuracy: 0.8892 - val_loss: 0.3142 - val_accuracy: 0.8953 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3199 - accuracy: 0.8897 - val_loss: 0.3142 - val_accuracy: 0.8957 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3249 - accuracy: 0.8893 - val_loss: 0.3142 - val_accuracy: 0.8953 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3222 - accuracy: 0.8866 - val_loss: 0.3141 - val_accuracy: 0.8955 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3257 - accuracy: 0.8834 - val_loss: 0.3142 - val_accuracy: 0.8955 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3189 - accuracy: 0.8894 - val_loss: 0.3143 - val_accuracy: 0.8955 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3223 - accuracy: 0.8868 - val_loss: 0.3142 - val_accuracy: 0.8959 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3225 - accuracy: 0.8872 - val_loss: 0.3139 - val_accuracy: 0.8957 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3254 - accuracy: 0.8850 - val_loss: 0.3141 - val_accuracy: 0.8955 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 9ms/step - loss: 0.2861 - accuracy: 0.9026\n",
      "17/17 [==============================] - 1s 8ms/step\n",
      "TP:5541, TN:9754, FP:701, FN:950, loss0.2861282527446747, acc0.9025728785554114, sn0.8536435063934679, sp0.9329507412721186, f10.8703369198146549, auc0.9603695983129642\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 18s 41ms/step - loss: 1.6657 - accuracy: 0.5855 - val_loss: 1.6035 - val_accuracy: 0.3849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 1.3809 - accuracy: 0.6243 - val_loss: 1.4197 - val_accuracy: 0.4232 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.2131 - accuracy: 0.6454 - val_loss: 1.3106 - val_accuracy: 0.4049 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.0830 - accuracy: 0.6577 - val_loss: 1.2617 - val_accuracy: 0.4288 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.9765 - accuracy: 0.6781 - val_loss: 1.2269 - val_accuracy: 0.4352 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.8939 - accuracy: 0.6801 - val_loss: 1.1917 - val_accuracy: 0.4184 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.8310 - accuracy: 0.6910 - val_loss: 1.2352 - val_accuracy: 0.4300 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.7821 - accuracy: 0.6977 - val_loss: 1.2599 - val_accuracy: 0.3863 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.7387 - accuracy: 0.7002 - val_loss: 1.2510 - val_accuracy: 0.4095 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.7051 - accuracy: 0.7103 - val_loss: 1.2613 - val_accuracy: 0.3899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.6770 - accuracy: 0.7199 - val_loss: 1.2150 - val_accuracy: 0.4400 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.6523 - accuracy: 0.7325 - val_loss: 1.1607 - val_accuracy: 0.4011 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.6289 - accuracy: 0.7396 - val_loss: 0.9001 - val_accuracy: 0.5297 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.6050 - accuracy: 0.7463 - val_loss: 0.7038 - val_accuracy: 0.6697 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.5885 - accuracy: 0.7593 - val_loss: 0.6226 - val_accuracy: 0.7286 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.5714 - accuracy: 0.7676 - val_loss: 0.5840 - val_accuracy: 0.7425 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.5546 - accuracy: 0.7737 - val_loss: 0.5875 - val_accuracy: 0.7469 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.5374 - accuracy: 0.7796 - val_loss: 0.4943 - val_accuracy: 0.8041 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.5267 - accuracy: 0.7911 - val_loss: 0.4827 - val_accuracy: 0.8091 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.5080 - accuracy: 0.8012 - val_loss: 0.4853 - val_accuracy: 0.8061 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4928 - accuracy: 0.8066 - val_loss: 0.4614 - val_accuracy: 0.8331 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4790 - accuracy: 0.8168 - val_loss: 0.4583 - val_accuracy: 0.8321 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4675 - accuracy: 0.8244 - val_loss: 0.4307 - val_accuracy: 0.8412 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4559 - accuracy: 0.8310 - val_loss: 0.4210 - val_accuracy: 0.8552 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.4475 - accuracy: 0.8364 - val_loss: 0.4260 - val_accuracy: 0.8620 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4450 - accuracy: 0.8344 - val_loss: 0.3866 - val_accuracy: 0.8628 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.4312 - accuracy: 0.8433 - val_loss: 0.3870 - val_accuracy: 0.8674 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.4193 - accuracy: 0.8499 - val_loss: 0.4017 - val_accuracy: 0.8664 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.4175 - accuracy: 0.8496 - val_loss: 0.3623 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4112 - accuracy: 0.8527 - val_loss: 0.3727 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4043 - accuracy: 0.8571 - val_loss: 0.3920 - val_accuracy: 0.8704 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3943 - accuracy: 0.8624 - val_loss: 0.3715 - val_accuracy: 0.8795 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.4024 - accuracy: 0.8623 - val_loss: 0.3535 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3909 - accuracy: 0.8635 - val_loss: 0.3488 - val_accuracy: 0.8837 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3880 - accuracy: 0.8679 - val_loss: 0.3545 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3854 - accuracy: 0.8632 - val_loss: 0.3753 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3859 - accuracy: 0.8648 - val_loss: 0.3551 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3833 - accuracy: 0.8688 - val_loss: 0.3594 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3783 - accuracy: 0.8664 - val_loss: 0.3676 - val_accuracy: 0.8815 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3802 - accuracy: 0.8715 - val_loss: 0.3608 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3814 - accuracy: 0.8683 - val_loss: 0.3495 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3755 - accuracy: 0.8679 - val_loss: 0.3649 - val_accuracy: 0.8805 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3793 - accuracy: 0.8684 - val_loss: 0.3567 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3701 - accuracy: 0.8749 - val_loss: 0.3476 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3696 - accuracy: 0.8704 - val_loss: 0.3408 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3715 - accuracy: 0.8717 - val_loss: 0.3404 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3710 - accuracy: 0.8741 - val_loss: 0.3274 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3704 - accuracy: 0.8724 - val_loss: 0.3557 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3664 - accuracy: 0.8726 - val_loss: 0.3311 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3693 - accuracy: 0.8730 - val_loss: 0.3575 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3684 - accuracy: 0.8743 - val_loss: 0.3500 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3637 - accuracy: 0.8738 - val_loss: 0.3379 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3629 - accuracy: 0.8750 - val_loss: 0.3547 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3702 - accuracy: 0.8751 - val_loss: 0.3384 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3781 - accuracy: 0.8650 - val_loss: 0.3423 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3598 - accuracy: 0.8770 - val_loss: 0.3610 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3652 - accuracy: 0.8735 - val_loss: 0.3384 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3617 - accuracy: 0.8743 - val_loss: 0.3353 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3579 - accuracy: 0.8787 - val_loss: 0.3413 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3612 - accuracy: 0.8762 - val_loss: 0.3394 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3611 - accuracy: 0.8771 - val_loss: 0.3669 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3645 - accuracy: 0.8743 - val_loss: 0.3340 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3610 - accuracy: 0.8733 - val_loss: 0.3476 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3593 - accuracy: 0.8781 - val_loss: 0.3243 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3613 - accuracy: 0.8763 - val_loss: 0.3504 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3531 - accuracy: 0.8779 - val_loss: 0.3362 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3671 - accuracy: 0.8714 - val_loss: 0.3380 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3606 - accuracy: 0.8759 - val_loss: 0.3469 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3639 - accuracy: 0.8719 - val_loss: 0.3373 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3588 - accuracy: 0.8782 - val_loss: 0.3543 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3569 - accuracy: 0.8744 - val_loss: 0.3394 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3483 - accuracy: 0.8786 - val_loss: 0.3343 - val_accuracy: 0.8891 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3436 - accuracy: 0.8820 - val_loss: 0.3308 - val_accuracy: 0.8909 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 4s 40ms/step - loss: 0.3412 - accuracy: 0.8806 - val_loss: 0.3306 - val_accuracy: 0.8907 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3435 - accuracy: 0.8803 - val_loss: 0.3322 - val_accuracy: 0.8911 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3358 - accuracy: 0.8798 - val_loss: 0.3243 - val_accuracy: 0.8921 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3340 - accuracy: 0.8841 - val_loss: 0.3226 - val_accuracy: 0.8939 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3366 - accuracy: 0.8823 - val_loss: 0.3276 - val_accuracy: 0.8917 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3340 - accuracy: 0.8837 - val_loss: 0.3204 - val_accuracy: 0.8951 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.3329 - accuracy: 0.8861 - val_loss: 0.3172 - val_accuracy: 0.8943 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3298 - accuracy: 0.8861 - val_loss: 0.3196 - val_accuracy: 0.8953 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3250 - accuracy: 0.8881 - val_loss: 0.3192 - val_accuracy: 0.8955 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3279 - accuracy: 0.8869 - val_loss: 0.3188 - val_accuracy: 0.8945 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3317 - accuracy: 0.8838 - val_loss: 0.3189 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3330 - accuracy: 0.8823 - val_loss: 0.3178 - val_accuracy: 0.8949 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3252 - accuracy: 0.8873 - val_loss: 0.3186 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3342 - accuracy: 0.8821 - val_loss: 0.3183 - val_accuracy: 0.8941 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3322 - accuracy: 0.8830 - val_loss: 0.3181 - val_accuracy: 0.8945 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3331 - accuracy: 0.8836 - val_loss: 0.3174 - val_accuracy: 0.8949 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3295 - accuracy: 0.8813 - val_loss: 0.3174 - val_accuracy: 0.8949 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3304 - accuracy: 0.8879 - val_loss: 0.3175 - val_accuracy: 0.8949 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3267 - accuracy: 0.8861 - val_loss: 0.3176 - val_accuracy: 0.8951 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3292 - accuracy: 0.8871 - val_loss: 0.3178 - val_accuracy: 0.8949 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3315 - accuracy: 0.8830 - val_loss: 0.3177 - val_accuracy: 0.8947 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3302 - accuracy: 0.8866 - val_loss: 0.3177 - val_accuracy: 0.8947 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3281 - accuracy: 0.8861 - val_loss: 0.3178 - val_accuracy: 0.8947 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3320 - accuracy: 0.8813 - val_loss: 0.3176 - val_accuracy: 0.8951 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3271 - accuracy: 0.8871 - val_loss: 0.3177 - val_accuracy: 0.8949 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3286 - accuracy: 0.8854 - val_loss: 0.3177 - val_accuracy: 0.8947 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3316 - accuracy: 0.8855 - val_loss: 0.3178 - val_accuracy: 0.8949 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 9ms/step - loss: 0.2851 - accuracy: 0.9033\n",
      "17/17 [==============================] - 1s 9ms/step\n",
      "TP:5496, TN:9812, FP:643, FN:995, loss0.285076379776001, acc0.9033400212439514, sn0.8467108303805269, sp0.9384983261597322, f10.8703087885985749, auc0.9606616334679936\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 16s 42ms/step - loss: 1.7459 - accuracy: 0.5697 - val_loss: 1.5385 - val_accuracy: 0.6123 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.4600 - accuracy: 0.6030 - val_loss: 1.4383 - val_accuracy: 0.5535 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 1.2887 - accuracy: 0.6288 - val_loss: 1.2928 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 1.1539 - accuracy: 0.6469 - val_loss: 1.1448 - val_accuracy: 0.5913 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 1.0386 - accuracy: 0.6631 - val_loss: 1.0394 - val_accuracy: 0.6115 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.9562 - accuracy: 0.6760 - val_loss: 1.0009 - val_accuracy: 0.6075 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.8845 - accuracy: 0.6848 - val_loss: 0.9801 - val_accuracy: 0.5995 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.8294 - accuracy: 0.6903 - val_loss: 0.9356 - val_accuracy: 0.5846 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.7744 - accuracy: 0.7064 - val_loss: 0.9782 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.7401 - accuracy: 0.7063 - val_loss: 0.9440 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.7025 - accuracy: 0.7199 - val_loss: 0.8523 - val_accuracy: 0.5995 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.6726 - accuracy: 0.7272 - val_loss: 0.7309 - val_accuracy: 0.6368 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.6463 - accuracy: 0.7405 - val_loss: 0.6254 - val_accuracy: 0.7439 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.6058 - accuracy: 0.7600 - val_loss: 0.6096 - val_accuracy: 0.7519 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.5795 - accuracy: 0.7688 - val_loss: 0.5696 - val_accuracy: 0.7686 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.5639 - accuracy: 0.7787 - val_loss: 0.5216 - val_accuracy: 0.8063 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.5453 - accuracy: 0.7895 - val_loss: 0.5188 - val_accuracy: 0.8089 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.5273 - accuracy: 0.8001 - val_loss: 0.4790 - val_accuracy: 0.8203 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.5048 - accuracy: 0.8063 - val_loss: 0.4550 - val_accuracy: 0.8367 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4772 - accuracy: 0.8211 - val_loss: 0.4727 - val_accuracy: 0.8365 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4654 - accuracy: 0.8267 - val_loss: 0.4315 - val_accuracy: 0.8548 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4524 - accuracy: 0.8398 - val_loss: 0.4034 - val_accuracy: 0.8646 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4416 - accuracy: 0.8466 - val_loss: 0.4121 - val_accuracy: 0.8678 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.4248 - accuracy: 0.8482 - val_loss: 0.4263 - val_accuracy: 0.8634 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4182 - accuracy: 0.8520 - val_loss: 0.4094 - val_accuracy: 0.8636 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4084 - accuracy: 0.8590 - val_loss: 0.3844 - val_accuracy: 0.8738 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4059 - accuracy: 0.8604 - val_loss: 0.3726 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.4056 - accuracy: 0.8604 - val_loss: 0.3556 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3924 - accuracy: 0.8620 - val_loss: 0.3702 - val_accuracy: 0.8801 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3899 - accuracy: 0.8665 - val_loss: 0.3522 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3941 - accuracy: 0.8638 - val_loss: 0.3502 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3857 - accuracy: 0.8675 - val_loss: 0.3480 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3828 - accuracy: 0.8657 - val_loss: 0.3485 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3681 - accuracy: 0.8733 - val_loss: 0.3543 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3802 - accuracy: 0.8690 - val_loss: 0.3454 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3730 - accuracy: 0.8701 - val_loss: 0.3577 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3781 - accuracy: 0.8679 - val_loss: 0.3543 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3671 - accuracy: 0.8724 - val_loss: 0.3385 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3702 - accuracy: 0.8733 - val_loss: 0.3275 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3656 - accuracy: 0.8761 - val_loss: 0.3385 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3642 - accuracy: 0.8740 - val_loss: 0.3273 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3659 - accuracy: 0.8712 - val_loss: 0.3472 - val_accuracy: 0.8821 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3664 - accuracy: 0.8749 - val_loss: 0.3477 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3677 - accuracy: 0.8723 - val_loss: 0.3499 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3571 - accuracy: 0.8778 - val_loss: 0.3715 - val_accuracy: 0.8771 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3590 - accuracy: 0.8736 - val_loss: 0.3164 - val_accuracy: 0.8955 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3629 - accuracy: 0.8728 - val_loss: 0.3390 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 3s 35ms/step - loss: 0.3658 - accuracy: 0.8714 - val_loss: 0.3506 - val_accuracy: 0.8831 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3688 - accuracy: 0.8696 - val_loss: 0.3453 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3613 - accuracy: 0.8746 - val_loss: 0.3545 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3635 - accuracy: 0.8723 - val_loss: 0.3267 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3572 - accuracy: 0.8790 - val_loss: 0.3293 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3539 - accuracy: 0.8765 - val_loss: 0.3385 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3664 - accuracy: 0.8732 - val_loss: 0.3427 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3582 - accuracy: 0.8768 - val_loss: 0.3273 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3549 - accuracy: 0.8753 - val_loss: 0.3468 - val_accuracy: 0.8831 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3596 - accuracy: 0.8767 - val_loss: 0.3435 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3556 - accuracy: 0.8758 - val_loss: 0.3327 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3555 - accuracy: 0.8773 - val_loss: 0.3373 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3474 - accuracy: 0.8790 - val_loss: 0.3492 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3596 - accuracy: 0.8723 - val_loss: 0.3321 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3586 - accuracy: 0.8735 - val_loss: 0.3290 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3504 - accuracy: 0.8798 - val_loss: 0.3324 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3536 - accuracy: 0.8758 - val_loss: 0.3321 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3524 - accuracy: 0.8769 - val_loss: 0.3363 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3502 - accuracy: 0.8784 - val_loss: 0.3299 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3531 - accuracy: 0.8779 - val_loss: 0.3307 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3478 - accuracy: 0.8817 - val_loss: 0.3252 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3592 - accuracy: 0.8751 - val_loss: 0.3427 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3495 - accuracy: 0.8814 - val_loss: 0.3294 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3519 - accuracy: 0.8796 - val_loss: 0.3317 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3433 - accuracy: 0.8818 - val_loss: 0.3236 - val_accuracy: 0.8941 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.3369 - accuracy: 0.8841 - val_loss: 0.3222 - val_accuracy: 0.8953 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3397 - accuracy: 0.8816 - val_loss: 0.3191 - val_accuracy: 0.8959 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3337 - accuracy: 0.8855 - val_loss: 0.3212 - val_accuracy: 0.8957 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3330 - accuracy: 0.8837 - val_loss: 0.3179 - val_accuracy: 0.8965 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3308 - accuracy: 0.8857 - val_loss: 0.3163 - val_accuracy: 0.8967 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3335 - accuracy: 0.8830 - val_loss: 0.3138 - val_accuracy: 0.8955 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3324 - accuracy: 0.8825 - val_loss: 0.3123 - val_accuracy: 0.8983 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3269 - accuracy: 0.8869 - val_loss: 0.3130 - val_accuracy: 0.8969 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3306 - accuracy: 0.8832 - val_loss: 0.3142 - val_accuracy: 0.8971 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3240 - accuracy: 0.8873 - val_loss: 0.3143 - val_accuracy: 0.8981 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.3287 - accuracy: 0.8842 - val_loss: 0.3143 - val_accuracy: 0.8971 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3298 - accuracy: 0.8817 - val_loss: 0.3146 - val_accuracy: 0.8981 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3198 - accuracy: 0.8923 - val_loss: 0.3146 - val_accuracy: 0.8975 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3254 - accuracy: 0.8867 - val_loss: 0.3150 - val_accuracy: 0.8985 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 3s 34ms/step - loss: 0.3237 - accuracy: 0.8861 - val_loss: 0.3149 - val_accuracy: 0.8983 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.3233 - accuracy: 0.8855 - val_loss: 0.3144 - val_accuracy: 0.8989 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3206 - accuracy: 0.8869 - val_loss: 0.3145 - val_accuracy: 0.8983 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.3230 - accuracy: 0.8896 - val_loss: 0.3138 - val_accuracy: 0.8989 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3227 - accuracy: 0.8864 - val_loss: 0.3139 - val_accuracy: 0.8993 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3256 - accuracy: 0.8820 - val_loss: 0.3137 - val_accuracy: 0.8995 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3200 - accuracy: 0.8872 - val_loss: 0.3138 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3273 - accuracy: 0.8855 - val_loss: 0.3138 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3181 - accuracy: 0.8894 - val_loss: 0.3139 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.3229 - accuracy: 0.8856 - val_loss: 0.3137 - val_accuracy: 0.8995 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.3245 - accuracy: 0.8879 - val_loss: 0.3137 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3245 - accuracy: 0.8833 - val_loss: 0.3137 - val_accuracy: 0.8991 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.3183 - accuracy: 0.8896 - val_loss: 0.3138 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.3257 - accuracy: 0.8861 - val_loss: 0.3138 - val_accuracy: 0.8993 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 4s 8ms/step - loss: 0.2812 - accuracy: 0.9034\n",
      "17/17 [==============================] - 1s 7ms/step\n",
      "TP:5584, TN:9725, FP:730, FN:907, loss0.2812199294567108, acc0.903399032219993, sn0.8602680634725004, sp0.9301769488283118, f10.8721593127684497, auc0.9615906024756642\n",
      "Average Test loss:  0.282440385222435\n",
      "Average Accuracy:  0.9031570872182225\n",
      "Average Sensitivity:  0.8527653674318287\n",
      "Average Specificity:  0.9344428503108559\n",
      "Average F1 Score:  0.8708946491531803\n",
      "Average AUC Score:  0.9611536939533168\n",
      "AUC for ROC curve 1: 0.9614\n",
      "AUC for ROC curve 2: 0.9614\n",
      "AUC for ROC curve 3: 0.9610\n",
      "AUC for ROC curve 4: 0.9610\n",
      "AUC for ROC curve 5: 0.9609\n",
      "AUC for ROC curve 6: 0.9609\n",
      "AUC for ROC curve 7: 0.9607\n",
      "AUC for ROC curve 8: 0.9607\n",
      "AUC for ROC curve 9: 0.9614\n",
      "AUC for ROC curve 10: 0.9614\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, f1_score,roc_auc_score\n",
    "losses = []\n",
    "accuracies = []\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "f1_scores = []\n",
    "auc_scores = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "\n",
    "num_trainings = 10\n",
    "for i in range(num_trainings):\n",
    "    model = create_model(x_train1.shape[1:], x_train2.shape[1:], x_train3.shape[1:])\n",
    "    model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "    history = model.fit([x_train1, x_train2, x_train3], y_train, batch_size=128, epochs=100,\n",
    "                        validation_data=([x_val1, x_val2, x_val3], y_val), callbacks=[lr_scheduler])\n",
    "    loss, accuracy = model.evaluate([x_test1, x_test2, x_test3], y_test)\n",
    "    y_prob = model.predict([x_test1, x_test2, x_test3], batch_size=1024, verbose=1)\n",
    "\n",
    "    y_true = y_test.argmax(axis=-1)\n",
    "    y_pred = np.argmax(y_prob, axis=-1)\n",
    "\n",
    "    C = confusion_matrix(y_true, y_pred, labels=(1, 0))\n",
    "    TP, TN, FP, FN = C[0, 0], C[1, 1], C[1, 0], C[0, 1]\n",
    "    acc, sn, sp = 1. * (TP + TN) / (TP + TN + FP + FN), 1. * TP / (TP + FN), 1. * TN / (TN + FP)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    sn = TP / (TP + FN)  \n",
    "    sp = TN / (TN + FP) \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = sn\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    auc_scores.append(roc_auc)\n",
    "    \n",
    "    print(\"TP:{}, TN:{}, FP:{}, FN:{}, loss{}, acc{}, sn{}, sp{}, f1{}, auc{}\".format(TP, TN, FP, FN, loss, acc, sn, sp, f1, roc_auc))\n",
    "    losses.append(loss)\n",
    "    accuracies.append(acc)\n",
    "    sensitivities.append(sn)\n",
    "    specificities.append(sp)\n",
    "    f1_scores.append(f1)\n",
    "    auc_scores.append(roc_auc)\n",
    "\n",
    "avg_loss = np.mean(losses)\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_sensitivity = np.mean(sensitivities)\n",
    "avg_specificity = np.mean(specificities)\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "avg_auc_score = np.mean(auc_scores)\n",
    "\n",
    "print(\"Average Test loss: \", avg_loss)\n",
    "print(\"Average Accuracy: \", avg_accuracy)\n",
    "print(\"Average Sensitivity: \", avg_sensitivity)\n",
    "print(\"Average Specificity: \", avg_specificity)\n",
    "print(\"Average F1 Score: \", avg_f1_score)\n",
    "print(\"Average AUC Score: \", avg_auc_score)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = np.zeros_like(mean_fpr)\n",
    "for i in range(num_trainings):\n",
    "    mean_tpr += np.interp(mean_fpr, fprs[i], tprs[i])\n",
    "    plt.plot(fprs[i], tprs[i], alpha=0.3, label='ROC curve {} (AUC = {:.4f})'.format(i+1, auc_scores[i]))\n",
    "    print('AUC for ROC curve {}: {:.4f}'.format(i+1, auc_scores[i]))\n",
    "mean_tpr /= num_trainings\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--', label='Mean ROC (AUC = {:.4f})'.format(mean_auc), lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f9963-cfa7-47f5-8701-2a24e58e20bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gcn",
   "language": "python",
   "name": "gcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
