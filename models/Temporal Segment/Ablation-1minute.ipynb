{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "-028b2NqE02R",
   "metadata": {
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1693232083105,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "-028b2NqE02R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 22:42:19.099679: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.Session(config=config).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a034672d",
   "metadata": {
    "executionInfo": {
     "elapsed": 1150,
     "status": "ok",
     "timestamp": 1693232086282,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "a034672d"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import BatchNormalization, LeakyReLU, MaxPooling1D, Dropout, Flatten, Dense, Conv1D,Reshape,multiply,GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from scipy.interpolate import splev, splrep\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591596f3",
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1693232087740,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "591596f3"
   },
   "outputs": [],
   "source": [
    "base_dir = \"./dataset\"\n",
    "\n",
    "ir = 3 \n",
    "before = 2\n",
    "after = 2\n",
    "scaler = lambda arr: (arr - np.min(arr)) / (np.max(arr) - np.min(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cef782d",
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1693232089719,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "0cef782d"
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "def interpolate_numpy_array(arr, desired_length):\n",
    "    cs = CubicSpline(np.linspace(0, 1, len(arr)), arr)\n",
    "    x_new = np.linspace(0, 1, desired_length)\n",
    "    interpolated_arr = cs(x_new)\n",
    "    return interpolated_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "KXj-pyPoXKm3",
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1693232167282,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "KXj-pyPoXKm3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def load_data():\n",
    "    tm = np.arange(0, (before + 1 + after) * 60, step=1 / float(ir))\n",
    "    with open(os.path.join(base_dir, \"apnea.pkl\"), 'rb') as f:\n",
    "        apnea_ecg = pickle.load(f)\n",
    "    x_train1,x_train2,x_train3 = [],[],[]\n",
    "    o_train, y_train = apnea_ecg[\"o_train\"], apnea_ecg[\"y_train\"]\n",
    "    groups_train = apnea_ecg[\"groups_train\"]\n",
    "    for i in range(len(o_train)):\n",
    "        min_distance_list, max_distance_list= o_train[i]\n",
    "        min_distance_list_inter = interpolate_numpy_array(min_distance_list,900)\n",
    "        max_distance_list_inter = interpolate_numpy_array(max_distance_list,900)\n",
    "        x_train1.append([min_distance_list_inter, max_distance_list_inter])\n",
    "        x_train2.append([min_distance_list_inter[180:720], max_distance_list_inter[180:720]])\n",
    "        x_train3.append([min_distance_list_inter[360:540], max_distance_list_inter[360:540]])\n",
    "    x_training1,x_training2,x_training3,y_training,groups_training = [],[],[],[],[]\n",
    "    x_val1,x_val2,x_val3,y_val,groups_val = [],[],[],[],[]\n",
    "\n",
    "    trainlist = random.sample(range(len(o_train)),int(len(o_train)*0.7))\n",
    "    num=[i for i in range(16713)]\n",
    "    vallist = set(num) - set(trainlist)\n",
    "    vallist = list(vallist)\n",
    "    for i in trainlist:\n",
    "        x_training1.append(x_train1[i])\n",
    "        x_training2.append(x_train2[i])\n",
    "        x_training3.append(x_train3[i])\n",
    "        y_training.append(y_train[i])\n",
    "        groups_training.append(groups_train[i])\n",
    "    for i in vallist:\n",
    "        x_val1.append(x_train1[i])\n",
    "        x_val2.append(x_train2[i])\n",
    "        x_val3.append(x_train3[i])\n",
    "        y_val.append(y_train[i])\n",
    "        groups_val.append(groups_train[i])\n",
    "\n",
    "    x_training1 = np.array(x_training1, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_training2 = np.array(x_training2, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_training3 = np.array(x_training3, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    y_training = np.array(y_training, dtype=\"float32\")\n",
    "    x_val1 = np.array(x_val1, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_val2 = np.array(x_val2, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_val3 = np.array(x_val3, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    y_val = np.array(y_val, dtype=\"float32\")\n",
    "\n",
    "    x_test1,x_test2,x_test3 = [],[],[]\n",
    "    o_test, y_test = apnea_ecg[\"o_test\"], apnea_ecg[\"y_test\"]\n",
    "    groups_test = apnea_ecg[\"groups_test\"]\n",
    "    for i in range(len(o_test)):\n",
    "        min_distance_list, max_distance_list = o_test[i]\n",
    "        min_distance_list_inter = interpolate_numpy_array(min_distance_list,900)\n",
    "        max_distance_list_inter = interpolate_numpy_array(max_distance_list,900)\n",
    "        x_test1.append([min_distance_list_inter, max_distance_list_inter])\n",
    "        x_test2.append([min_distance_list_inter[180:720], max_distance_list_inter[180:720]])\n",
    "        x_test3.append([min_distance_list_inter[360:540], max_distance_list_inter[360:540]])\n",
    "    x_test1 = np.array(x_test1, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_test2 = np.array(x_test2, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    x_test3 = np.array(x_test3, dtype=\"float32\").transpose((0, 2, 1))\n",
    "    y_test = np.array(y_test, dtype=\"float32\")\n",
    "\n",
    "    return x_training1, x_training2, x_training3, y_training, groups_training, x_val1, x_val2, x_val3, y_val, groups_val, x_test1, x_test2, x_test3, y_test, groups_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ef5b79-3b27-4888-9bb6-ad2415d780d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, ratio=4,**kwargs):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.channels = input_shape[-1]\n",
    "        self.fc1 = tf.keras.layers.Dense(self.channels // self.ratio, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(self.channels, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        max_pool = tf.reduce_max(inputs, axis=[1, 2], keepdims=True)\n",
    "        avg_pool = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n",
    "        max_pool = self.fc1(max_pool)\n",
    "        avg_pool = self.fc1(avg_pool)\n",
    "        attention = self.fc2(tf.keras.layers.add([max_pool, avg_pool]))\n",
    "        return inputs * attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9c50e53-c397-4432-bb00-4ec3a202a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = keras.layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71576d5f-5bfa-4321-bd05-f1a9b3c2d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualAttentionBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(ResidualAttentionBlock, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv1D(num_output_features, kernel_size=1, strides=1, padding='valid', use_bias=False)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv1D(num_output_features, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv3 = tf.keras.layers.Conv1D(num_output_features, kernel_size=1, strides=1, padding='valid', use_bias=False)\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        residual = x       \n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = self.sigmoid(out)      \n",
    "\n",
    "        out = out * residual + residual\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd7222a-ca10-4ac3-b7ca-6272cbbd2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers=2, d_model=64, nhead=1, dim_feedforward=128, dropout=0.30):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.precnnlayer = layers.Dense(d_model)\n",
    "        self.multi_head_attention = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model)\n",
    "\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(dim_feedforward, activation='relu'),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "\n",
    "        self.layer_norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "        self.pred_layer = tf.keras.Sequential([\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.precnnlayer(x)\n",
    "        x += self.multi_head_attention(x, x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm1(x)\n",
    "        ffn_output = self.ffn(x)\n",
    "        x += ffn_output\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.pred_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "GnDFx0fGCy1m",
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1693232096445,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "GnDFx0fGCy1m"
   },
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling1D\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, GRU, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "def create_model(input_c_shape, weight=1e-3,rate=1):\n",
    "    leaky_relu = LeakyReLU()\n",
    "\n",
    "    # CNN-3\n",
    "    input3 = Input(shape=input_c_shape)\n",
    "\n",
    "    x3 = Conv1D(16, kernel_size=7, strides=4, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(input3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = leaky_relu(x3)\n",
    "    x3 = MaxPooling1D(pool_size=3)(x3)\n",
    "    x3 = Dropout(0.5)(x3)\n",
    "\n",
    "    x3 = Conv1D(32, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = leaky_relu(x3)\n",
    "    x3 = MaxPooling1D(pool_size=3)(x3)\n",
    "    x3 = Dropout(0.5)(x3)\n",
    "\n",
    "    x3 = Conv1D(64, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(x3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = leaky_relu(x3)\n",
    "    x3 = Dropout(0.5)(x3)\n",
    "\n",
    "    attention = ResidualAttentionBlock(64, 64)\n",
    "    x3 = attention(x3)\n",
    "\n",
    "    concat=ChannelAttention()(x3)\n",
    "    x = GlobalAveragePooling1D()(concat)\n",
    "    dp = Dropout(0.5)(x)\n",
    "    outputs = Dense(2, activation='softmax', name=\"Output_Layer\")(dp)\n",
    "    model = Model(inputs=[input3], outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c830eb3",
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1693232100397,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "6c830eb3"
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch > 70 and \\\n",
    "            (epoch - 1) % 10 == 0:\n",
    "        lr *= 0.1\n",
    "    print(\"Learning rate: \", lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded3f606",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1693232101699,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "ded3f606"
   },
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    \"\"\"Plot performance curve\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    axes[0].plot(history[\"loss\"], \"r-\", history[\"val_loss\"], \"b-\", linewidth=0.5)\n",
    "    axes[0].set_title(\"Loss\")\n",
    "    axes[1].plot(history[\"accuracy\"], \"r-\", history[\"val_accuracy\"], \"b-\", linewidth=0.5)\n",
    "    axes[1].set_title(\"Accuracy\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "v6XhEYeu7cgM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45661,
     "status": "ok",
     "timestamp": 1693233004292,
     "user": {
      "displayName": "Hiếu Nguyễn Xuân",
      "userId": "09184859202144170734"
     },
     "user_tz": -420
    },
    "id": "v6XhEYeu7cgM",
    "outputId": "4f452c32-a1f2-4c9e-b7bc-05ca348f3613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape (11699, 900, 2) (11699, 540, 2) (11699, 180, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    x_train1, x_train2, x_train3, y_train, groups_train, x_val1, x_val2, x_val3, y_val, groups_val, x_test1, x_test2, x_test3, y_test, groups_test= load_data()\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes=2)  # Convert to two categories\n",
    "    y_val = keras.utils.to_categorical(y_val, num_classes=2)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes=2)\n",
    "\n",
    "    print('input_shape', x_train1.shape, x_train2.shape, x_train3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae98c6d-d470-4371-b7bb-6707c20168f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 17s 40ms/step - loss: 0.9284 - accuracy: 0.5682 - val_loss: 0.8684 - val_accuracy: 0.6113 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.8471 - accuracy: 0.5882 - val_loss: 0.8510 - val_accuracy: 0.5818 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.8092 - accuracy: 0.5981 - val_loss: 0.8286 - val_accuracy: 0.5784 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7775 - accuracy: 0.6084 - val_loss: 0.8154 - val_accuracy: 0.5505 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7534 - accuracy: 0.6181 - val_loss: 0.8029 - val_accuracy: 0.5136 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.7346 - accuracy: 0.6191 - val_loss: 0.7928 - val_accuracy: 0.4984 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.7176 - accuracy: 0.6244 - val_loss: 0.7778 - val_accuracy: 0.5533 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.7015 - accuracy: 0.6269 - val_loss: 0.7711 - val_accuracy: 0.5550 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6894 - accuracy: 0.6335 - val_loss: 0.7696 - val_accuracy: 0.5170 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6805 - accuracy: 0.6324 - val_loss: 0.7497 - val_accuracy: 0.5716 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6701 - accuracy: 0.6454 - val_loss: 0.7600 - val_accuracy: 0.5016 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6646 - accuracy: 0.6445 - val_loss: 0.7568 - val_accuracy: 0.4928 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.6588 - accuracy: 0.6517 - val_loss: 0.7726 - val_accuracy: 0.4581 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.6515 - accuracy: 0.6528 - val_loss: 0.7874 - val_accuracy: 0.4533 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.6435 - accuracy: 0.6585 - val_loss: 0.7811 - val_accuracy: 0.4661 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.6392 - accuracy: 0.6643 - val_loss: 0.7360 - val_accuracy: 0.5397 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6375 - accuracy: 0.6637 - val_loss: 0.8085 - val_accuracy: 0.4659 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6335 - accuracy: 0.6715 - val_loss: 0.6871 - val_accuracy: 0.6067 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6271 - accuracy: 0.6694 - val_loss: 0.8412 - val_accuracy: 0.4685 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6279 - accuracy: 0.6672 - val_loss: 0.8315 - val_accuracy: 0.4665 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6216 - accuracy: 0.6713 - val_loss: 0.7672 - val_accuracy: 0.5247 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6193 - accuracy: 0.6763 - val_loss: 0.7328 - val_accuracy: 0.5519 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6217 - accuracy: 0.6730 - val_loss: 0.7802 - val_accuracy: 0.4990 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6183 - accuracy: 0.6730 - val_loss: 0.7266 - val_accuracy: 0.5608 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6135 - accuracy: 0.6743 - val_loss: 0.7163 - val_accuracy: 0.5674 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6124 - accuracy: 0.6781 - val_loss: 0.7523 - val_accuracy: 0.5533 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.6112 - accuracy: 0.6839 - val_loss: 0.7153 - val_accuracy: 0.5708 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6050 - accuracy: 0.6929 - val_loss: 0.8034 - val_accuracy: 0.4950 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6052 - accuracy: 0.6862 - val_loss: 0.7081 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6050 - accuracy: 0.6847 - val_loss: 0.7856 - val_accuracy: 0.5106 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5997 - accuracy: 0.6922 - val_loss: 0.7400 - val_accuracy: 0.5383 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5987 - accuracy: 0.6939 - val_loss: 0.7684 - val_accuracy: 0.5359 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5941 - accuracy: 0.6981 - val_loss: 0.7637 - val_accuracy: 0.5160 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5959 - accuracy: 0.6967 - val_loss: 0.6353 - val_accuracy: 0.6452 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5869 - accuracy: 0.7041 - val_loss: 0.6361 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5895 - accuracy: 0.7026 - val_loss: 0.5961 - val_accuracy: 0.6799 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5864 - accuracy: 0.7047 - val_loss: 0.6405 - val_accuracy: 0.6444 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5828 - accuracy: 0.7085 - val_loss: 0.6711 - val_accuracy: 0.6075 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5842 - accuracy: 0.7097 - val_loss: 0.5944 - val_accuracy: 0.6855 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5829 - accuracy: 0.7099 - val_loss: 0.6297 - val_accuracy: 0.6516 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.5798 - accuracy: 0.7072 - val_loss: 0.6165 - val_accuracy: 0.6625 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5779 - accuracy: 0.7118 - val_loss: 0.5766 - val_accuracy: 0.7050 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5748 - accuracy: 0.7178 - val_loss: 0.5582 - val_accuracy: 0.7314 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5748 - accuracy: 0.7119 - val_loss: 0.5609 - val_accuracy: 0.7238 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5748 - accuracy: 0.7110 - val_loss: 0.6126 - val_accuracy: 0.6687 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5769 - accuracy: 0.7111 - val_loss: 0.6402 - val_accuracy: 0.6294 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5736 - accuracy: 0.7134 - val_loss: 0.5806 - val_accuracy: 0.7050 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5721 - accuracy: 0.7195 - val_loss: 0.6137 - val_accuracy: 0.6645 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5711 - accuracy: 0.7172 - val_loss: 0.5879 - val_accuracy: 0.6921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5708 - accuracy: 0.7200 - val_loss: 0.6162 - val_accuracy: 0.6592 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5647 - accuracy: 0.7225 - val_loss: 0.5641 - val_accuracy: 0.7248 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5632 - accuracy: 0.7242 - val_loss: 0.5736 - val_accuracy: 0.7118 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5622 - accuracy: 0.7231 - val_loss: 0.5577 - val_accuracy: 0.7306 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5665 - accuracy: 0.7215 - val_loss: 0.5502 - val_accuracy: 0.7339 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5624 - accuracy: 0.7249 - val_loss: 0.5302 - val_accuracy: 0.7495 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5634 - accuracy: 0.7215 - val_loss: 0.6079 - val_accuracy: 0.6729 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5613 - accuracy: 0.7296 - val_loss: 0.5188 - val_accuracy: 0.7605 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5624 - accuracy: 0.7238 - val_loss: 0.5353 - val_accuracy: 0.7515 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5549 - accuracy: 0.7307 - val_loss: 0.5653 - val_accuracy: 0.7204 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5576 - accuracy: 0.7304 - val_loss: 0.5042 - val_accuracy: 0.7675 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5616 - accuracy: 0.7268 - val_loss: 0.5106 - val_accuracy: 0.7631 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5557 - accuracy: 0.7314 - val_loss: 0.5243 - val_accuracy: 0.7623 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5523 - accuracy: 0.7331 - val_loss: 0.5457 - val_accuracy: 0.7337 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5538 - accuracy: 0.7284 - val_loss: 0.5170 - val_accuracy: 0.7696 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5524 - accuracy: 0.7353 - val_loss: 0.5027 - val_accuracy: 0.7696 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5499 - accuracy: 0.7380 - val_loss: 0.4973 - val_accuracy: 0.7718 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.5499 - accuracy: 0.7378 - val_loss: 0.4905 - val_accuracy: 0.7780 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.5522 - accuracy: 0.7286 - val_loss: 0.5163 - val_accuracy: 0.7675 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5423 - accuracy: 0.7418 - val_loss: 0.4972 - val_accuracy: 0.7786 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.5458 - accuracy: 0.7392 - val_loss: 0.5005 - val_accuracy: 0.7702 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5500 - accuracy: 0.7339 - val_loss: 0.4848 - val_accuracy: 0.7852 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5395 - accuracy: 0.7448 - val_loss: 0.4846 - val_accuracy: 0.7860 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5408 - accuracy: 0.7385 - val_loss: 0.4833 - val_accuracy: 0.7862 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.5413 - accuracy: 0.7436 - val_loss: 0.4839 - val_accuracy: 0.7842 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5381 - accuracy: 0.7410 - val_loss: 0.4817 - val_accuracy: 0.7866 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5404 - accuracy: 0.7478 - val_loss: 0.4829 - val_accuracy: 0.7852 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5385 - accuracy: 0.7408 - val_loss: 0.4823 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5356 - accuracy: 0.7466 - val_loss: 0.4803 - val_accuracy: 0.7886 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5384 - accuracy: 0.7448 - val_loss: 0.4792 - val_accuracy: 0.7860 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5303 - accuracy: 0.7478 - val_loss: 0.4762 - val_accuracy: 0.7866 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5327 - accuracy: 0.7513 - val_loss: 0.4817 - val_accuracy: 0.7872 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.5319 - accuracy: 0.7489 - val_loss: 0.4779 - val_accuracy: 0.7876 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5334 - accuracy: 0.7496 - val_loss: 0.4778 - val_accuracy: 0.7878 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.5318 - accuracy: 0.7490 - val_loss: 0.4772 - val_accuracy: 0.7882 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5320 - accuracy: 0.7465 - val_loss: 0.4767 - val_accuracy: 0.7896 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5379 - accuracy: 0.7419 - val_loss: 0.4764 - val_accuracy: 0.7894 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5338 - accuracy: 0.7525 - val_loss: 0.4765 - val_accuracy: 0.7896 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5364 - accuracy: 0.7467 - val_loss: 0.4762 - val_accuracy: 0.7890 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5318 - accuracy: 0.7474 - val_loss: 0.4760 - val_accuracy: 0.7898 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5367 - accuracy: 0.7448 - val_loss: 0.4755 - val_accuracy: 0.7896 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5336 - accuracy: 0.7505 - val_loss: 0.4756 - val_accuracy: 0.7900 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5317 - accuracy: 0.7467 - val_loss: 0.4755 - val_accuracy: 0.7894 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5325 - accuracy: 0.7475 - val_loss: 0.4755 - val_accuracy: 0.7894 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5357 - accuracy: 0.7448 - val_loss: 0.4753 - val_accuracy: 0.7894 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5368 - accuracy: 0.7419 - val_loss: 0.4751 - val_accuracy: 0.7896 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5297 - accuracy: 0.7504 - val_loss: 0.4756 - val_accuracy: 0.7900 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.5343 - accuracy: 0.7470 - val_loss: 0.4757 - val_accuracy: 0.7902 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 21ms/step - loss: 0.5334 - accuracy: 0.7519 - val_loss: 0.4756 - val_accuracy: 0.7894 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5356 - accuracy: 0.7432 - val_loss: 0.4753 - val_accuracy: 0.7900 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 32ms/step - loss: 0.5339 - accuracy: 0.7430 - val_loss: 0.4751 - val_accuracy: 0.7898 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 4s 7ms/step - loss: 0.4397 - accuracy: 0.8103\n",
      "17/17 [==============================] - 1s 9ms/step\n",
      "TP:4544, TN:9188, FP:1267, FN:1947, loss0.4396541118621826, acc0.8103387230024784, sn0.7000462178400862, sp0.8788139646102343, f10.7387416680214599, auc0.8791335256461121\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 13s 35ms/step - loss: 1.0041 - accuracy: 0.5475 - val_loss: 0.9550 - val_accuracy: 0.3855 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.8714 - accuracy: 0.5944 - val_loss: 0.9029 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.8338 - accuracy: 0.5991 - val_loss: 0.8679 - val_accuracy: 0.5018 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.8007 - accuracy: 0.6177 - val_loss: 0.8429 - val_accuracy: 0.5142 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.7761 - accuracy: 0.6282 - val_loss: 0.8185 - val_accuracy: 0.5351 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.7575 - accuracy: 0.6248 - val_loss: 0.7959 - val_accuracy: 0.5525 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.7371 - accuracy: 0.6340 - val_loss: 0.7849 - val_accuracy: 0.5560 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.7211 - accuracy: 0.6465 - val_loss: 0.7623 - val_accuracy: 0.5792 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.7073 - accuracy: 0.6449 - val_loss: 0.7632 - val_accuracy: 0.5600 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6947 - accuracy: 0.6477 - val_loss: 0.7630 - val_accuracy: 0.5544 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6830 - accuracy: 0.6537 - val_loss: 0.7381 - val_accuracy: 0.5844 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6723 - accuracy: 0.6548 - val_loss: 0.7524 - val_accuracy: 0.5554 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6648 - accuracy: 0.6595 - val_loss: 0.7782 - val_accuracy: 0.5148 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6601 - accuracy: 0.6560 - val_loss: 0.7271 - val_accuracy: 0.5722 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6497 - accuracy: 0.6648 - val_loss: 0.7545 - val_accuracy: 0.5429 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6430 - accuracy: 0.6702 - val_loss: 0.7717 - val_accuracy: 0.5271 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6314 - accuracy: 0.6764 - val_loss: 0.7562 - val_accuracy: 0.5411 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6293 - accuracy: 0.6827 - val_loss: 0.7214 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6231 - accuracy: 0.6870 - val_loss: 0.7078 - val_accuracy: 0.5864 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6185 - accuracy: 0.6881 - val_loss: 0.7006 - val_accuracy: 0.5856 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6153 - accuracy: 0.6950 - val_loss: 0.7456 - val_accuracy: 0.5361 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6079 - accuracy: 0.7010 - val_loss: 0.6739 - val_accuracy: 0.6294 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6042 - accuracy: 0.7031 - val_loss: 0.6085 - val_accuracy: 0.6825 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6042 - accuracy: 0.6966 - val_loss: 0.6415 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5957 - accuracy: 0.7011 - val_loss: 0.6116 - val_accuracy: 0.6823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5936 - accuracy: 0.7090 - val_loss: 0.7329 - val_accuracy: 0.5586 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5911 - accuracy: 0.7114 - val_loss: 0.6203 - val_accuracy: 0.6695 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5901 - accuracy: 0.7085 - val_loss: 0.5901 - val_accuracy: 0.7026 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5874 - accuracy: 0.7143 - val_loss: 0.6241 - val_accuracy: 0.6645 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5808 - accuracy: 0.7154 - val_loss: 0.6488 - val_accuracy: 0.6356 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5840 - accuracy: 0.7135 - val_loss: 0.6162 - val_accuracy: 0.6725 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5721 - accuracy: 0.7210 - val_loss: 0.6124 - val_accuracy: 0.6811 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5728 - accuracy: 0.7205 - val_loss: 0.6127 - val_accuracy: 0.6815 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5749 - accuracy: 0.7188 - val_loss: 0.5659 - val_accuracy: 0.7312 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5722 - accuracy: 0.7238 - val_loss: 0.5887 - val_accuracy: 0.6992 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5703 - accuracy: 0.7223 - val_loss: 0.5417 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5683 - accuracy: 0.7254 - val_loss: 0.5523 - val_accuracy: 0.7441 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5629 - accuracy: 0.7295 - val_loss: 0.5633 - val_accuracy: 0.7355 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5596 - accuracy: 0.7328 - val_loss: 0.6093 - val_accuracy: 0.6823 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5633 - accuracy: 0.7307 - val_loss: 0.5561 - val_accuracy: 0.7393 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5549 - accuracy: 0.7362 - val_loss: 0.5209 - val_accuracy: 0.7617 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5602 - accuracy: 0.7363 - val_loss: 0.5359 - val_accuracy: 0.7561 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5601 - accuracy: 0.7330 - val_loss: 0.5241 - val_accuracy: 0.7663 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5569 - accuracy: 0.7342 - val_loss: 0.5089 - val_accuracy: 0.7698 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5517 - accuracy: 0.7368 - val_loss: 0.5029 - val_accuracy: 0.7828 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5489 - accuracy: 0.7387 - val_loss: 0.4978 - val_accuracy: 0.7780 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5495 - accuracy: 0.7401 - val_loss: 0.5062 - val_accuracy: 0.7788 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5483 - accuracy: 0.7402 - val_loss: 0.4882 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5499 - accuracy: 0.7369 - val_loss: 0.4976 - val_accuracy: 0.7720 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5423 - accuracy: 0.7474 - val_loss: 0.4886 - val_accuracy: 0.7940 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5435 - accuracy: 0.7410 - val_loss: 0.4820 - val_accuracy: 0.7804 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5443 - accuracy: 0.7421 - val_loss: 0.4915 - val_accuracy: 0.7694 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5464 - accuracy: 0.7436 - val_loss: 0.4983 - val_accuracy: 0.7886 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5421 - accuracy: 0.7422 - val_loss: 0.4766 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5336 - accuracy: 0.7492 - val_loss: 0.4834 - val_accuracy: 0.7800 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5303 - accuracy: 0.7539 - val_loss: 0.4781 - val_accuracy: 0.7806 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5334 - accuracy: 0.7518 - val_loss: 0.4768 - val_accuracy: 0.7820 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5334 - accuracy: 0.7485 - val_loss: 0.4942 - val_accuracy: 0.7688 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5345 - accuracy: 0.7492 - val_loss: 0.4660 - val_accuracy: 0.7956 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5315 - accuracy: 0.7474 - val_loss: 0.4650 - val_accuracy: 0.7956 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5270 - accuracy: 0.7552 - val_loss: 0.4782 - val_accuracy: 0.7906 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5288 - accuracy: 0.7553 - val_loss: 0.4674 - val_accuracy: 0.7934 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5300 - accuracy: 0.7540 - val_loss: 0.4991 - val_accuracy: 0.7631 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5215 - accuracy: 0.7569 - val_loss: 0.4960 - val_accuracy: 0.7702 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5226 - accuracy: 0.7601 - val_loss: 0.4664 - val_accuracy: 0.7862 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5310 - accuracy: 0.7522 - val_loss: 0.4651 - val_accuracy: 0.7862 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5281 - accuracy: 0.7575 - val_loss: 0.4700 - val_accuracy: 0.7788 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5254 - accuracy: 0.7581 - val_loss: 0.4572 - val_accuracy: 0.7988 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5194 - accuracy: 0.7612 - val_loss: 0.4637 - val_accuracy: 0.7960 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5231 - accuracy: 0.7543 - val_loss: 0.5356 - val_accuracy: 0.7531 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5188 - accuracy: 0.7602 - val_loss: 0.4437 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5115 - accuracy: 0.7667 - val_loss: 0.4461 - val_accuracy: 0.8014 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5114 - accuracy: 0.7689 - val_loss: 0.4503 - val_accuracy: 0.7990 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5091 - accuracy: 0.7664 - val_loss: 0.4511 - val_accuracy: 0.7996 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5121 - accuracy: 0.7659 - val_loss: 0.4523 - val_accuracy: 0.7990 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5067 - accuracy: 0.7674 - val_loss: 0.4528 - val_accuracy: 0.7992 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5177 - accuracy: 0.7617 - val_loss: 0.4509 - val_accuracy: 0.7994 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5118 - accuracy: 0.7625 - val_loss: 0.4502 - val_accuracy: 0.7974 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5091 - accuracy: 0.7646 - val_loss: 0.4507 - val_accuracy: 0.7994 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5096 - accuracy: 0.7699 - val_loss: 0.4481 - val_accuracy: 0.8010 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5109 - accuracy: 0.7637 - val_loss: 0.4495 - val_accuracy: 0.7984 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5115 - accuracy: 0.7612 - val_loss: 0.4500 - val_accuracy: 0.7996 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5125 - accuracy: 0.7639 - val_loss: 0.4509 - val_accuracy: 0.7994 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5057 - accuracy: 0.7673 - val_loss: 0.4509 - val_accuracy: 0.7992 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5121 - accuracy: 0.7611 - val_loss: 0.4496 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5116 - accuracy: 0.7660 - val_loss: 0.4498 - val_accuracy: 0.7996 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5055 - accuracy: 0.7669 - val_loss: 0.4491 - val_accuracy: 0.8008 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5107 - accuracy: 0.7636 - val_loss: 0.4495 - val_accuracy: 0.8006 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5044 - accuracy: 0.7745 - val_loss: 0.4494 - val_accuracy: 0.8008 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5082 - accuracy: 0.7691 - val_loss: 0.4495 - val_accuracy: 0.8012 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5071 - accuracy: 0.7673 - val_loss: 0.4501 - val_accuracy: 0.7992 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5109 - accuracy: 0.7659 - val_loss: 0.4491 - val_accuracy: 0.8020 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5013 - accuracy: 0.7702 - val_loss: 0.4491 - val_accuracy: 0.8018 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5035 - accuracy: 0.7690 - val_loss: 0.4491 - val_accuracy: 0.8018 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5051 - accuracy: 0.7673 - val_loss: 0.4490 - val_accuracy: 0.8018 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5076 - accuracy: 0.7663 - val_loss: 0.4491 - val_accuracy: 0.8018 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5087 - accuracy: 0.7661 - val_loss: 0.4488 - val_accuracy: 0.8018 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5063 - accuracy: 0.7703 - val_loss: 0.4491 - val_accuracy: 0.8018 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5094 - accuracy: 0.7639 - val_loss: 0.4488 - val_accuracy: 0.8016 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5039 - accuracy: 0.7693 - val_loss: 0.4485 - val_accuracy: 0.8018 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 9ms/step - loss: 0.4122 - accuracy: 0.8195\n",
      "17/17 [==============================] - 1s 7ms/step\n",
      "TP:4452, TN:9436, FP:1019, FN:2039, loss0.4121975898742676, acc0.8195444352649592, sn0.6858727468802958, sp0.9025346724055476, f10.7443571309145628, auc0.896608665598197\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 14s 35ms/step - loss: 0.9330 - accuracy: 0.5673 - val_loss: 0.8716 - val_accuracy: 0.5780 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.8614 - accuracy: 0.5802 - val_loss: 0.8549 - val_accuracy: 0.5710 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.8145 - accuracy: 0.6024 - val_loss: 0.8339 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7818 - accuracy: 0.6094 - val_loss: 0.8167 - val_accuracy: 0.5644 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.7552 - accuracy: 0.6259 - val_loss: 0.7972 - val_accuracy: 0.5560 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.7349 - accuracy: 0.6197 - val_loss: 0.7814 - val_accuracy: 0.5451 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7181 - accuracy: 0.6343 - val_loss: 0.7589 - val_accuracy: 0.5706 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.7031 - accuracy: 0.6324 - val_loss: 0.7619 - val_accuracy: 0.5199 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6877 - accuracy: 0.6381 - val_loss: 0.7428 - val_accuracy: 0.5499 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6780 - accuracy: 0.6471 - val_loss: 0.7424 - val_accuracy: 0.5319 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6705 - accuracy: 0.6436 - val_loss: 0.7194 - val_accuracy: 0.5802 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6565 - accuracy: 0.6591 - val_loss: 0.7213 - val_accuracy: 0.5590 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6515 - accuracy: 0.6606 - val_loss: 0.6761 - val_accuracy: 0.6290 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6482 - accuracy: 0.6594 - val_loss: 0.6908 - val_accuracy: 0.6135 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6359 - accuracy: 0.6672 - val_loss: 0.6990 - val_accuracy: 0.5736 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6338 - accuracy: 0.6682 - val_loss: 0.6619 - val_accuracy: 0.6398 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6267 - accuracy: 0.6800 - val_loss: 0.7186 - val_accuracy: 0.5455 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6174 - accuracy: 0.6847 - val_loss: 0.6150 - val_accuracy: 0.6773 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6170 - accuracy: 0.6861 - val_loss: 0.6920 - val_accuracy: 0.5814 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6093 - accuracy: 0.6924 - val_loss: 0.6797 - val_accuracy: 0.6009 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6036 - accuracy: 0.6962 - val_loss: 0.6895 - val_accuracy: 0.5870 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5983 - accuracy: 0.7002 - val_loss: 0.6764 - val_accuracy: 0.5953 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5952 - accuracy: 0.7058 - val_loss: 0.6402 - val_accuracy: 0.6416 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5931 - accuracy: 0.7051 - val_loss: 0.6349 - val_accuracy: 0.6426 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5880 - accuracy: 0.7089 - val_loss: 0.6004 - val_accuracy: 0.6951 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5899 - accuracy: 0.7092 - val_loss: 0.6077 - val_accuracy: 0.6849 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5801 - accuracy: 0.7133 - val_loss: 0.6084 - val_accuracy: 0.6751 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5786 - accuracy: 0.7177 - val_loss: 0.6587 - val_accuracy: 0.6015 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5804 - accuracy: 0.7147 - val_loss: 0.6037 - val_accuracy: 0.6933 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5761 - accuracy: 0.7189 - val_loss: 0.5772 - val_accuracy: 0.7190 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5750 - accuracy: 0.7159 - val_loss: 0.5688 - val_accuracy: 0.7316 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5711 - accuracy: 0.7250 - val_loss: 0.5835 - val_accuracy: 0.7096 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5719 - accuracy: 0.7216 - val_loss: 0.5790 - val_accuracy: 0.7361 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5675 - accuracy: 0.7295 - val_loss: 0.5444 - val_accuracy: 0.7619 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5664 - accuracy: 0.7283 - val_loss: 0.5521 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5645 - accuracy: 0.7270 - val_loss: 0.5566 - val_accuracy: 0.7477 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5652 - accuracy: 0.7289 - val_loss: 0.5916 - val_accuracy: 0.7092 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5612 - accuracy: 0.7323 - val_loss: 0.5657 - val_accuracy: 0.7345 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5545 - accuracy: 0.7382 - val_loss: 0.5391 - val_accuracy: 0.7722 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5578 - accuracy: 0.7339 - val_loss: 0.5145 - val_accuracy: 0.7637 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5468 - accuracy: 0.7355 - val_loss: 0.5101 - val_accuracy: 0.7698 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5535 - accuracy: 0.7365 - val_loss: 0.5202 - val_accuracy: 0.7595 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5504 - accuracy: 0.7374 - val_loss: 0.5144 - val_accuracy: 0.7696 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5500 - accuracy: 0.7419 - val_loss: 0.5240 - val_accuracy: 0.7531 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5471 - accuracy: 0.7413 - val_loss: 0.4976 - val_accuracy: 0.7748 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5401 - accuracy: 0.7479 - val_loss: 0.4838 - val_accuracy: 0.7792 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5489 - accuracy: 0.7349 - val_loss: 0.4964 - val_accuracy: 0.7700 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5370 - accuracy: 0.7534 - val_loss: 0.4878 - val_accuracy: 0.7806 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5383 - accuracy: 0.7441 - val_loss: 0.4882 - val_accuracy: 0.7740 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5444 - accuracy: 0.7478 - val_loss: 0.4867 - val_accuracy: 0.7732 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5366 - accuracy: 0.7475 - val_loss: 0.5087 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5398 - accuracy: 0.7495 - val_loss: 0.5294 - val_accuracy: 0.7547 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5368 - accuracy: 0.7466 - val_loss: 0.4877 - val_accuracy: 0.7762 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5274 - accuracy: 0.7577 - val_loss: 0.4869 - val_accuracy: 0.7780 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5376 - accuracy: 0.7490 - val_loss: 0.5165 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5290 - accuracy: 0.7512 - val_loss: 0.4689 - val_accuracy: 0.7840 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5303 - accuracy: 0.7529 - val_loss: 0.4974 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5312 - accuracy: 0.7564 - val_loss: 0.4965 - val_accuracy: 0.7718 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.5282 - accuracy: 0.7554 - val_loss: 0.4772 - val_accuracy: 0.7782 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5246 - accuracy: 0.7566 - val_loss: 0.4808 - val_accuracy: 0.7786 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5279 - accuracy: 0.7582 - val_loss: 0.4902 - val_accuracy: 0.7726 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5291 - accuracy: 0.7623 - val_loss: 0.5298 - val_accuracy: 0.7591 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5273 - accuracy: 0.7520 - val_loss: 0.4910 - val_accuracy: 0.7738 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5285 - accuracy: 0.7540 - val_loss: 0.5282 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5254 - accuracy: 0.7607 - val_loss: 0.4685 - val_accuracy: 0.7828 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5232 - accuracy: 0.7601 - val_loss: 0.4849 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5218 - accuracy: 0.7580 - val_loss: 0.5416 - val_accuracy: 0.7647 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5236 - accuracy: 0.7574 - val_loss: 0.4844 - val_accuracy: 0.7774 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5165 - accuracy: 0.7680 - val_loss: 0.4576 - val_accuracy: 0.7908 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5222 - accuracy: 0.7596 - val_loss: 0.5199 - val_accuracy: 0.7702 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5215 - accuracy: 0.7605 - val_loss: 0.4833 - val_accuracy: 0.7810 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5161 - accuracy: 0.7658 - val_loss: 0.4940 - val_accuracy: 0.7758 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5035 - accuracy: 0.7753 - val_loss: 0.4909 - val_accuracy: 0.7780 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5043 - accuracy: 0.7707 - val_loss: 0.4901 - val_accuracy: 0.7786 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5134 - accuracy: 0.7641 - val_loss: 0.4837 - val_accuracy: 0.7824 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5103 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5139 - accuracy: 0.7688 - val_loss: 0.4860 - val_accuracy: 0.7810 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5085 - accuracy: 0.7649 - val_loss: 0.4798 - val_accuracy: 0.7822 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5098 - accuracy: 0.7661 - val_loss: 0.4826 - val_accuracy: 0.7830 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5099 - accuracy: 0.7658 - val_loss: 0.4874 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5042 - accuracy: 0.7721 - val_loss: 0.4758 - val_accuracy: 0.7836 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5069 - accuracy: 0.7667 - val_loss: 0.4769 - val_accuracy: 0.7830 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5085 - accuracy: 0.7666 - val_loss: 0.4776 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5061 - accuracy: 0.7708 - val_loss: 0.4781 - val_accuracy: 0.7828 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5004 - accuracy: 0.7731 - val_loss: 0.4795 - val_accuracy: 0.7824 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5049 - accuracy: 0.7703 - val_loss: 0.4778 - val_accuracy: 0.7832 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5073 - accuracy: 0.7699 - val_loss: 0.4783 - val_accuracy: 0.7828 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5109 - accuracy: 0.7655 - val_loss: 0.4780 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5075 - accuracy: 0.7638 - val_loss: 0.4781 - val_accuracy: 0.7838 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5093 - accuracy: 0.7684 - val_loss: 0.4785 - val_accuracy: 0.7830 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5027 - accuracy: 0.7727 - val_loss: 0.4800 - val_accuracy: 0.7822 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5064 - accuracy: 0.7701 - val_loss: 0.4791 - val_accuracy: 0.7832 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5126 - accuracy: 0.7690 - val_loss: 0.4788 - val_accuracy: 0.7830 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5033 - accuracy: 0.7722 - val_loss: 0.4770 - val_accuracy: 0.7838 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5058 - accuracy: 0.7696 - val_loss: 0.4786 - val_accuracy: 0.7828 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.5070 - accuracy: 0.7684 - val_loss: 0.4782 - val_accuracy: 0.7828 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.5082 - accuracy: 0.7673 - val_loss: 0.4776 - val_accuracy: 0.7832 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.5089 - accuracy: 0.7733 - val_loss: 0.4766 - val_accuracy: 0.7842 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5068 - accuracy: 0.7721 - val_loss: 0.4770 - val_accuracy: 0.7838 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5043 - accuracy: 0.7704 - val_loss: 0.4784 - val_accuracy: 0.7834 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 4s 7ms/step - loss: 0.4361 - accuracy: 0.8116\n",
      "17/17 [==============================] - 1s 7ms/step\n",
      "TP:4062, TN:9692, FP:763, FN:2429, loss0.4361422657966614, acc0.8116369644753925, sn0.6257895547681405, sp0.9270205643232903, f10.7179215270413574, auc0.8956897314539406\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 13s 33ms/step - loss: 0.9370 - accuracy: 0.5568 - val_loss: 0.8676 - val_accuracy: 0.5644 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.8560 - accuracy: 0.5893 - val_loss: 0.8693 - val_accuracy: 0.5279 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.8153 - accuracy: 0.6017 - val_loss: 0.8442 - val_accuracy: 0.5146 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7824 - accuracy: 0.6084 - val_loss: 0.8234 - val_accuracy: 0.5403 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.7595 - accuracy: 0.6148 - val_loss: 0.8127 - val_accuracy: 0.5150 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.7347 - accuracy: 0.6223 - val_loss: 0.8130 - val_accuracy: 0.4539 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7153 - accuracy: 0.6302 - val_loss: 0.7954 - val_accuracy: 0.4771 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6999 - accuracy: 0.6371 - val_loss: 0.7716 - val_accuracy: 0.5132 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6892 - accuracy: 0.6394 - val_loss: 0.7715 - val_accuracy: 0.4944 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6808 - accuracy: 0.6371 - val_loss: 0.7559 - val_accuracy: 0.5217 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6687 - accuracy: 0.6467 - val_loss: 0.7771 - val_accuracy: 0.4765 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6576 - accuracy: 0.6524 - val_loss: 0.7507 - val_accuracy: 0.5333 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6517 - accuracy: 0.6547 - val_loss: 0.7501 - val_accuracy: 0.5174 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.6480 - accuracy: 0.6600 - val_loss: 0.6920 - val_accuracy: 0.6043 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6409 - accuracy: 0.6640 - val_loss: 0.7350 - val_accuracy: 0.5411 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6363 - accuracy: 0.6659 - val_loss: 0.7228 - val_accuracy: 0.5588 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6332 - accuracy: 0.6677 - val_loss: 0.7190 - val_accuracy: 0.5660 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6281 - accuracy: 0.6700 - val_loss: 0.7461 - val_accuracy: 0.5247 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6217 - accuracy: 0.6785 - val_loss: 0.7801 - val_accuracy: 0.5110 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6204 - accuracy: 0.6784 - val_loss: 0.7552 - val_accuracy: 0.5367 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6166 - accuracy: 0.6812 - val_loss: 0.7098 - val_accuracy: 0.5696 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.6118 - accuracy: 0.6799 - val_loss: 0.6611 - val_accuracy: 0.6260 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6099 - accuracy: 0.6848 - val_loss: 0.7041 - val_accuracy: 0.5748 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6035 - accuracy: 0.6912 - val_loss: 0.7776 - val_accuracy: 0.5146 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6028 - accuracy: 0.6942 - val_loss: 0.6519 - val_accuracy: 0.6292 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5977 - accuracy: 0.6989 - val_loss: 0.6485 - val_accuracy: 0.6340 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5962 - accuracy: 0.6937 - val_loss: 0.6717 - val_accuracy: 0.6047 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5925 - accuracy: 0.7009 - val_loss: 0.6462 - val_accuracy: 0.6366 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5889 - accuracy: 0.7038 - val_loss: 0.6577 - val_accuracy: 0.6262 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5872 - accuracy: 0.7049 - val_loss: 0.6508 - val_accuracy: 0.6344 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5888 - accuracy: 0.7071 - val_loss: 0.6195 - val_accuracy: 0.6643 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5853 - accuracy: 0.7046 - val_loss: 0.6435 - val_accuracy: 0.6414 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5834 - accuracy: 0.7065 - val_loss: 0.6416 - val_accuracy: 0.6370 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5784 - accuracy: 0.7104 - val_loss: 0.5854 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5815 - accuracy: 0.7073 - val_loss: 0.6554 - val_accuracy: 0.6247 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.5748 - accuracy: 0.7144 - val_loss: 0.6508 - val_accuracy: 0.6258 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5792 - accuracy: 0.7131 - val_loss: 0.6165 - val_accuracy: 0.6665 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5758 - accuracy: 0.7175 - val_loss: 0.6102 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5734 - accuracy: 0.7133 - val_loss: 0.5635 - val_accuracy: 0.7210 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5779 - accuracy: 0.7127 - val_loss: 0.5931 - val_accuracy: 0.6895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5708 - accuracy: 0.7212 - val_loss: 0.6043 - val_accuracy: 0.6687 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5711 - accuracy: 0.7183 - val_loss: 0.5680 - val_accuracy: 0.7172 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5628 - accuracy: 0.7256 - val_loss: 0.6253 - val_accuracy: 0.6572 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5703 - accuracy: 0.7195 - val_loss: 0.5532 - val_accuracy: 0.7212 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5681 - accuracy: 0.7186 - val_loss: 0.5450 - val_accuracy: 0.7429 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5635 - accuracy: 0.7222 - val_loss: 0.5797 - val_accuracy: 0.7016 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5644 - accuracy: 0.7220 - val_loss: 0.5682 - val_accuracy: 0.7146 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5653 - accuracy: 0.7232 - val_loss: 0.5570 - val_accuracy: 0.7310 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5655 - accuracy: 0.7202 - val_loss: 0.5705 - val_accuracy: 0.7210 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5648 - accuracy: 0.7241 - val_loss: 0.6093 - val_accuracy: 0.6779 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5601 - accuracy: 0.7243 - val_loss: 0.5516 - val_accuracy: 0.7345 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5613 - accuracy: 0.7247 - val_loss: 0.5416 - val_accuracy: 0.7497 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5560 - accuracy: 0.7296 - val_loss: 0.5473 - val_accuracy: 0.7421 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5618 - accuracy: 0.7249 - val_loss: 0.5206 - val_accuracy: 0.7643 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5568 - accuracy: 0.7277 - val_loss: 0.5346 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5555 - accuracy: 0.7255 - val_loss: 0.5657 - val_accuracy: 0.7208 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5571 - accuracy: 0.7232 - val_loss: 0.5516 - val_accuracy: 0.7286 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5561 - accuracy: 0.7295 - val_loss: 0.5286 - val_accuracy: 0.7509 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5566 - accuracy: 0.7233 - val_loss: 0.5491 - val_accuracy: 0.7347 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5514 - accuracy: 0.7319 - val_loss: 0.5034 - val_accuracy: 0.7637 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5534 - accuracy: 0.7355 - val_loss: 0.5042 - val_accuracy: 0.7665 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5467 - accuracy: 0.7407 - val_loss: 0.5269 - val_accuracy: 0.7573 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5496 - accuracy: 0.7337 - val_loss: 0.5287 - val_accuracy: 0.7605 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5503 - accuracy: 0.7326 - val_loss: 0.5326 - val_accuracy: 0.7529 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5496 - accuracy: 0.7360 - val_loss: 0.5349 - val_accuracy: 0.7519 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5491 - accuracy: 0.7372 - val_loss: 0.5478 - val_accuracy: 0.7469 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5428 - accuracy: 0.7373 - val_loss: 0.5194 - val_accuracy: 0.7659 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5479 - accuracy: 0.7361 - val_loss: 0.4969 - val_accuracy: 0.7758 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5444 - accuracy: 0.7398 - val_loss: 0.4831 - val_accuracy: 0.7812 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5447 - accuracy: 0.7401 - val_loss: 0.5407 - val_accuracy: 0.7599 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5451 - accuracy: 0.7401 - val_loss: 0.4986 - val_accuracy: 0.7627 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5427 - accuracy: 0.7390 - val_loss: 0.4964 - val_accuracy: 0.7746 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5457 - accuracy: 0.7362 - val_loss: 0.4860 - val_accuracy: 0.7782 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5388 - accuracy: 0.7447 - val_loss: 0.4881 - val_accuracy: 0.7804 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5328 - accuracy: 0.7471 - val_loss: 0.4881 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5334 - accuracy: 0.7488 - val_loss: 0.4851 - val_accuracy: 0.7804 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5398 - accuracy: 0.7398 - val_loss: 0.4843 - val_accuracy: 0.7820 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5383 - accuracy: 0.7431 - val_loss: 0.4800 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5322 - accuracy: 0.7483 - val_loss: 0.4890 - val_accuracy: 0.7836 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5319 - accuracy: 0.7478 - val_loss: 0.4818 - val_accuracy: 0.7832 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5353 - accuracy: 0.7428 - val_loss: 0.4803 - val_accuracy: 0.7820 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5322 - accuracy: 0.7470 - val_loss: 0.4805 - val_accuracy: 0.7826 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5306 - accuracy: 0.7471 - val_loss: 0.4808 - val_accuracy: 0.7830 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5338 - accuracy: 0.7454 - val_loss: 0.4814 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5320 - accuracy: 0.7455 - val_loss: 0.4814 - val_accuracy: 0.7838 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5311 - accuracy: 0.7483 - val_loss: 0.4809 - val_accuracy: 0.7818 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5356 - accuracy: 0.7463 - val_loss: 0.4808 - val_accuracy: 0.7822 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5318 - accuracy: 0.7497 - val_loss: 0.4807 - val_accuracy: 0.7816 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5302 - accuracy: 0.7484 - val_loss: 0.4805 - val_accuracy: 0.7812 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.5285 - accuracy: 0.7499 - val_loss: 0.4813 - val_accuracy: 0.7826 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5304 - accuracy: 0.7498 - val_loss: 0.4817 - val_accuracy: 0.7828 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5324 - accuracy: 0.7464 - val_loss: 0.4810 - val_accuracy: 0.7820 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.5332 - accuracy: 0.7486 - val_loss: 0.4811 - val_accuracy: 0.7812 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5335 - accuracy: 0.7523 - val_loss: 0.4811 - val_accuracy: 0.7816 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5303 - accuracy: 0.7479 - val_loss: 0.4809 - val_accuracy: 0.7806 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5276 - accuracy: 0.7529 - val_loss: 0.4810 - val_accuracy: 0.7824 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.5284 - accuracy: 0.7489 - val_loss: 0.4809 - val_accuracy: 0.7828 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.5332 - accuracy: 0.7548 - val_loss: 0.4812 - val_accuracy: 0.7826 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5310 - accuracy: 0.7471 - val_loss: 0.4810 - val_accuracy: 0.7818 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5377 - accuracy: 0.7417 - val_loss: 0.4812 - val_accuracy: 0.7826 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 4s 8ms/step - loss: 0.4475 - accuracy: 0.8051\n",
      "17/17 [==============================] - 1s 6ms/step\n",
      "TP:4633, TN:9010, FP:1445, FN:1858, loss0.44753873348236084, acc0.805086746134781, sn0.713757510399014, sp0.8617886178861789, f10.7372105975017901, auc0.8757338583290951\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 13s 32ms/step - loss: 0.9181 - accuracy: 0.5793 - val_loss: 0.9098 - val_accuracy: 0.4108 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.8455 - accuracy: 0.6004 - val_loss: 0.9066 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.8063 - accuracy: 0.6059 - val_loss: 0.8713 - val_accuracy: 0.4069 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.7760 - accuracy: 0.6076 - val_loss: 0.8364 - val_accuracy: 0.4242 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.7535 - accuracy: 0.6218 - val_loss: 0.8014 - val_accuracy: 0.5501 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7293 - accuracy: 0.6274 - val_loss: 0.7772 - val_accuracy: 0.5566 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7123 - accuracy: 0.6292 - val_loss: 0.7710 - val_accuracy: 0.5391 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6990 - accuracy: 0.6383 - val_loss: 0.7777 - val_accuracy: 0.5050 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6837 - accuracy: 0.6442 - val_loss: 0.7688 - val_accuracy: 0.5211 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6731 - accuracy: 0.6508 - val_loss: 0.7620 - val_accuracy: 0.5136 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6629 - accuracy: 0.6570 - val_loss: 0.7246 - val_accuracy: 0.5666 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6541 - accuracy: 0.6540 - val_loss: 0.7420 - val_accuracy: 0.5453 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6532 - accuracy: 0.6543 - val_loss: 0.7331 - val_accuracy: 0.5507 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6448 - accuracy: 0.6626 - val_loss: 0.7387 - val_accuracy: 0.5401 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6405 - accuracy: 0.6683 - val_loss: 0.8200 - val_accuracy: 0.4801 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6345 - accuracy: 0.6695 - val_loss: 0.7512 - val_accuracy: 0.5345 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6339 - accuracy: 0.6619 - val_loss: 0.7657 - val_accuracy: 0.5164 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6308 - accuracy: 0.6707 - val_loss: 0.7197 - val_accuracy: 0.5750 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6278 - accuracy: 0.6766 - val_loss: 0.7445 - val_accuracy: 0.5630 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6190 - accuracy: 0.6730 - val_loss: 0.6959 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6170 - accuracy: 0.6819 - val_loss: 0.7714 - val_accuracy: 0.5419 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6199 - accuracy: 0.6799 - val_loss: 0.7074 - val_accuracy: 0.5931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6174 - accuracy: 0.6792 - val_loss: 0.7817 - val_accuracy: 0.5245 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6175 - accuracy: 0.6794 - val_loss: 0.7463 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6143 - accuracy: 0.6823 - val_loss: 0.8137 - val_accuracy: 0.4970 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6126 - accuracy: 0.6793 - val_loss: 0.6722 - val_accuracy: 0.6181 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6038 - accuracy: 0.6887 - val_loss: 0.7285 - val_accuracy: 0.5630 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6056 - accuracy: 0.6866 - val_loss: 0.6758 - val_accuracy: 0.6143 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6028 - accuracy: 0.6935 - val_loss: 0.6903 - val_accuracy: 0.5921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5979 - accuracy: 0.6913 - val_loss: 0.7694 - val_accuracy: 0.5295 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5948 - accuracy: 0.6949 - val_loss: 0.8029 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5964 - accuracy: 0.6987 - val_loss: 0.5898 - val_accuracy: 0.6897 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6013 - accuracy: 0.6915 - val_loss: 0.6863 - val_accuracy: 0.5911 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5925 - accuracy: 0.7001 - val_loss: 0.6918 - val_accuracy: 0.5931 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5929 - accuracy: 0.6980 - val_loss: 0.6855 - val_accuracy: 0.6039 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5905 - accuracy: 0.7019 - val_loss: 0.6179 - val_accuracy: 0.6613 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5880 - accuracy: 0.7002 - val_loss: 0.6364 - val_accuracy: 0.6442 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5866 - accuracy: 0.7006 - val_loss: 0.6036 - val_accuracy: 0.6735 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5812 - accuracy: 0.7058 - val_loss: 0.6338 - val_accuracy: 0.6448 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5865 - accuracy: 0.7076 - val_loss: 0.6417 - val_accuracy: 0.6376 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5833 - accuracy: 0.7081 - val_loss: 0.6115 - val_accuracy: 0.6586 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5742 - accuracy: 0.7150 - val_loss: 0.5456 - val_accuracy: 0.7298 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5795 - accuracy: 0.7094 - val_loss: 0.5547 - val_accuracy: 0.7224 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5814 - accuracy: 0.7087 - val_loss: 0.5807 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5767 - accuracy: 0.7120 - val_loss: 0.5821 - val_accuracy: 0.6961 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5781 - accuracy: 0.7150 - val_loss: 0.7030 - val_accuracy: 0.6039 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5791 - accuracy: 0.7073 - val_loss: 0.5750 - val_accuracy: 0.7050 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5758 - accuracy: 0.7146 - val_loss: 0.5379 - val_accuracy: 0.7377 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5717 - accuracy: 0.7188 - val_loss: 0.6246 - val_accuracy: 0.6540 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5707 - accuracy: 0.7154 - val_loss: 0.5433 - val_accuracy: 0.7379 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5698 - accuracy: 0.7161 - val_loss: 0.6189 - val_accuracy: 0.6641 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5731 - accuracy: 0.7091 - val_loss: 0.5466 - val_accuracy: 0.7369 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5689 - accuracy: 0.7154 - val_loss: 0.5161 - val_accuracy: 0.7605 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5665 - accuracy: 0.7167 - val_loss: 0.5435 - val_accuracy: 0.7409 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5728 - accuracy: 0.7131 - val_loss: 0.5529 - val_accuracy: 0.7246 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5668 - accuracy: 0.7195 - val_loss: 0.5620 - val_accuracy: 0.7166 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5669 - accuracy: 0.7210 - val_loss: 0.5557 - val_accuracy: 0.7343 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5606 - accuracy: 0.7195 - val_loss: 0.5933 - val_accuracy: 0.6921 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5658 - accuracy: 0.7202 - val_loss: 0.5322 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5640 - accuracy: 0.7210 - val_loss: 0.5425 - val_accuracy: 0.7363 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5582 - accuracy: 0.7300 - val_loss: 0.5745 - val_accuracy: 0.7094 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5613 - accuracy: 0.7272 - val_loss: 0.5297 - val_accuracy: 0.7483 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5609 - accuracy: 0.7245 - val_loss: 0.5335 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5610 - accuracy: 0.7290 - val_loss: 0.5411 - val_accuracy: 0.7395 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5609 - accuracy: 0.7225 - val_loss: 0.5228 - val_accuracy: 0.7543 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5600 - accuracy: 0.7269 - val_loss: 0.5799 - val_accuracy: 0.6998 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5572 - accuracy: 0.7323 - val_loss: 0.5714 - val_accuracy: 0.7164 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5529 - accuracy: 0.7309 - val_loss: 0.5237 - val_accuracy: 0.7569 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5550 - accuracy: 0.7319 - val_loss: 0.5150 - val_accuracy: 0.7675 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5554 - accuracy: 0.7255 - val_loss: 0.5122 - val_accuracy: 0.7603 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5561 - accuracy: 0.7343 - val_loss: 0.5454 - val_accuracy: 0.7300 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5520 - accuracy: 0.7330 - val_loss: 0.5240 - val_accuracy: 0.7521 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5536 - accuracy: 0.7334 - val_loss: 0.5112 - val_accuracy: 0.7613 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5462 - accuracy: 0.7363 - val_loss: 0.5064 - val_accuracy: 0.7673 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5457 - accuracy: 0.7373 - val_loss: 0.5056 - val_accuracy: 0.7665 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5531 - accuracy: 0.7290 - val_loss: 0.5065 - val_accuracy: 0.7679 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5479 - accuracy: 0.7366 - val_loss: 0.5168 - val_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5413 - accuracy: 0.7387 - val_loss: 0.5161 - val_accuracy: 0.7601 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5444 - accuracy: 0.7399 - val_loss: 0.5101 - val_accuracy: 0.7627 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5441 - accuracy: 0.7402 - val_loss: 0.5108 - val_accuracy: 0.7619 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5474 - accuracy: 0.7331 - val_loss: 0.5080 - val_accuracy: 0.7671 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5380 - accuracy: 0.7428 - val_loss: 0.5060 - val_accuracy: 0.7682 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5440 - accuracy: 0.7401 - val_loss: 0.5049 - val_accuracy: 0.7688 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5458 - accuracy: 0.7355 - val_loss: 0.5041 - val_accuracy: 0.7696 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5471 - accuracy: 0.7360 - val_loss: 0.5036 - val_accuracy: 0.7698 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5437 - accuracy: 0.7364 - val_loss: 0.5032 - val_accuracy: 0.7706 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5485 - accuracy: 0.7354 - val_loss: 0.5033 - val_accuracy: 0.7708 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5455 - accuracy: 0.7371 - val_loss: 0.5042 - val_accuracy: 0.7677 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5405 - accuracy: 0.7414 - val_loss: 0.5040 - val_accuracy: 0.7692 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5424 - accuracy: 0.7387 - val_loss: 0.5042 - val_accuracy: 0.7680 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5455 - accuracy: 0.7398 - val_loss: 0.5044 - val_accuracy: 0.7686 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5409 - accuracy: 0.7400 - val_loss: 0.5039 - val_accuracy: 0.7694 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5412 - accuracy: 0.7407 - val_loss: 0.5036 - val_accuracy: 0.7700 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5425 - accuracy: 0.7405 - val_loss: 0.5041 - val_accuracy: 0.7690 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5431 - accuracy: 0.7381 - val_loss: 0.5040 - val_accuracy: 0.7690 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5384 - accuracy: 0.7473 - val_loss: 0.5040 - val_accuracy: 0.7686 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5382 - accuracy: 0.7438 - val_loss: 0.5042 - val_accuracy: 0.7684 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5470 - accuracy: 0.7331 - val_loss: 0.5043 - val_accuracy: 0.7692 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5428 - accuracy: 0.7386 - val_loss: 0.5039 - val_accuracy: 0.7700 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5451 - accuracy: 0.7407 - val_loss: 0.5037 - val_accuracy: 0.7700 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 4s 8ms/step - loss: 0.4720 - accuracy: 0.7884\n",
      "17/17 [==============================] - 1s 6ms/step\n",
      "TP:4709, TN:8651, FP:1804, FN:1782, loss0.4719756841659546, acc0.7883866399150242, sn0.7254660298875366, sp0.8274509803921568, f10.724238695785912, auc0.857426590958706\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 13s 33ms/step - loss: 0.9304 - accuracy: 0.5689 - val_loss: 0.8694 - val_accuracy: 0.5790 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.8570 - accuracy: 0.5906 - val_loss: 0.8637 - val_accuracy: 0.5447 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.8109 - accuracy: 0.5969 - val_loss: 0.8483 - val_accuracy: 0.5048 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.7810 - accuracy: 0.6049 - val_loss: 0.8206 - val_accuracy: 0.5213 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7594 - accuracy: 0.6032 - val_loss: 0.7974 - val_accuracy: 0.5319 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7352 - accuracy: 0.6025 - val_loss: 0.7758 - val_accuracy: 0.5724 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.7176 - accuracy: 0.6086 - val_loss: 0.7590 - val_accuracy: 0.5834 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7016 - accuracy: 0.6211 - val_loss: 0.7374 - val_accuracy: 0.5983 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6870 - accuracy: 0.6288 - val_loss: 0.7274 - val_accuracy: 0.6017 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6767 - accuracy: 0.6377 - val_loss: 0.7364 - val_accuracy: 0.5447 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6657 - accuracy: 0.6370 - val_loss: 0.7368 - val_accuracy: 0.5253 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.6625 - accuracy: 0.6429 - val_loss: 0.7150 - val_accuracy: 0.5680 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6529 - accuracy: 0.6487 - val_loss: 0.7052 - val_accuracy: 0.5714 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6455 - accuracy: 0.6585 - val_loss: 0.7289 - val_accuracy: 0.5441 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6429 - accuracy: 0.6537 - val_loss: 0.7263 - val_accuracy: 0.5291 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6368 - accuracy: 0.6613 - val_loss: 0.7150 - val_accuracy: 0.5527 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6257 - accuracy: 0.6695 - val_loss: 0.7231 - val_accuracy: 0.5491 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6281 - accuracy: 0.6700 - val_loss: 0.7536 - val_accuracy: 0.5150 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6235 - accuracy: 0.6732 - val_loss: 0.7286 - val_accuracy: 0.5497 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6180 - accuracy: 0.6817 - val_loss: 0.6460 - val_accuracy: 0.6436 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6140 - accuracy: 0.6802 - val_loss: 0.7098 - val_accuracy: 0.5674 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6088 - accuracy: 0.6865 - val_loss: 0.7125 - val_accuracy: 0.5483 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6119 - accuracy: 0.6819 - val_loss: 0.7084 - val_accuracy: 0.5620 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 3s 31ms/step - loss: 0.6028 - accuracy: 0.6951 - val_loss: 0.7061 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5964 - accuracy: 0.6978 - val_loss: 0.6938 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5999 - accuracy: 0.6932 - val_loss: 0.7796 - val_accuracy: 0.5062 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5934 - accuracy: 0.7007 - val_loss: 0.6818 - val_accuracy: 0.5868 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5934 - accuracy: 0.7009 - val_loss: 0.6657 - val_accuracy: 0.6019 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5936 - accuracy: 0.7010 - val_loss: 0.6249 - val_accuracy: 0.6532 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5890 - accuracy: 0.7049 - val_loss: 0.6200 - val_accuracy: 0.6594 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5864 - accuracy: 0.7140 - val_loss: 0.6135 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5850 - accuracy: 0.7104 - val_loss: 0.6036 - val_accuracy: 0.6827 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5809 - accuracy: 0.7148 - val_loss: 0.6879 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5804 - accuracy: 0.7101 - val_loss: 0.5854 - val_accuracy: 0.7102 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5788 - accuracy: 0.7140 - val_loss: 0.6504 - val_accuracy: 0.6256 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5805 - accuracy: 0.7084 - val_loss: 0.5973 - val_accuracy: 0.6827 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5733 - accuracy: 0.7190 - val_loss: 0.5814 - val_accuracy: 0.7098 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5737 - accuracy: 0.7174 - val_loss: 0.5456 - val_accuracy: 0.7439 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5694 - accuracy: 0.7195 - val_loss: 0.5861 - val_accuracy: 0.7046 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5619 - accuracy: 0.7222 - val_loss: 0.5397 - val_accuracy: 0.7569 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5758 - accuracy: 0.7154 - val_loss: 0.5382 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5695 - accuracy: 0.7194 - val_loss: 0.6883 - val_accuracy: 0.5893 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5671 - accuracy: 0.7236 - val_loss: 0.5810 - val_accuracy: 0.7194 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5706 - accuracy: 0.7248 - val_loss: 0.5306 - val_accuracy: 0.7625 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5645 - accuracy: 0.7276 - val_loss: 0.5813 - val_accuracy: 0.7124 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5655 - accuracy: 0.7242 - val_loss: 0.5225 - val_accuracy: 0.7712 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5589 - accuracy: 0.7301 - val_loss: 0.5433 - val_accuracy: 0.7549 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5623 - accuracy: 0.7322 - val_loss: 0.5539 - val_accuracy: 0.7325 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5561 - accuracy: 0.7319 - val_loss: 0.5275 - val_accuracy: 0.7673 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5537 - accuracy: 0.7313 - val_loss: 0.5541 - val_accuracy: 0.7507 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5582 - accuracy: 0.7289 - val_loss: 0.4947 - val_accuracy: 0.7804 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5525 - accuracy: 0.7341 - val_loss: 0.5360 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5521 - accuracy: 0.7343 - val_loss: 0.5383 - val_accuracy: 0.7585 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5517 - accuracy: 0.7348 - val_loss: 0.5378 - val_accuracy: 0.7593 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5548 - accuracy: 0.7337 - val_loss: 0.5013 - val_accuracy: 0.7712 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5491 - accuracy: 0.7369 - val_loss: 0.5051 - val_accuracy: 0.7796 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5470 - accuracy: 0.7395 - val_loss: 0.5083 - val_accuracy: 0.7704 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5468 - accuracy: 0.7415 - val_loss: 0.4930 - val_accuracy: 0.7798 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5411 - accuracy: 0.7412 - val_loss: 0.4903 - val_accuracy: 0.7798 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5409 - accuracy: 0.7421 - val_loss: 0.4994 - val_accuracy: 0.7828 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5394 - accuracy: 0.7438 - val_loss: 0.4728 - val_accuracy: 0.7866 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5398 - accuracy: 0.7433 - val_loss: 0.4863 - val_accuracy: 0.7918 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5378 - accuracy: 0.7512 - val_loss: 0.4889 - val_accuracy: 0.7900 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5427 - accuracy: 0.7407 - val_loss: 0.4768 - val_accuracy: 0.7818 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5319 - accuracy: 0.7506 - val_loss: 0.4610 - val_accuracy: 0.8020 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5352 - accuracy: 0.7447 - val_loss: 0.4684 - val_accuracy: 0.7842 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5321 - accuracy: 0.7531 - val_loss: 0.4883 - val_accuracy: 0.7710 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5338 - accuracy: 0.7519 - val_loss: 0.5020 - val_accuracy: 0.7708 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5283 - accuracy: 0.7483 - val_loss: 0.4773 - val_accuracy: 0.7836 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5257 - accuracy: 0.7537 - val_loss: 0.4736 - val_accuracy: 0.7906 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5295 - accuracy: 0.7482 - val_loss: 0.4609 - val_accuracy: 0.8002 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5225 - accuracy: 0.7572 - val_loss: 0.4514 - val_accuracy: 0.8006 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5214 - accuracy: 0.7567 - val_loss: 0.4536 - val_accuracy: 0.7994 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5182 - accuracy: 0.7585 - val_loss: 0.4533 - val_accuracy: 0.7978 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5265 - accuracy: 0.7538 - val_loss: 0.4520 - val_accuracy: 0.8036 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5197 - accuracy: 0.7564 - val_loss: 0.4516 - val_accuracy: 0.8010 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5207 - accuracy: 0.7599 - val_loss: 0.4552 - val_accuracy: 0.7964 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5176 - accuracy: 0.7556 - val_loss: 0.4521 - val_accuracy: 0.8043 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5199 - accuracy: 0.7603 - val_loss: 0.4526 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5155 - accuracy: 0.7635 - val_loss: 0.4523 - val_accuracy: 0.8006 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5237 - accuracy: 0.7555 - val_loss: 0.4518 - val_accuracy: 0.8010 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5135 - accuracy: 0.7647 - val_loss: 0.4504 - val_accuracy: 0.8028 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5165 - accuracy: 0.7617 - val_loss: 0.4498 - val_accuracy: 0.8041 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5180 - accuracy: 0.7525 - val_loss: 0.4498 - val_accuracy: 0.8047 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5174 - accuracy: 0.7611 - val_loss: 0.4499 - val_accuracy: 0.8049 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5150 - accuracy: 0.7595 - val_loss: 0.4496 - val_accuracy: 0.8049 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5213 - accuracy: 0.7566 - val_loss: 0.4495 - val_accuracy: 0.8051 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5121 - accuracy: 0.7658 - val_loss: 0.4500 - val_accuracy: 0.8047 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5214 - accuracy: 0.7584 - val_loss: 0.4499 - val_accuracy: 0.8053 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5165 - accuracy: 0.7596 - val_loss: 0.4500 - val_accuracy: 0.8041 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5166 - accuracy: 0.7618 - val_loss: 0.4501 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5183 - accuracy: 0.7620 - val_loss: 0.4499 - val_accuracy: 0.8043 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5160 - accuracy: 0.7601 - val_loss: 0.4496 - val_accuracy: 0.8041 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5113 - accuracy: 0.7657 - val_loss: 0.4500 - val_accuracy: 0.8047 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5122 - accuracy: 0.7678 - val_loss: 0.4500 - val_accuracy: 0.8041 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5111 - accuracy: 0.7627 - val_loss: 0.4497 - val_accuracy: 0.8041 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5162 - accuracy: 0.7633 - val_loss: 0.4497 - val_accuracy: 0.8049 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5084 - accuracy: 0.7647 - val_loss: 0.4495 - val_accuracy: 0.8047 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5114 - accuracy: 0.7636 - val_loss: 0.4498 - val_accuracy: 0.8036 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5186 - accuracy: 0.7602 - val_loss: 0.4498 - val_accuracy: 0.8043 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 4s 8ms/step - loss: 0.4147 - accuracy: 0.8201\n",
      "17/17 [==============================] - 1s 6ms/step\n",
      "TP:4615, TN:9283, FP:1172, FN:1876, loss0.41473716497421265, acc0.8201345450253748, sn0.7109844399938376, sp0.8879005260640842, f10.7517510995276103, auc0.8955351562451075\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 13s 32ms/step - loss: 0.9335 - accuracy: 0.5618 - val_loss: 0.8785 - val_accuracy: 0.5660 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.8530 - accuracy: 0.5895 - val_loss: 0.8837 - val_accuracy: 0.4747 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.8127 - accuracy: 0.6054 - val_loss: 0.8509 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7809 - accuracy: 0.6106 - val_loss: 0.8206 - val_accuracy: 0.5309 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7553 - accuracy: 0.6126 - val_loss: 0.7780 - val_accuracy: 0.5892 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7342 - accuracy: 0.6238 - val_loss: 0.7688 - val_accuracy: 0.5722 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7145 - accuracy: 0.6346 - val_loss: 0.7481 - val_accuracy: 0.6011 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7021 - accuracy: 0.6383 - val_loss: 0.7465 - val_accuracy: 0.5822 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6850 - accuracy: 0.6425 - val_loss: 0.7365 - val_accuracy: 0.5977 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6736 - accuracy: 0.6491 - val_loss: 0.7302 - val_accuracy: 0.5878 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6655 - accuracy: 0.6501 - val_loss: 0.7783 - val_accuracy: 0.4888 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6566 - accuracy: 0.6562 - val_loss: 0.7296 - val_accuracy: 0.5570 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6513 - accuracy: 0.6595 - val_loss: 0.7388 - val_accuracy: 0.5538 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6439 - accuracy: 0.6621 - val_loss: 0.7224 - val_accuracy: 0.5710 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6381 - accuracy: 0.6677 - val_loss: 0.7454 - val_accuracy: 0.5285 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.6377 - accuracy: 0.6660 - val_loss: 0.7003 - val_accuracy: 0.5915 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6316 - accuracy: 0.6713 - val_loss: 0.7279 - val_accuracy: 0.5686 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6298 - accuracy: 0.6683 - val_loss: 0.7350 - val_accuracy: 0.5379 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6245 - accuracy: 0.6764 - val_loss: 0.6628 - val_accuracy: 0.6408 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6195 - accuracy: 0.6813 - val_loss: 0.6892 - val_accuracy: 0.6071 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6174 - accuracy: 0.6867 - val_loss: 0.6814 - val_accuracy: 0.6037 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6131 - accuracy: 0.6860 - val_loss: 0.6993 - val_accuracy: 0.5738 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6091 - accuracy: 0.6905 - val_loss: 0.6244 - val_accuracy: 0.6611 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6093 - accuracy: 0.6891 - val_loss: 0.6506 - val_accuracy: 0.6426 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6044 - accuracy: 0.6937 - val_loss: 0.6627 - val_accuracy: 0.6155 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6015 - accuracy: 0.6970 - val_loss: 0.5943 - val_accuracy: 0.7048 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5994 - accuracy: 0.6926 - val_loss: 0.6320 - val_accuracy: 0.6572 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5928 - accuracy: 0.6987 - val_loss: 0.6560 - val_accuracy: 0.6183 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5904 - accuracy: 0.7013 - val_loss: 0.6600 - val_accuracy: 0.6249 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5910 - accuracy: 0.7053 - val_loss: 0.6745 - val_accuracy: 0.6081 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5838 - accuracy: 0.7105 - val_loss: 0.6618 - val_accuracy: 0.6298 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5911 - accuracy: 0.7014 - val_loss: 0.6300 - val_accuracy: 0.6516 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5882 - accuracy: 0.7078 - val_loss: 0.6477 - val_accuracy: 0.6316 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5854 - accuracy: 0.7103 - val_loss: 0.5979 - val_accuracy: 0.7006 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5818 - accuracy: 0.7071 - val_loss: 0.6096 - val_accuracy: 0.6949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5792 - accuracy: 0.7117 - val_loss: 0.5944 - val_accuracy: 0.6949 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5775 - accuracy: 0.7178 - val_loss: 0.5841 - val_accuracy: 0.7080 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5793 - accuracy: 0.7117 - val_loss: 0.6384 - val_accuracy: 0.6350 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5757 - accuracy: 0.7128 - val_loss: 0.5754 - val_accuracy: 0.7192 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5735 - accuracy: 0.7183 - val_loss: 0.5991 - val_accuracy: 0.6955 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5670 - accuracy: 0.7193 - val_loss: 0.5871 - val_accuracy: 0.7026 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5703 - accuracy: 0.7207 - val_loss: 0.5317 - val_accuracy: 0.7483 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5654 - accuracy: 0.7205 - val_loss: 0.5542 - val_accuracy: 0.7325 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5659 - accuracy: 0.7195 - val_loss: 0.5508 - val_accuracy: 0.7479 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5667 - accuracy: 0.7199 - val_loss: 0.5381 - val_accuracy: 0.7557 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5606 - accuracy: 0.7309 - val_loss: 0.5630 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5653 - accuracy: 0.7289 - val_loss: 0.5353 - val_accuracy: 0.7545 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5655 - accuracy: 0.7236 - val_loss: 0.5430 - val_accuracy: 0.7477 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5578 - accuracy: 0.7284 - val_loss: 0.5368 - val_accuracy: 0.7475 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5644 - accuracy: 0.7245 - val_loss: 0.5352 - val_accuracy: 0.7531 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5566 - accuracy: 0.7291 - val_loss: 0.5429 - val_accuracy: 0.7473 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5544 - accuracy: 0.7250 - val_loss: 0.5232 - val_accuracy: 0.7549 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5559 - accuracy: 0.7332 - val_loss: 0.5486 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5552 - accuracy: 0.7319 - val_loss: 0.5380 - val_accuracy: 0.7487 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5601 - accuracy: 0.7267 - val_loss: 0.5080 - val_accuracy: 0.7692 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5561 - accuracy: 0.7341 - val_loss: 0.5490 - val_accuracy: 0.7451 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5525 - accuracy: 0.7309 - val_loss: 0.5120 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5508 - accuracy: 0.7346 - val_loss: 0.5054 - val_accuracy: 0.7722 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.5447 - accuracy: 0.7433 - val_loss: 0.5027 - val_accuracy: 0.7690 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5432 - accuracy: 0.7413 - val_loss: 0.5099 - val_accuracy: 0.7665 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5453 - accuracy: 0.7437 - val_loss: 0.5109 - val_accuracy: 0.7684 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5453 - accuracy: 0.7389 - val_loss: 0.4918 - val_accuracy: 0.7718 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5448 - accuracy: 0.7417 - val_loss: 0.5133 - val_accuracy: 0.7603 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5461 - accuracy: 0.7408 - val_loss: 0.4898 - val_accuracy: 0.7780 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5442 - accuracy: 0.7402 - val_loss: 0.5039 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5367 - accuracy: 0.7447 - val_loss: 0.4945 - val_accuracy: 0.7758 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5418 - accuracy: 0.7478 - val_loss: 0.4972 - val_accuracy: 0.7714 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5402 - accuracy: 0.7485 - val_loss: 0.4876 - val_accuracy: 0.7820 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5356 - accuracy: 0.7507 - val_loss: 0.4810 - val_accuracy: 0.7856 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5338 - accuracy: 0.7504 - val_loss: 0.4928 - val_accuracy: 0.7734 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5356 - accuracy: 0.7470 - val_loss: 0.4859 - val_accuracy: 0.7810 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5319 - accuracy: 0.7551 - val_loss: 0.4874 - val_accuracy: 0.7766 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5229 - accuracy: 0.7571 - val_loss: 0.4848 - val_accuracy: 0.7786 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5253 - accuracy: 0.7572 - val_loss: 0.4850 - val_accuracy: 0.7794 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5350 - accuracy: 0.7514 - val_loss: 0.4832 - val_accuracy: 0.7796 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5302 - accuracy: 0.7552 - val_loss: 0.4804 - val_accuracy: 0.7810 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5252 - accuracy: 0.7547 - val_loss: 0.4811 - val_accuracy: 0.7782 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5243 - accuracy: 0.7546 - val_loss: 0.4769 - val_accuracy: 0.7832 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5238 - accuracy: 0.7599 - val_loss: 0.4773 - val_accuracy: 0.7836 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5247 - accuracy: 0.7554 - val_loss: 0.4788 - val_accuracy: 0.7822 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5268 - accuracy: 0.7522 - val_loss: 0.4798 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5280 - accuracy: 0.7537 - val_loss: 0.4785 - val_accuracy: 0.7800 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5265 - accuracy: 0.7566 - val_loss: 0.4783 - val_accuracy: 0.7808 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5247 - accuracy: 0.7578 - val_loss: 0.4798 - val_accuracy: 0.7796 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5217 - accuracy: 0.7553 - val_loss: 0.4780 - val_accuracy: 0.7806 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5301 - accuracy: 0.7521 - val_loss: 0.4778 - val_accuracy: 0.7802 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5218 - accuracy: 0.7590 - val_loss: 0.4783 - val_accuracy: 0.7798 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5175 - accuracy: 0.7622 - val_loss: 0.4782 - val_accuracy: 0.7796 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5266 - accuracy: 0.7556 - val_loss: 0.4788 - val_accuracy: 0.7800 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5233 - accuracy: 0.7553 - val_loss: 0.4773 - val_accuracy: 0.7816 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5218 - accuracy: 0.7566 - val_loss: 0.4797 - val_accuracy: 0.7800 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5252 - accuracy: 0.7578 - val_loss: 0.4792 - val_accuracy: 0.7804 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5262 - accuracy: 0.7531 - val_loss: 0.4784 - val_accuracy: 0.7806 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5217 - accuracy: 0.7607 - val_loss: 0.4787 - val_accuracy: 0.7800 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5315 - accuracy: 0.7481 - val_loss: 0.4782 - val_accuracy: 0.7802 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5216 - accuracy: 0.7566 - val_loss: 0.4781 - val_accuracy: 0.7800 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5239 - accuracy: 0.7543 - val_loss: 0.4792 - val_accuracy: 0.7800 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5192 - accuracy: 0.7658 - val_loss: 0.4797 - val_accuracy: 0.7798 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5214 - accuracy: 0.7560 - val_loss: 0.4792 - val_accuracy: 0.7800 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5206 - accuracy: 0.7583 - val_loss: 0.4787 - val_accuracy: 0.7802 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 4s 8ms/step - loss: 0.4418 - accuracy: 0.8028\n",
      "17/17 [==============================] - 1s 6ms/step\n",
      "TP:4084, TN:9520, FP:935, FN:2407, loss0.4418150782585144, acc0.8027853180691609, sn0.6291788630411339, sp0.9105691056910569, f10.7096437880104257, auc0.8838884815756002\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 14s 33ms/step - loss: 0.9240 - accuracy: 0.5666 - val_loss: 0.8671 - val_accuracy: 0.5822 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.8457 - accuracy: 0.5921 - val_loss: 0.8625 - val_accuracy: 0.5321 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.8030 - accuracy: 0.5971 - val_loss: 0.8421 - val_accuracy: 0.5144 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7758 - accuracy: 0.6081 - val_loss: 0.8090 - val_accuracy: 0.5714 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.7504 - accuracy: 0.6139 - val_loss: 0.7840 - val_accuracy: 0.6041 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7267 - accuracy: 0.6216 - val_loss: 0.7604 - val_accuracy: 0.6053 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.7100 - accuracy: 0.6286 - val_loss: 0.7656 - val_accuracy: 0.5473 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6931 - accuracy: 0.6409 - val_loss: 0.7381 - val_accuracy: 0.5790 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6809 - accuracy: 0.6478 - val_loss: 0.7305 - val_accuracy: 0.5800 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6650 - accuracy: 0.6606 - val_loss: 0.7446 - val_accuracy: 0.5439 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6597 - accuracy: 0.6588 - val_loss: 0.7093 - val_accuracy: 0.5901 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.6522 - accuracy: 0.6608 - val_loss: 0.7388 - val_accuracy: 0.5533 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6441 - accuracy: 0.6652 - val_loss: 0.7075 - val_accuracy: 0.5830 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6350 - accuracy: 0.6767 - val_loss: 0.7567 - val_accuracy: 0.5455 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6265 - accuracy: 0.6801 - val_loss: 0.6601 - val_accuracy: 0.6454 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6257 - accuracy: 0.6860 - val_loss: 0.7616 - val_accuracy: 0.5441 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6175 - accuracy: 0.6897 - val_loss: 0.7064 - val_accuracy: 0.5766 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6143 - accuracy: 0.6896 - val_loss: 0.7131 - val_accuracy: 0.5728 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6095 - accuracy: 0.6971 - val_loss: 0.6836 - val_accuracy: 0.6103 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6029 - accuracy: 0.6977 - val_loss: 0.7042 - val_accuracy: 0.5826 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5959 - accuracy: 0.7040 - val_loss: 0.7082 - val_accuracy: 0.5838 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5954 - accuracy: 0.7041 - val_loss: 0.6525 - val_accuracy: 0.6298 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5912 - accuracy: 0.7086 - val_loss: 0.6291 - val_accuracy: 0.6544 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5917 - accuracy: 0.7079 - val_loss: 0.5794 - val_accuracy: 0.7260 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5897 - accuracy: 0.7090 - val_loss: 0.6444 - val_accuracy: 0.6308 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5822 - accuracy: 0.7152 - val_loss: 0.6306 - val_accuracy: 0.6470 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5803 - accuracy: 0.7201 - val_loss: 0.5738 - val_accuracy: 0.7148 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5789 - accuracy: 0.7150 - val_loss: 0.5655 - val_accuracy: 0.7387 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5802 - accuracy: 0.7148 - val_loss: 0.5518 - val_accuracy: 0.7509 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5737 - accuracy: 0.7238 - val_loss: 0.5699 - val_accuracy: 0.7383 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5703 - accuracy: 0.7243 - val_loss: 0.5466 - val_accuracy: 0.7567 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5651 - accuracy: 0.7271 - val_loss: 0.5824 - val_accuracy: 0.7168 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5648 - accuracy: 0.7322 - val_loss: 0.5443 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.5663 - accuracy: 0.7303 - val_loss: 0.5763 - val_accuracy: 0.7278 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5594 - accuracy: 0.7319 - val_loss: 0.5311 - val_accuracy: 0.7557 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5601 - accuracy: 0.7329 - val_loss: 0.5735 - val_accuracy: 0.7200 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5594 - accuracy: 0.7307 - val_loss: 0.5247 - val_accuracy: 0.7631 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5605 - accuracy: 0.7318 - val_loss: 0.5605 - val_accuracy: 0.7445 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5532 - accuracy: 0.7373 - val_loss: 0.5413 - val_accuracy: 0.7515 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5540 - accuracy: 0.7354 - val_loss: 0.5142 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5547 - accuracy: 0.7360 - val_loss: 0.5132 - val_accuracy: 0.7679 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5453 - accuracy: 0.7436 - val_loss: 0.5151 - val_accuracy: 0.7609 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5499 - accuracy: 0.7400 - val_loss: 0.4896 - val_accuracy: 0.7782 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5464 - accuracy: 0.7405 - val_loss: 0.4962 - val_accuracy: 0.7756 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5485 - accuracy: 0.7350 - val_loss: 0.5088 - val_accuracy: 0.7679 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5444 - accuracy: 0.7426 - val_loss: 0.4989 - val_accuracy: 0.7724 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5406 - accuracy: 0.7475 - val_loss: 0.4958 - val_accuracy: 0.7724 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5398 - accuracy: 0.7485 - val_loss: 0.4818 - val_accuracy: 0.7860 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5386 - accuracy: 0.7519 - val_loss: 0.4859 - val_accuracy: 0.7828 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5357 - accuracy: 0.7490 - val_loss: 0.5070 - val_accuracy: 0.7651 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5322 - accuracy: 0.7525 - val_loss: 0.4838 - val_accuracy: 0.7792 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5320 - accuracy: 0.7482 - val_loss: 0.4856 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5362 - accuracy: 0.7480 - val_loss: 0.4752 - val_accuracy: 0.7834 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5314 - accuracy: 0.7525 - val_loss: 0.4693 - val_accuracy: 0.7818 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5315 - accuracy: 0.7525 - val_loss: 0.4739 - val_accuracy: 0.7834 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5260 - accuracy: 0.7573 - val_loss: 0.4683 - val_accuracy: 0.7820 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5245 - accuracy: 0.7576 - val_loss: 0.4755 - val_accuracy: 0.7898 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5273 - accuracy: 0.7573 - val_loss: 0.4668 - val_accuracy: 0.7926 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5253 - accuracy: 0.7537 - val_loss: 0.4933 - val_accuracy: 0.7714 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5271 - accuracy: 0.7511 - val_loss: 0.4636 - val_accuracy: 0.7904 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5213 - accuracy: 0.7572 - val_loss: 0.4638 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5223 - accuracy: 0.7596 - val_loss: 0.4587 - val_accuracy: 0.7934 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5261 - accuracy: 0.7578 - val_loss: 0.4657 - val_accuracy: 0.7804 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5247 - accuracy: 0.7544 - val_loss: 0.4566 - val_accuracy: 0.8004 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5247 - accuracy: 0.7537 - val_loss: 0.4647 - val_accuracy: 0.7928 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.5165 - accuracy: 0.7609 - val_loss: 0.4480 - val_accuracy: 0.8016 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5127 - accuracy: 0.7609 - val_loss: 0.4591 - val_accuracy: 0.7988 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5171 - accuracy: 0.7645 - val_loss: 0.4585 - val_accuracy: 0.7956 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5217 - accuracy: 0.7547 - val_loss: 0.5067 - val_accuracy: 0.7682 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5229 - accuracy: 0.7650 - val_loss: 0.4555 - val_accuracy: 0.7980 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5123 - accuracy: 0.7616 - val_loss: 0.4617 - val_accuracy: 0.7988 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5054 - accuracy: 0.7698 - val_loss: 0.4506 - val_accuracy: 0.8024 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5150 - accuracy: 0.7601 - val_loss: 0.4490 - val_accuracy: 0.8012 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5141 - accuracy: 0.7660 - val_loss: 0.4496 - val_accuracy: 0.8004 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5080 - accuracy: 0.7658 - val_loss: 0.4463 - val_accuracy: 0.8034 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5106 - accuracy: 0.7656 - val_loss: 0.4462 - val_accuracy: 0.8006 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5010 - accuracy: 0.7729 - val_loss: 0.4473 - val_accuracy: 0.8026 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.5134 - accuracy: 0.7696 - val_loss: 0.4454 - val_accuracy: 0.8032 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5012 - accuracy: 0.7689 - val_loss: 0.4491 - val_accuracy: 0.7986 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5099 - accuracy: 0.7683 - val_loss: 0.4475 - val_accuracy: 0.8008 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.4970 - accuracy: 0.7731 - val_loss: 0.4496 - val_accuracy: 0.7994 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5052 - accuracy: 0.7725 - val_loss: 0.4482 - val_accuracy: 0.7998 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.4993 - accuracy: 0.7731 - val_loss: 0.4483 - val_accuracy: 0.8002 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5046 - accuracy: 0.7716 - val_loss: 0.4477 - val_accuracy: 0.8004 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.4998 - accuracy: 0.7712 - val_loss: 0.4481 - val_accuracy: 0.8006 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5034 - accuracy: 0.7737 - val_loss: 0.4477 - val_accuracy: 0.8018 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5004 - accuracy: 0.7714 - val_loss: 0.4473 - val_accuracy: 0.8018 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5043 - accuracy: 0.7681 - val_loss: 0.4476 - val_accuracy: 0.8008 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5061 - accuracy: 0.7736 - val_loss: 0.4475 - val_accuracy: 0.8016 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5046 - accuracy: 0.7669 - val_loss: 0.4469 - val_accuracy: 0.8014 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5074 - accuracy: 0.7667 - val_loss: 0.4470 - val_accuracy: 0.8024 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5013 - accuracy: 0.7735 - val_loss: 0.4471 - val_accuracy: 0.8018 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5048 - accuracy: 0.7683 - val_loss: 0.4468 - val_accuracy: 0.8022 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5071 - accuracy: 0.7689 - val_loss: 0.4472 - val_accuracy: 0.8022 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5029 - accuracy: 0.7726 - val_loss: 0.4468 - val_accuracy: 0.8018 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5033 - accuracy: 0.7731 - val_loss: 0.4464 - val_accuracy: 0.8026 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5025 - accuracy: 0.7736 - val_loss: 0.4457 - val_accuracy: 0.8032 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.4973 - accuracy: 0.7778 - val_loss: 0.4461 - val_accuracy: 0.8037 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.4992 - accuracy: 0.7766 - val_loss: 0.4458 - val_accuracy: 0.8036 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5007 - accuracy: 0.7723 - val_loss: 0.4460 - val_accuracy: 0.8030 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 4s 8ms/step - loss: 0.4088 - accuracy: 0.8218\n",
      "17/17 [==============================] - 1s 7ms/step\n",
      "TP:4570, TN:9356, FP:1099, FN:1921, loss0.4087941646575928, acc0.821786852354538, sn0.7040517639808966, sp0.894882831181253, f10.7516447368421053, auc0.8980670141735445\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 13s 35ms/step - loss: 0.9623 - accuracy: 0.5528 - val_loss: 0.8684 - val_accuracy: 0.6031 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.8670 - accuracy: 0.5877 - val_loss: 0.8565 - val_accuracy: 0.5457 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.8216 - accuracy: 0.6012 - val_loss: 0.8354 - val_accuracy: 0.5441 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.7948 - accuracy: 0.5993 - val_loss: 0.8092 - val_accuracy: 0.5493 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.7675 - accuracy: 0.6090 - val_loss: 0.7865 - val_accuracy: 0.5682 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.7463 - accuracy: 0.6138 - val_loss: 0.7661 - val_accuracy: 0.5572 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.7240 - accuracy: 0.6162 - val_loss: 0.7433 - val_accuracy: 0.5915 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.7087 - accuracy: 0.6248 - val_loss: 0.7229 - val_accuracy: 0.6019 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6919 - accuracy: 0.6327 - val_loss: 0.7268 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.6776 - accuracy: 0.6440 - val_loss: 0.7274 - val_accuracy: 0.5690 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6709 - accuracy: 0.6506 - val_loss: 0.7234 - val_accuracy: 0.5700 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6589 - accuracy: 0.6593 - val_loss: 0.7208 - val_accuracy: 0.5648 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6485 - accuracy: 0.6609 - val_loss: 0.6844 - val_accuracy: 0.6201 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6432 - accuracy: 0.6653 - val_loss: 0.7737 - val_accuracy: 0.5048 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6386 - accuracy: 0.6659 - val_loss: 0.7198 - val_accuracy: 0.5792 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6332 - accuracy: 0.6737 - val_loss: 0.6540 - val_accuracy: 0.6424 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6260 - accuracy: 0.6801 - val_loss: 0.7074 - val_accuracy: 0.5760 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6154 - accuracy: 0.6875 - val_loss: 0.7459 - val_accuracy: 0.5459 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6127 - accuracy: 0.6916 - val_loss: 0.6588 - val_accuracy: 0.6213 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6052 - accuracy: 0.6963 - val_loss: 0.6521 - val_accuracy: 0.6282 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.6009 - accuracy: 0.7028 - val_loss: 0.7103 - val_accuracy: 0.5570 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5985 - accuracy: 0.7018 - val_loss: 0.7066 - val_accuracy: 0.5656 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5906 - accuracy: 0.7095 - val_loss: 0.6646 - val_accuracy: 0.6091 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5823 - accuracy: 0.7162 - val_loss: 0.6027 - val_accuracy: 0.6861 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5852 - accuracy: 0.7119 - val_loss: 0.6041 - val_accuracy: 0.6909 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5876 - accuracy: 0.7107 - val_loss: 0.6514 - val_accuracy: 0.6296 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5770 - accuracy: 0.7237 - val_loss: 0.5727 - val_accuracy: 0.7296 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5778 - accuracy: 0.7188 - val_loss: 0.5695 - val_accuracy: 0.7343 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5708 - accuracy: 0.7270 - val_loss: 0.5801 - val_accuracy: 0.7194 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5683 - accuracy: 0.7229 - val_loss: 0.6181 - val_accuracy: 0.6715 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5703 - accuracy: 0.7266 - val_loss: 0.5679 - val_accuracy: 0.7329 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5671 - accuracy: 0.7292 - val_loss: 0.5827 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5676 - accuracy: 0.7281 - val_loss: 0.5298 - val_accuracy: 0.7597 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5625 - accuracy: 0.7346 - val_loss: 0.5466 - val_accuracy: 0.7549 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5597 - accuracy: 0.7327 - val_loss: 0.5204 - val_accuracy: 0.7637 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5584 - accuracy: 0.7363 - val_loss: 0.5151 - val_accuracy: 0.7609 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5625 - accuracy: 0.7315 - val_loss: 0.5394 - val_accuracy: 0.7567 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5585 - accuracy: 0.7383 - val_loss: 0.5230 - val_accuracy: 0.7563 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5562 - accuracy: 0.7371 - val_loss: 0.5183 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5564 - accuracy: 0.7329 - val_loss: 0.5156 - val_accuracy: 0.7680 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5536 - accuracy: 0.7384 - val_loss: 0.5006 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.5437 - accuracy: 0.7404 - val_loss: 0.5102 - val_accuracy: 0.7870 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5449 - accuracy: 0.7426 - val_loss: 0.5140 - val_accuracy: 0.7655 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5403 - accuracy: 0.7487 - val_loss: 0.4966 - val_accuracy: 0.7752 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5392 - accuracy: 0.7460 - val_loss: 0.5007 - val_accuracy: 0.7820 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5414 - accuracy: 0.7462 - val_loss: 0.4880 - val_accuracy: 0.7792 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5394 - accuracy: 0.7522 - val_loss: 0.4934 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5363 - accuracy: 0.7472 - val_loss: 0.5135 - val_accuracy: 0.7679 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5280 - accuracy: 0.7545 - val_loss: 0.5137 - val_accuracy: 0.7688 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5345 - accuracy: 0.7471 - val_loss: 0.4789 - val_accuracy: 0.7934 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5302 - accuracy: 0.7532 - val_loss: 0.4975 - val_accuracy: 0.7760 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5285 - accuracy: 0.7510 - val_loss: 0.4853 - val_accuracy: 0.7848 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5326 - accuracy: 0.7534 - val_loss: 0.4898 - val_accuracy: 0.7722 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5263 - accuracy: 0.7557 - val_loss: 0.4810 - val_accuracy: 0.7850 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5293 - accuracy: 0.7525 - val_loss: 0.4765 - val_accuracy: 0.7986 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5271 - accuracy: 0.7548 - val_loss: 0.4652 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 3s 33ms/step - loss: 0.5240 - accuracy: 0.7566 - val_loss: 0.4704 - val_accuracy: 0.7880 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5183 - accuracy: 0.7606 - val_loss: 0.4708 - val_accuracy: 0.7812 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5240 - accuracy: 0.7572 - val_loss: 0.4666 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5248 - accuracy: 0.7551 - val_loss: 0.4571 - val_accuracy: 0.8004 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5217 - accuracy: 0.7632 - val_loss: 0.4616 - val_accuracy: 0.8047 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5190 - accuracy: 0.7594 - val_loss: 0.4542 - val_accuracy: 0.7948 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5149 - accuracy: 0.7612 - val_loss: 0.4523 - val_accuracy: 0.7990 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5155 - accuracy: 0.7632 - val_loss: 0.4677 - val_accuracy: 0.7900 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5151 - accuracy: 0.7607 - val_loss: 0.4568 - val_accuracy: 0.7978 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5132 - accuracy: 0.7626 - val_loss: 0.4665 - val_accuracy: 0.7952 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5115 - accuracy: 0.7648 - val_loss: 0.4887 - val_accuracy: 0.7826 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5224 - accuracy: 0.7554 - val_loss: 0.4492 - val_accuracy: 0.7992 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5079 - accuracy: 0.7629 - val_loss: 0.4608 - val_accuracy: 0.8008 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5138 - accuracy: 0.7642 - val_loss: 0.4485 - val_accuracy: 0.8010 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5077 - accuracy: 0.7704 - val_loss: 0.4506 - val_accuracy: 0.7966 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5060 - accuracy: 0.7709 - val_loss: 0.4397 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5105 - accuracy: 0.7649 - val_loss: 0.4412 - val_accuracy: 0.8037 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5042 - accuracy: 0.7707 - val_loss: 0.4397 - val_accuracy: 0.8053 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5079 - accuracy: 0.7684 - val_loss: 0.4400 - val_accuracy: 0.8081 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5018 - accuracy: 0.7732 - val_loss: 0.4411 - val_accuracy: 0.8087 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5025 - accuracy: 0.7730 - val_loss: 0.4394 - val_accuracy: 0.8067 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5011 - accuracy: 0.7698 - val_loss: 0.4409 - val_accuracy: 0.8063 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5067 - accuracy: 0.7650 - val_loss: 0.4439 - val_accuracy: 0.8010 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5023 - accuracy: 0.7734 - val_loss: 0.4381 - val_accuracy: 0.8113 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5031 - accuracy: 0.7698 - val_loss: 0.4377 - val_accuracy: 0.8093 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5006 - accuracy: 0.7701 - val_loss: 0.4382 - val_accuracy: 0.8079 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5001 - accuracy: 0.7699 - val_loss: 0.4394 - val_accuracy: 0.8073 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5026 - accuracy: 0.7720 - val_loss: 0.4390 - val_accuracy: 0.8067 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5000 - accuracy: 0.7692 - val_loss: 0.4389 - val_accuracy: 0.8069 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5025 - accuracy: 0.7740 - val_loss: 0.4392 - val_accuracy: 0.8075 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.4977 - accuracy: 0.7753 - val_loss: 0.4390 - val_accuracy: 0.8071 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5016 - accuracy: 0.7666 - val_loss: 0.4394 - val_accuracy: 0.8065 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5079 - accuracy: 0.7681 - val_loss: 0.4392 - val_accuracy: 0.8057 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.4988 - accuracy: 0.7762 - val_loss: 0.4394 - val_accuracy: 0.8061 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.4948 - accuracy: 0.7747 - val_loss: 0.4400 - val_accuracy: 0.8061 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.4986 - accuracy: 0.7737 - val_loss: 0.4402 - val_accuracy: 0.8053 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.4987 - accuracy: 0.7725 - val_loss: 0.4398 - val_accuracy: 0.8063 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.4988 - accuracy: 0.7719 - val_loss: 0.4399 - val_accuracy: 0.8063 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.4997 - accuracy: 0.7707 - val_loss: 0.4397 - val_accuracy: 0.8063 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5033 - accuracy: 0.7725 - val_loss: 0.4395 - val_accuracy: 0.8063 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.4929 - accuracy: 0.7835 - val_loss: 0.4394 - val_accuracy: 0.8063 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.5050 - accuracy: 0.7741 - val_loss: 0.4393 - val_accuracy: 0.8063 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5022 - accuracy: 0.7715 - val_loss: 0.4388 - val_accuracy: 0.8075 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5011 - accuracy: 0.7725 - val_loss: 0.4392 - val_accuracy: 0.8067 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 4s 8ms/step - loss: 0.4014 - accuracy: 0.8257\n",
      "17/17 [==============================] - 1s 6ms/step\n",
      "TP:4631, TN:9361, FP:1094, FN:1860, loss0.4014422297477722, acc0.8256815767732798, sn0.7134493914651056, sp0.8953610712577714, f10.7581859855926654, auc0.9023413797170949\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 14s 31ms/step - loss: 0.9539 - accuracy: 0.5636 - val_loss: 0.8878 - val_accuracy: 0.5728 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.8577 - accuracy: 0.5926 - val_loss: 0.8792 - val_accuracy: 0.5088 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.8140 - accuracy: 0.6024 - val_loss: 0.8578 - val_accuracy: 0.4944 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7836 - accuracy: 0.6048 - val_loss: 0.8221 - val_accuracy: 0.5265 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7601 - accuracy: 0.6015 - val_loss: 0.7874 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.7387 - accuracy: 0.6195 - val_loss: 0.7626 - val_accuracy: 0.5870 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7209 - accuracy: 0.6171 - val_loss: 0.7638 - val_accuracy: 0.5604 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.7062 - accuracy: 0.6186 - val_loss: 0.7486 - val_accuracy: 0.5917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6942 - accuracy: 0.6340 - val_loss: 0.7445 - val_accuracy: 0.5822 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6787 - accuracy: 0.6434 - val_loss: 0.7553 - val_accuracy: 0.5423 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.6697 - accuracy: 0.6468 - val_loss: 0.7380 - val_accuracy: 0.5445 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6624 - accuracy: 0.6501 - val_loss: 0.7548 - val_accuracy: 0.5265 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6566 - accuracy: 0.6499 - val_loss: 0.7615 - val_accuracy: 0.5152 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6502 - accuracy: 0.6554 - val_loss: 0.7471 - val_accuracy: 0.5283 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6473 - accuracy: 0.6517 - val_loss: 0.7412 - val_accuracy: 0.5311 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6409 - accuracy: 0.6552 - val_loss: 0.7655 - val_accuracy: 0.5096 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6409 - accuracy: 0.6538 - val_loss: 0.6936 - val_accuracy: 0.5965 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6313 - accuracy: 0.6646 - val_loss: 0.7469 - val_accuracy: 0.5417 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6309 - accuracy: 0.6674 - val_loss: 0.7872 - val_accuracy: 0.4886 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6285 - accuracy: 0.6644 - val_loss: 0.6963 - val_accuracy: 0.5917 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6225 - accuracy: 0.6711 - val_loss: 0.6443 - val_accuracy: 0.6370 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6172 - accuracy: 0.6763 - val_loss: 0.7416 - val_accuracy: 0.5513 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6134 - accuracy: 0.6739 - val_loss: 0.7546 - val_accuracy: 0.5341 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6172 - accuracy: 0.6742 - val_loss: 0.7071 - val_accuracy: 0.5886 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6073 - accuracy: 0.6850 - val_loss: 0.6921 - val_accuracy: 0.6057 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6078 - accuracy: 0.6900 - val_loss: 0.6892 - val_accuracy: 0.6013 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.6029 - accuracy: 0.6865 - val_loss: 0.6878 - val_accuracy: 0.5899 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.6021 - accuracy: 0.6879 - val_loss: 0.6791 - val_accuracy: 0.5895 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5994 - accuracy: 0.6958 - val_loss: 0.6755 - val_accuracy: 0.6121 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5972 - accuracy: 0.6999 - val_loss: 0.6050 - val_accuracy: 0.6881 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5916 - accuracy: 0.7031 - val_loss: 0.6539 - val_accuracy: 0.6231 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5939 - accuracy: 0.7020 - val_loss: 0.6064 - val_accuracy: 0.6763 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5914 - accuracy: 0.7036 - val_loss: 0.6728 - val_accuracy: 0.6089 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5846 - accuracy: 0.7066 - val_loss: 0.5988 - val_accuracy: 0.6787 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5837 - accuracy: 0.7087 - val_loss: 0.6573 - val_accuracy: 0.6229 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5794 - accuracy: 0.7103 - val_loss: 0.5870 - val_accuracy: 0.6996 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5804 - accuracy: 0.7124 - val_loss: 0.6167 - val_accuracy: 0.6669 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5735 - accuracy: 0.7184 - val_loss: 0.6077 - val_accuracy: 0.6745 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5737 - accuracy: 0.7167 - val_loss: 0.5591 - val_accuracy: 0.7260 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5728 - accuracy: 0.7185 - val_loss: 0.6364 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5694 - accuracy: 0.7203 - val_loss: 0.5626 - val_accuracy: 0.7232 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5713 - accuracy: 0.7178 - val_loss: 0.5619 - val_accuracy: 0.7288 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5658 - accuracy: 0.7237 - val_loss: 0.5729 - val_accuracy: 0.7236 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5666 - accuracy: 0.7225 - val_loss: 0.5691 - val_accuracy: 0.7258 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5633 - accuracy: 0.7262 - val_loss: 0.5613 - val_accuracy: 0.7375 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5608 - accuracy: 0.7284 - val_loss: 0.5268 - val_accuracy: 0.7571 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5623 - accuracy: 0.7266 - val_loss: 0.6138 - val_accuracy: 0.6763 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5554 - accuracy: 0.7260 - val_loss: 0.5240 - val_accuracy: 0.7537 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5634 - accuracy: 0.7291 - val_loss: 0.5422 - val_accuracy: 0.7577 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.5567 - accuracy: 0.7309 - val_loss: 0.5362 - val_accuracy: 0.7609 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5538 - accuracy: 0.7321 - val_loss: 0.5254 - val_accuracy: 0.7587 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5515 - accuracy: 0.7331 - val_loss: 0.5223 - val_accuracy: 0.7710 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5544 - accuracy: 0.7339 - val_loss: 0.5421 - val_accuracy: 0.7535 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5536 - accuracy: 0.7381 - val_loss: 0.4997 - val_accuracy: 0.7714 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5507 - accuracy: 0.7360 - val_loss: 0.5008 - val_accuracy: 0.7774 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5443 - accuracy: 0.7428 - val_loss: 0.5064 - val_accuracy: 0.7671 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5412 - accuracy: 0.7440 - val_loss: 0.5019 - val_accuracy: 0.7768 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5458 - accuracy: 0.7368 - val_loss: 0.4942 - val_accuracy: 0.7752 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5457 - accuracy: 0.7369 - val_loss: 0.5263 - val_accuracy: 0.7587 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5438 - accuracy: 0.7388 - val_loss: 0.4882 - val_accuracy: 0.7798 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5486 - accuracy: 0.7390 - val_loss: 0.4845 - val_accuracy: 0.7788 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5368 - accuracy: 0.7513 - val_loss: 0.5120 - val_accuracy: 0.7641 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5437 - accuracy: 0.7395 - val_loss: 0.4984 - val_accuracy: 0.7692 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5379 - accuracy: 0.7428 - val_loss: 0.4790 - val_accuracy: 0.7874 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5369 - accuracy: 0.7485 - val_loss: 0.4745 - val_accuracy: 0.7836 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5355 - accuracy: 0.7470 - val_loss: 0.5012 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5344 - accuracy: 0.7469 - val_loss: 0.4830 - val_accuracy: 0.7870 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5318 - accuracy: 0.7480 - val_loss: 0.4847 - val_accuracy: 0.7808 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5344 - accuracy: 0.7517 - val_loss: 0.4663 - val_accuracy: 0.7894 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5333 - accuracy: 0.7504 - val_loss: 0.4691 - val_accuracy: 0.7868 - lr: 0.0010\n",
      "Learning rate:  0.0010000000474974513\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.5311 - accuracy: 0.7487 - val_loss: 0.4767 - val_accuracy: 0.7798 - lr: 0.0010\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5366 - accuracy: 0.7509 - val_loss: 0.4693 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5285 - accuracy: 0.7497 - val_loss: 0.4660 - val_accuracy: 0.7882 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5222 - accuracy: 0.7604 - val_loss: 0.4668 - val_accuracy: 0.7894 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5275 - accuracy: 0.7501 - val_loss: 0.4645 - val_accuracy: 0.7926 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5230 - accuracy: 0.7553 - val_loss: 0.4631 - val_accuracy: 0.7904 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5194 - accuracy: 0.7602 - val_loss: 0.4627 - val_accuracy: 0.7908 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5216 - accuracy: 0.7590 - val_loss: 0.4637 - val_accuracy: 0.7908 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5274 - accuracy: 0.7536 - val_loss: 0.4629 - val_accuracy: 0.7898 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5181 - accuracy: 0.7568 - val_loss: 0.4600 - val_accuracy: 0.7940 - lr: 1.0000e-04\n",
      "Learning rate:  0.00010000000474974513\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5180 - accuracy: 0.7596 - val_loss: 0.4611 - val_accuracy: 0.7934 - lr: 1.0000e-04\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5182 - accuracy: 0.7602 - val_loss: 0.4592 - val_accuracy: 0.7942 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5207 - accuracy: 0.7564 - val_loss: 0.4590 - val_accuracy: 0.7944 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5203 - accuracy: 0.7598 - val_loss: 0.4584 - val_accuracy: 0.7940 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5188 - accuracy: 0.7592 - val_loss: 0.4584 - val_accuracy: 0.7932 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5099 - accuracy: 0.7630 - val_loss: 0.4584 - val_accuracy: 0.7936 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5187 - accuracy: 0.7614 - val_loss: 0.4589 - val_accuracy: 0.7940 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5233 - accuracy: 0.7584 - val_loss: 0.4581 - val_accuracy: 0.7932 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5206 - accuracy: 0.7590 - val_loss: 0.4579 - val_accuracy: 0.7936 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5154 - accuracy: 0.7614 - val_loss: 0.4580 - val_accuracy: 0.7934 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-05\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5190 - accuracy: 0.7581 - val_loss: 0.4585 - val_accuracy: 0.7938 - lr: 1.0000e-05\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5211 - accuracy: 0.7550 - val_loss: 0.4589 - val_accuracy: 0.7936 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5161 - accuracy: 0.7626 - val_loss: 0.4584 - val_accuracy: 0.7936 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.5176 - accuracy: 0.7588 - val_loss: 0.4585 - val_accuracy: 0.7934 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.5171 - accuracy: 0.7578 - val_loss: 0.4585 - val_accuracy: 0.7936 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.5206 - accuracy: 0.7552 - val_loss: 0.4585 - val_accuracy: 0.7938 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5172 - accuracy: 0.7609 - val_loss: 0.4586 - val_accuracy: 0.7936 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.5225 - accuracy: 0.7554 - val_loss: 0.4583 - val_accuracy: 0.7938 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.5219 - accuracy: 0.7564 - val_loss: 0.4575 - val_accuracy: 0.7942 - lr: 1.0000e-06\n",
      "Learning rate:  1.0000001111620804e-06\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 3s 27ms/step - loss: 0.5200 - accuracy: 0.7586 - val_loss: 0.4586 - val_accuracy: 0.7936 - lr: 1.0000e-06\n",
      "530/530 [==============================] - 5s 8ms/step - loss: 0.4179 - accuracy: 0.8153\n",
      "17/17 [==============================] - 1s 7ms/step\n",
      "TP:4440, TN:9376, FP:1079, FN:2051, loss0.4179059863090515, acc0.8152956449899681, sn0.6840240332768449, sp0.8967957914873267, f10.739383846794338, auc0.8931697208532344\n",
      "Average Test loss:  0.42922030091285707\n",
      "Average Accuracy:  0.8120677446004958\n",
      "Average Sensitivity:  0.6892620551532892\n",
      "Average Specificity:  0.88831181252989\n",
      "Average F1 Score:  0.7373079076032227\n",
      "Average AUC Score:  0.8877594124550632\n",
      "AUC for ROC curve 1: 0.8791\n",
      "AUC for ROC curve 2: 0.8791\n",
      "AUC for ROC curve 3: 0.8966\n",
      "AUC for ROC curve 4: 0.8966\n",
      "AUC for ROC curve 5: 0.8957\n",
      "AUC for ROC curve 6: 0.8957\n",
      "AUC for ROC curve 7: 0.8757\n",
      "AUC for ROC curve 8: 0.8757\n",
      "AUC for ROC curve 9: 0.8574\n",
      "AUC for ROC curve 10: 0.8574\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, f1_score,roc_auc_score\n",
    "losses = []\n",
    "accuracies = []\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "f1_scores = []\n",
    "auc_scores = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "\n",
    "num_trainings = 10\n",
    "for i in range(num_trainings):\n",
    "    model = create_model(x_train1.shape[1:], x_train2.shape[1:], x_train3.shape[1:])\n",
    "    model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "    history = model.fit([x_train1, x_train2, x_train3], y_train, batch_size=128, epochs=100,\n",
    "                        validation_data=([x_val1, x_val2, x_val3], y_val), callbacks=[lr_scheduler])\n",
    "    loss, accuracy = model.evaluate([x_test1, x_test2, x_test3], y_test)\n",
    "    y_prob = model.predict([x_test1, x_test2, x_test3], batch_size=1024, verbose=1)\n",
    "\n",
    "    y_true = y_test.argmax(axis=-1)\n",
    "    y_pred = np.argmax(y_prob, axis=-1)\n",
    "\n",
    "    C = confusion_matrix(y_true, y_pred, labels=(1, 0))\n",
    "    TP, TN, FP, FN = C[0, 0], C[1, 1], C[1, 0], C[0, 1]\n",
    "    acc, sn, sp = 1. * (TP + TN) / (TP + TN + FP + FN), 1. * TP / (TP + FN), 1. * TN / (TN + FP)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    sn = TP / (TP + FN)  \n",
    "    sp = TN / (TN + FP) \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = sn\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    auc_scores.append(roc_auc)\n",
    "    \n",
    "    print(\"TP:{}, TN:{}, FP:{}, FN:{}, loss{}, acc{}, sn{}, sp{}, f1{}, auc{}\".format(TP, TN, FP, FN, loss, acc, sn, sp, f1, roc_auc))\n",
    "    losses.append(loss)\n",
    "    accuracies.append(acc)\n",
    "    sensitivities.append(sn)\n",
    "    specificities.append(sp)\n",
    "    f1_scores.append(f1)\n",
    "    auc_scores.append(roc_auc)\n",
    "\n",
    "avg_loss = np.mean(losses)\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_sensitivity = np.mean(sensitivities)\n",
    "avg_specificity = np.mean(specificities)\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "avg_auc_score = np.mean(auc_scores)\n",
    "\n",
    "print(\"Average Test loss: \", avg_loss)\n",
    "print(\"Average Accuracy: \", avg_accuracy)\n",
    "print(\"Average Sensitivity: \", avg_sensitivity)\n",
    "print(\"Average Specificity: \", avg_specificity)\n",
    "print(\"Average F1 Score: \", avg_f1_score)\n",
    "print(\"Average AUC Score: \", avg_auc_score)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = np.zeros_like(mean_fpr)\n",
    "for i in range(num_trainings):\n",
    "    mean_tpr += np.interp(mean_fpr, fprs[i], tprs[i])\n",
    "    plt.plot(fprs[i], tprs[i], alpha=0.3, label='ROC curve {} (AUC = {:.4f})'.format(i+1, auc_scores[i]))\n",
    "    print('AUC for ROC curve {}: {:.4f}'.format(i+1, auc_scores[i]))\n",
    "mean_tpr /= num_trainings\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--', label='Mean ROC (AUC = {:.4f})'.format(mean_auc), lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f9963-cfa7-47f5-8701-2a24e58e20bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gcn",
   "language": "python",
   "name": "gcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
